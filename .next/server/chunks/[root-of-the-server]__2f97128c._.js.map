{"version":3,"sources":["../../../src/lib/convex-shim.ts","../../../src/lib/openclaw/auth-server.ts","../../../src/lib/passcodeAuth.ts","../../../src/lib/memory/manager.ts","../../../src/lib/memory/ai-ingestion.ts"],"sourcesContent":["export class ConvexHttpClient {\n    constructor(url: string) { }\n    query(query: any, args?: any): Promise<any> { return Promise.resolve(null); }\n    mutation(mutation: any, args?: any): Promise<any> { return Promise.resolve(null); }\n}\n\nexport const api = {\n    jobs: {\n        getAgentJobs: 'jobs:getAgentJobs',\n        cancelJob: 'jobs:cancelJob',\n        getJob: 'jobs:getJob',\n        queueCodeIteration: 'jobs:queueCodeIteration',\n        queueSpecialistDelegation: 'jobs:queueSpecialistDelegation',\n        queueAgentTask: 'jobs:queueAgentTask',\n        updateJobStatusPublic: 'jobs:updateJobStatusPublic',\n        logJobEventPublic: 'jobs:logJobEventPublic',\n    },\n    aiSettings: {\n        getSettings: 'aiSettings:getSettings',\n    },\n    erv: {\n        createEntity: 'erv:createEntity',\n        createRelationship: 'erv:createRelationship',\n        createDimension: 'erv:createDimension',\n        listDimensions: 'erv:listDimensions',\n        searchEntities: 'erv:searchEntities',\n        getEntity: 'erv:getEntity',\n    },\n    jamz: {\n        createProject: 'jamz:createProject',\n        createTrack: 'jamz:createTrack',\n        createClip: 'jamz:createClip',\n    },\n    messages: {\n        send: 'messages:send',\n    },\n    whatsappContacts: {\n        list: 'whatsappContacts:list',\n        getContactByPhone: 'whatsappContacts:getContactByPhone',\n        listContacts: 'whatsappContacts:listContacts',\n        upsertContact: 'whatsappContacts:upsertContact',\n    },\n    channels: {\n        list: 'channels:list',\n        getChannel: 'channels:getChannel',\n        sendMessage: 'channels:sendMessage',\n        getUserMessages: 'channels:getUserMessages',\n        getUserIntegrations: 'channels:getUserIntegrations',\n        getConversations: 'channels:getConversations',\n        getIntegration: 'channels:getIntegration',\n        logOutboundMessage: 'channels:logOutboundMessage',\n        searchMessages: 'channels:searchMessages',\n    },\n    scheduling: {\n        list: 'scheduling:list',\n        createEvent: 'scheduling:createEvent',\n        getEventTypes: 'scheduling:getEventTypes',\n        getAvailableSlots: 'scheduling:getAvailableSlots',\n        createBooking: 'scheduling:createBooking',\n        rescheduleBooking: 'scheduling:rescheduleBooking',\n        updateBookingStatus: 'scheduling:updateBookingStatus',\n    },\n    userCronJobs: {\n        list: 'userCronJobs:list',\n        create: 'userCronJobs:create',\n        delete: 'userCronJobs:delete',\n        createJob: 'userCronJobs:createJob',\n        getUserJobs: 'userCronJobs:getUserJobs',\n        toggleJob: 'userCronJobs:toggleJob',\n        deleteJob: 'userCronJobs:deleteJob',\n    },\n    compaction: {\n        compact: 'compaction:compact',\n        getLatestCompaction: 'compaction:getLatestCompaction',\n    },\n    kanban: {\n        listLists: 'kanban:listLists',\n        createCard: 'kanban:createCard',\n        moveCard: 'kanban:moveCard',\n        getTaskById: 'kanban:getTaskById',\n        searchTasks: 'kanban:searchTasks',\n        getTasks: 'kanban:getTasks',\n        isSeeded: 'kanban:isSeeded',\n        addTask: 'kanban:addTask',\n        updateTask: 'kanban:updateTask',\n        deleteTask: 'kanban:deleteTask',\n        moveTask: 'kanban:moveTask',\n        seedTasks: 'kanban:seedTasks',\n    },\n    designCanvas: {\n        getCanvas: 'designCanvas:getCanvas',\n        updateCanvas: 'designCanvas:updateCanvas',\n        createItem: 'designCanvas:createItem',\n        createCanvas: 'designCanvas:createCanvas',\n        getUserCanvases: 'designCanvas:getUserCanvases',\n        getCanvasNodes: 'designCanvas:getCanvasNodes',\n        getCanvasEdges: 'designCanvas:getCanvasEdges',\n        addNode: 'designCanvas:addNode',\n        addEdge: 'designCanvas:addEdge',\n        updateNode: 'designCanvas:updateNode',\n    },\n    agentic: {\n        createProductProject: 'agentic:createProductProject',\n        createPRD: 'agentic:createPRD',\n        createEpic: 'agentic:createEpic',\n        createTicket: 'agentic:createTicket',\n    },\n    discovery: {\n        getSession: 'discovery:getSession',\n        storeInsights: 'discovery:storeInsights',\n        storeArtifacts: 'discovery:storeArtifacts',\n        markNotificationSent: 'discovery:markNotificationSent',\n        markError: 'discovery:markError',\n        getSessionByCallerId: 'discovery:getSessionByCallerId',\n        updateTranscript: 'discovery:updateTranscript',\n    },\n    memories: {\n        searchEpisodic: 'memories:searchEpisodic',\n        getSemanticByCategories: 'memories:getSemanticByCategories',\n        getAllSemantic: 'memories:getAllSemantic',\n        getRecentEpisodic: 'memories:getRecentEpisodic',\n        storeEpisodic: 'memories:storeEpisodic',\n        upsertSemantic: 'memories:upsertSemantic',\n        deleteEpisodic: 'memories:deleteEpisodic',\n        deleteSemantic: 'memories:deleteSemantic',\n        getMemoryStats: 'memories:getMemoryStats',\n    },\n    observability: {\n        getSecurityScans: 'observability:getSecurityScans',\n        createSecurityScan: 'observability:createSecurityScan',\n        getActivityStream: 'observability:getActivityStream',\n        getDashboardOverview: 'observability:getDashboardOverview',\n        getProviderHealthStatus: 'observability:getProviderHealthStatus',\n        logOperation: 'observability:logOperation',\n    },\n    roadmap: {\n        submitSuggestion: 'roadmap:submitSuggestion',\n        getSuggestions: 'roadmap:getSuggestions',\n        updateSuggestionStatus: 'roadmap:updateSuggestionStatus',\n        voteSuggestion: 'roadmap:voteSuggestion',\n    }\n\n};\n\n// Export ConvexReactClient type for compatibility\nexport type ConvexReactClient = any;\n\nexport type Id<T extends string> = string;\n","\nimport { NextResponse } from \"next/server\";\n\nexport const auth = () => {\n    return {\n        userId: \"mock-user-id\",\n        sessionId: \"mock-session-id\",\n        getToken: async () => \"mock-token\",\n        redirectToSignIn: () => ({})\n    };\n};\n\nexport const currentUser = async () => {\n    return {\n        id: \"mock-user-id\",\n        firstName: \"James\",\n        lastName: \"Spalding\",\n        emailAddresses: [{ emailAddress: \"james@example.com\" }]\n    };\n};\n\nexport const clerkClient = {\n    users: {\n        getUser: async () => currentUser()\n    }\n};\n\nexport const clerkMiddleware = () => {\n    return (req: any) => {\n        return NextResponse.next();\n    };\n};\n","/**\n * Passcode Authentication System\n *\n * Handles 6-digit passcode verification for protected areas and iPod collaborators.\n * Uses HMAC-SHA256 for secure hashing and timing-safe comparison.\n */\n\nimport crypto from 'crypto';\n\n// SECURITY: Require PASSCODE_SECRET to be set - no default fallback\nfunction getPasscodeSecret(): string {\n  const secret = process.env.PASSCODE_SECRET;\n  if (!secret) {\n    throw new Error('PASSCODE_SECRET environment variable is required');\n  }\n  if (secret.length < 32) {\n    throw new Error('PASSCODE_SECRET must be at least 32 characters long');\n  }\n  return secret;\n}\n\n// Lazy-initialize to allow env vars to be set before first use\nlet cachedSecret: string | null = null;\nfunction getSecret(): string {\n  if (!cachedSecret) {\n    cachedSecret = getPasscodeSecret();\n  }\n  return cachedSecret;\n}\n\n// Cookie names for session tokens\nexport const ADMIN_COOKIE = 'jamos_admin';\nexport const AREA_COOKIE_PREFIX = 'jamos_area_';\nexport const IPOD_COOKIE = 'jamos_ipod';\n\n// Session duration (24 hours for admin, 7 days for areas/iPod)\nconst ADMIN_SESSION_DURATION = 24 * 60 * 60 * 1000;\nconst AREA_SESSION_DURATION = 7 * 24 * 60 * 60 * 1000;\n\n/**\n * Hash a 6-digit passcode\n */\nexport function hashPasscode(passcode: string): string {\n  return crypto\n    .createHmac('sha256', getSecret())\n    .update(passcode)\n    .digest('hex');\n}\n\n/**\n * Verify a passcode against a hash (timing-safe)\n */\nexport function verifyPasscode(passcode: string, hash: string): boolean {\n  const inputHash = hashPasscode(passcode);\n  const inputBuffer = Buffer.from(inputHash);\n  const hashBuffer = Buffer.from(hash);\n\n  if (inputBuffer.length !== hashBuffer.length) {\n    return false;\n  }\n\n  return crypto.timingSafeEqual(inputBuffer, hashBuffer);\n}\n\n/**\n * Session token payload\n */\ninterface SessionPayload {\n  type: 'admin' | 'area' | 'ipod';\n  subject: string; // admin username, area slug, or collaborator slug\n  exp: number;\n}\n\n/**\n * Sign a session token\n */\nexport function signSession(payload: SessionPayload): string {\n  const payloadB64 = Buffer.from(JSON.stringify(payload)).toString('base64url');\n  const signature = crypto\n    .createHmac('sha256', getSecret())\n    .update(payloadB64)\n    .digest('base64url');\n  return `${payloadB64}.${signature}`;\n}\n\n/**\n * Verify and decode a session token\n */\nexport function verifySession(token: string | undefined): SessionPayload | null {\n  if (!token) return null;\n\n  const parts = token.split('.');\n  if (parts.length !== 2) return null;\n\n  const [payloadB64, signature] = parts;\n\n  // Verify signature\n  const expectedSig = crypto\n    .createHmac('sha256', getSecret())\n    .update(payloadB64)\n    .digest('base64url');\n\n  const sigBuffer = Buffer.from(signature);\n  const expectedBuffer = Buffer.from(expectedSig);\n\n  if (sigBuffer.length !== expectedBuffer.length) return null;\n  if (!crypto.timingSafeEqual(sigBuffer, expectedBuffer)) return null;\n\n  // Decode payload\n  try {\n    const payload = JSON.parse(Buffer.from(payloadB64, 'base64url').toString()) as SessionPayload;\n\n    // Check expiry\n    if (Date.now() > payload.exp) return null;\n\n    return payload;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Create an admin session token\n */\nexport function createAdminSession(username: string): string {\n  return signSession({\n    type: 'admin',\n    subject: username,\n    exp: Date.now() + ADMIN_SESSION_DURATION,\n  });\n}\n\n/**\n * Create an area session token\n */\nexport function createAreaSession(areaSlug: string): string {\n  return signSession({\n    type: 'area',\n    subject: areaSlug,\n    exp: Date.now() + AREA_SESSION_DURATION,\n  });\n}\n\n/**\n * Create an iPod collaborator session token\n */\nexport function createiPodSession(collaboratorSlug: string): string {\n  return signSession({\n    type: 'ipod',\n    subject: collaboratorSlug,\n    exp: Date.now() + AREA_SESSION_DURATION,\n  });\n}\n\n/**\n * Get cookie name for a protected area\n */\nexport function getAreaCookieName(areaSlug: string): string {\n  return `${AREA_COOKIE_PREFIX}${areaSlug}`;\n}\n\n/**\n * Validate a 6-digit passcode format\n */\nexport function isValidPasscodeFormat(passcode: string): boolean {\n  return /^\\d{6}$/.test(passcode);\n}\n","/**\n * MemoryManager\n *\n * Handles memory operations for the RLM (Recursive Memory Layer) system.\n * Provides methods to store, retrieve, and manage episodic, semantic,\n * and working memory for Claw AI interactions.\n *\n * @see docs/philosophy/README.md#self-learning-systems\n * @see docs/planning/recursive-memory-layer-scope.md\n */\n\nimport { ConvexHttpClient, api, Id } from '../convex-shim';\nimport {\n  EpisodicMemory,\n  EpisodicMemoryType,\n  ExtractedPattern,\n  Interaction,\n  MemorySearchOptions,\n  MemorySearchResult,\n  SemanticCategory,\n  SemanticMemory,\n} from \"./types\";\n\n// Dynamic import to handle cases where api types aren't generated yet\n// let api: any;\n// try {\n//   api = require('@/lib/convex-shim').api;\n// } catch {\n//   // API not generated yet - will use string paths\n//   api = null;\n// }\n\nexport class MemoryManager {\n  private convex: ConvexHttpClient | null = null;\n\n  constructor(convexUrl?: string) {\n    const url = convexUrl || process.env.NEXT_PUBLIC_CONVEX_URL;\n    if (url) {\n      this.convex = new ConvexHttpClient(url);\n    }\n  }\n\n  private getClient(): ConvexHttpClient {\n    if (!this.convex) {\n      const url = process.env.NEXT_PUBLIC_CONVEX_URL;\n      if (!url) {\n        throw new Error('NEXT_PUBLIC_CONVEX_URL not configured');\n      }\n      this.convex = new ConvexHttpClient(url);\n    }\n    return this.convex;\n  }\n\n  /**\n   * Get the API reference\n   */\n  private getApiRef(path: string) {\n    // If api is available (from shim or require), try to use it\n    if (api) {\n      const parts = path.split(\".\");\n      let ref: any = api;\n      for (const part of parts) {\n        if (ref) {\n          ref = ref[part];\n        }\n      }\n      if (ref) return ref;\n    }\n    // Fallback: return the path string\n    return path;\n  }\n\n  // ==========================================================================\n  // MEMORY LOADING\n  // ==========================================================================\n\n  /**\n   * Load relevant memories for a user query.\n   * Combines episodic (events) and semantic (facts) memories.\n   */\n  async loadRelevantMemories(\n    userId: string,\n    query: string,\n    options: MemorySearchOptions = {}\n  ): Promise<MemorySearchResult> {\n    const {\n      limit = 10,\n      includeEpisodic = true,\n      includeSemantic = true,\n      projectId,\n    } = options;\n\n    // Parallel fetch of episodic and semantic memories\n    const [episodic, semantic] = await Promise.all([\n      includeEpisodic\n        ? this.searchEpisodicMemories(userId, query, projectId, limit)\n        : [],\n      includeSemantic\n        ? this.loadSemanticMemories(userId, this.extractCategories(query))\n        : [],\n    ]);\n\n    // Build context summary for prompt injection\n    const contextSummary = this.buildContextSummary(episodic, semantic);\n\n    return { episodic, semantic, contextSummary };\n  }\n\n  /**\n   * Search episodic memories using text matching.\n   */\n  async searchEpisodicMemories(\n    userId: string,\n    query: string,\n    projectId?: Id<\"productProjects\">,\n    limit: number = 10\n  ): Promise<EpisodicMemory[]> {\n    const results = await this.getClient().query(\n      this.getApiRef(\"memories.searchEpisodic\"),\n      { userId, query, projectId, limit }\n    );\n    return results as EpisodicMemory[];\n  }\n\n  /**\n   * Load semantic memories by categories.\n   */\n  async loadSemanticMemories(\n    userId: string,\n    categories: SemanticCategory[]\n  ): Promise<SemanticMemory[]> {\n    const results = await this.getClient().query(\n      this.getApiRef(\"memories.getSemanticByCategories\"),\n      { userId, categories }\n    );\n    return results as SemanticMemory[];\n  }\n\n  /**\n   * Get all semantic memories for a user.\n   */\n  async getAllSemanticMemories(userId: string): Promise<SemanticMemory[]> {\n    const results = await this.getClient().query(\n      this.getApiRef(\"memories.getAllSemantic\"),\n      { userId }\n    );\n    return results as SemanticMemory[];\n  }\n\n  /**\n   * Get recent episodic memories.\n   */\n  async getRecentMemories(\n    userId: string,\n    projectId?: Id<\"productProjects\">,\n    limit: number = 10\n  ): Promise<EpisodicMemory[]> {\n    const results = await this.getClient().query(\n      this.getApiRef(\"memories.getRecentEpisodic\"),\n      { userId, projectId, limit }\n    );\n    return results as EpisodicMemory[];\n  }\n\n  // ==========================================================================\n  // MEMORY STORAGE\n  // ==========================================================================\n\n  /**\n   * Store an episodic memory.\n   */\n  async storeEpisodicMemory(\n    userId: string,\n    content: string,\n    memoryType: EpisodicMemoryType,\n    importance: number,\n    projectId?: Id<\"productProjects\">,\n    metadata?: {\n      toolsUsed?: string[];\n      outcome?: string;\n      compactionId?: string;\n      messageCount?: number;\n      topics?: string[];\n      [key: string]: unknown;\n    }\n  ): Promise<Id<\"episodicMemories\">> {\n    return await this.getClient().mutation(\n      this.getApiRef(\"memories.storeEpisodic\"),\n      { userId, projectId, content, memoryType, importance, metadata }\n    );\n  }\n\n  /**\n   * Store or update a semantic memory.\n   */\n  async upsertSemanticMemory(\n    userId: string,\n    category: SemanticCategory,\n    key: string,\n    value: string,\n    confidence: number,\n    source: string\n  ): Promise<Id<\"semanticMemories\">> {\n    return await this.getClient().mutation(\n      this.getApiRef(\"memories.upsertSemantic\"),\n      { userId, category, key, value, confidence, source }\n    );\n  }\n\n  // ==========================================================================\n  // INTERACTION PROCESSING\n  // ==========================================================================\n\n  /**\n   * Process an interaction and extract/store relevant memories.\n   */\n  async processInteraction(\n    userId: string,\n    interaction: Interaction,\n    projectId?: Id<\"productProjects\">\n  ): Promise<void> {\n    const importance = this.calculateImportance(interaction);\n\n    // Only store significant interactions (importance > 0.3)\n    if (importance > 0.3) {\n      const memoryType = this.classifyInteraction(interaction);\n      const content = this.summarizeInteraction(interaction);\n\n      await this.storeEpisodicMemory(\n        userId,\n        content,\n        memoryType,\n        importance,\n        projectId,\n        { toolsUsed: interaction.toolsUsed }\n      );\n    }\n\n    // Extract and store patterns/preferences\n    const patterns = this.extractPatterns(interaction);\n    for (const pattern of patterns) {\n      await this.upsertSemanticMemory(\n        userId,\n        pattern.category,\n        pattern.key,\n        pattern.value,\n        pattern.confidence,\n        \"interaction_learning\"\n      );\n    }\n  }\n\n  // ==========================================================================\n  // HELPER METHODS\n  // ==========================================================================\n\n  /**\n   * Extract relevant categories from a query for semantic memory lookup.\n   */\n  extractCategories(query: string): SemanticCategory[] {\n    const categories: SemanticCategory[] = [];\n    const lowerQuery = query.toLowerCase();\n\n    if (/prefer|like|style|theme|mode|favorite/.test(lowerQuery)) {\n      categories.push(\"preference\");\n    }\n    if (/skill|know|experience|proficient|expert|can you/.test(lowerQuery)) {\n      categories.push(\"skill\");\n    }\n    if (/pattern|usually|always|tend to|typically/.test(lowerQuery)) {\n      categories.push(\"pattern\");\n    }\n    if (/fact|is|are|does|what|who|where/.test(lowerQuery)) {\n      categories.push(\"fact\");\n    }\n\n    // Default to common categories if none detected\n    return categories.length > 0\n      ? categories\n      : [\"preference\", \"skill\", \"pattern\"];\n  }\n\n  /**\n   * Build a context summary for prompt injection.\n   */\n  buildContextSummary(\n    episodic: EpisodicMemory[],\n    semantic: SemanticMemory[]\n  ): string {\n    const parts: string[] = [];\n\n    // Add semantic memories (facts/preferences) - highest confidence first\n    if (semantic.length > 0) {\n      const semanticSummary = semantic\n        .sort((a, b) => b.confidence - a.confidence)\n        .slice(0, 5)\n        .map((m) => `- ${m.category}: ${m.value}`)\n        .join(\"\\n\");\n      parts.push(`User Context:\\n${semanticSummary}`);\n    }\n\n    // Add recent relevant episodic memories - highest importance first\n    if (episodic.length > 0) {\n      const episodicSummary = episodic\n        .sort((a, b) => b.importance - a.importance)\n        .slice(0, 3)\n        .map((m) => `- [${m.memoryType}] ${m.content}`)\n        .join(\"\\n\");\n      parts.push(`Recent History:\\n${episodicSummary}`);\n    }\n\n    return parts.join(\"\\n\\n\");\n  }\n\n  /**\n   * Calculate importance score for an interaction.\n   */\n  calculateImportance(interaction: Interaction): number {\n    let score = 0.3; // Base importance\n\n    // Positive feedback signals\n    if (\n      /thanks|perfect|great|exactly|awesome|excellent/i.test(\n        interaction.userMessage\n      )\n    ) {\n      score += 0.2;\n    }\n\n    // Multiple tools indicate complex interaction\n    if (interaction.toolsUsed.length > 2) {\n      score += 0.15;\n    }\n\n    // Decision-making language\n    if (\n      /decide|choose|prefer|want|let's|go with/i.test(interaction.userMessage)\n    ) {\n      score += 0.2;\n    }\n\n    // Creation operations are important\n    if (interaction.toolsUsed.some((t) => /create|update|delete/.test(t))) {\n      score += 0.15;\n    }\n\n    return Math.min(score, 1);\n  }\n\n  /**\n   * Classify an interaction into a memory type.\n   */\n  classifyInteraction(interaction: Interaction): EpisodicMemoryType {\n    const msg = interaction.userMessage.toLowerCase();\n\n    // Check for feedback\n    if (/thanks|great|perfect|awesome|excellent|love it/.test(msg)) {\n      return \"feedback\";\n    }\n\n    // Check for preferences\n    if (/prefer|like|want|rather|always use|my favorite/.test(msg)) {\n      return \"preference\";\n    }\n\n    // Check for decisions\n    if (/decide|choose|let's go with|use this|pick/.test(msg)) {\n      return \"decision\";\n    }\n\n    // Check for milestones based on tools\n    if (\n      interaction.toolsUsed.some((t) =>\n        /create_project|create_prd|shard_prd|launch/.test(t)\n      )\n    ) {\n      return \"milestone\";\n    }\n\n    return \"interaction\";\n  }\n\n  /**\n   * Summarize an interaction for storage.\n   */\n  summarizeInteraction(interaction: Interaction): string {\n    // Truncate user message if too long\n    const userPart =\n      interaction.userMessage.length > 100\n        ? interaction.userMessage.slice(0, 100) + \"...\"\n        : interaction.userMessage;\n\n    if (interaction.toolsUsed.length > 0) {\n      return `User: \"${userPart}\" â†’ Tools: ${interaction.toolsUsed.join(\", \")}`;\n    }\n    return `User: \"${userPart}\"`;\n  }\n\n  /**\n   * Extract patterns/preferences from an interaction.\n   */\n  extractPatterns(interaction: Interaction): ExtractedPattern[] {\n    const patterns: ExtractedPattern[] = [];\n    const msg = interaction.userMessage.toLowerCase();\n\n    // Detect explicit preferences\n    if (/i prefer|i like|i want|my favorite|i always use/.test(msg)) {\n      patterns.push({\n        category: \"preference\",\n        key: `pref_${Date.now()}`,\n        value: interaction.userMessage.slice(0, 200),\n        confidence: 0.7,\n      });\n    }\n\n    // Detect skill mentions\n    if (/i know|i can|experience with|proficient in|expert at/.test(msg)) {\n      patterns.push({\n        category: \"skill\",\n        key: `skill_${Date.now()}`,\n        value: interaction.userMessage.slice(0, 200),\n        confidence: 0.6,\n      });\n    }\n\n    // Detect behavioral patterns\n    if (/i usually|i always|i tend to|typically i/.test(msg)) {\n      patterns.push({\n        category: \"pattern\",\n        key: `pattern_${Date.now()}`,\n        value: interaction.userMessage.slice(0, 200),\n        confidence: 0.5,\n      });\n    }\n\n    return patterns;\n  }\n\n  // ==========================================================================\n  // MEMORY MANAGEMENT\n  // ==========================================================================\n\n  /**\n   * Delete an episodic memory.\n   */\n  async deleteEpisodicMemory(\n    memoryId: Id<\"episodicMemories\">,\n    userId: string\n  ): Promise<void> {\n    await this.getClient().mutation(\n      this.getApiRef(\"memories.deleteEpisodic\"),\n      { memoryId, userId }\n    );\n  }\n\n  /**\n   * Delete a semantic memory.\n   */\n  async deleteSemanticMemory(\n    memoryId: Id<\"semanticMemories\">,\n    userId: string\n  ): Promise<void> {\n    await this.getClient().mutation(\n      this.getApiRef(\"memories.deleteSemantic\"),\n      { memoryId, userId }\n    );\n  }\n\n  /**\n   * Get memory statistics for a user.\n   */\n  async getStats(userId: string) {\n    return await this.getClient().query(\n      this.getApiRef(\"memories.getMemoryStats\"),\n      { userId }\n    );\n  }\n}\n\n// Export singleton instance for convenience\nlet memoryManagerInstance: MemoryManager | null = null;\n\nexport function getMemoryManager(): MemoryManager {\n  if (!memoryManagerInstance) {\n    memoryManagerInstance = new MemoryManager();\n  }\n  return memoryManagerInstance;\n}\n","/**\n * AI-Powered Memory Ingestion\n *\n * Uses OpenAI (GPT-4o) to intelligently parse unstructured data and extract\n * structured memories (both episodic and semantic).\n *\n * @see docs/planning/recursive-memory-layer-scope.md\n */\n\nimport type { EpisodicMemoryType, SemanticCategory } from \"./types\";\n\n/**\n * Extracted memory from AI processing\n */\nexport interface ExtractedEpisodicMemory {\n  content: string;\n  memoryType: EpisodicMemoryType;\n  importance: number; // 0-1\n  context?: string; // Additional context about why this is important\n}\n\nexport interface ExtractedSemanticMemory {\n  category: SemanticCategory;\n  key: string; // Unique identifier like \"preferred_language\" or \"favorite_color\"\n  value: string; // The actual value/fact\n  confidence: number; // 0-1\n  source?: string; // Where this was extracted from\n}\n\nexport interface AIIngestionResult {\n  episodicMemories: ExtractedEpisodicMemory[];\n  semanticMemories: ExtractedSemanticMemory[];\n  summary: string;\n  processingNotes: string[];\n}\n\n/**\n * System prompt for memory extraction\n */\nconst EXTRACTION_SYSTEM_PROMPT = `You are a memory extraction AI for a personal knowledge system. Your job is to analyze text and extract two types of memories:\n\n## EPISODIC MEMORIES (Events/Interactions)\nThese are specific events, decisions, conversations, or milestones. Each should have:\n- content: A clear, standalone summary of what happened (50-200 chars)\n- memoryType: One of \"interaction\", \"decision\", \"preference\", \"feedback\", \"milestone\"\n- importance: 0.0-1.0 (higher = more significant)\n\nMemory type guidelines:\n- \"interaction\": General conversations or exchanges\n- \"decision\": Choices made, directions taken, options selected\n- \"preference\": Expressed likes, dislikes, preferences for how things should be\n- \"feedback\": Reactions to work, opinions given, reviews\n- \"milestone\": Achievements, completions, launches, significant events\n\n## SEMANTIC MEMORIES (Facts/Knowledge)\nThese are learned facts, preferences, patterns, and skills. Each should have:\n- category: One of \"preference\", \"skill\", \"pattern\", \"fact\"\n- key: A unique snake_case identifier (e.g., \"preferred_coding_language\", \"communication_style\")\n- value: The actual knowledge/fact (clear, specific)\n- confidence: 0.0-1.0 (how certain is this information)\n\nCategory guidelines:\n- \"preference\": Likes, dislikes, preferred ways of doing things\n- \"skill\": Abilities, expertise, proficiency levels\n- \"pattern\": Behavioral patterns, habits, tendencies\n- \"fact\": Objective facts about the person (location, job, etc.)\n\n## RULES\n1. Extract MEANINGFUL memories only - skip trivial/obvious content\n2. Be specific and actionable in your extractions\n3. Deduplicate - don't extract the same fact multiple times\n4. For semantic memories, use consistent key naming (snake_case, descriptive)\n5. Higher importance/confidence for explicitly stated things vs inferred\n6. Include context when it adds value\n\nRespond with valid JSON only, no markdown formatting.`;\n\n/**\n * Call OpenAI API directly\n */\nasync function callOpenAI(\n  systemPrompt: string,\n  userPrompt: string\n): Promise<string> {\n  const apiKey = process.env.OPENAI_API_KEY;\n  if (!apiKey) {\n    throw new Error(\"OPENAI_API_KEY not configured\");\n  }\n\n  const response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      Authorization: `Bearer ${apiKey}`,\n    },\n    body: JSON.stringify({\n      model: \"gpt-4o\",\n      max_tokens: 4096,\n      response_format: { type: \"json_object\" },\n      messages: [\n        { role: \"system\", content: systemPrompt },\n        { role: \"user\", content: userPrompt },\n      ],\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`OpenAI API error: ${response.status} - ${error}`);\n  }\n\n  const data = await response.json();\n  return data.choices?.[0]?.message?.content || \"\";\n}\n\n/**\n * Process content with AI and extract structured memories\n */\nexport async function extractMemoriesWithAI(\n  content: string,\n  filename: string,\n  options: {\n    maxEpisodic?: number;\n    maxSemantic?: number;\n  } = {}\n): Promise<AIIngestionResult> {\n  const { maxEpisodic = 50, maxSemantic = 30 } = options;\n\n  // Truncate very long content to avoid token limits\n  const truncatedContent =\n    content.length > 50000\n      ? content.slice(0, 50000) + \"\\n\\n[Content truncated...]\"\n      : content;\n\n  const userPrompt = `Analyze the following content from file \"${filename}\" and extract memories.\n\n<content>\n${truncatedContent}\n</content>\n\nExtract up to ${maxEpisodic} episodic memories and ${maxSemantic} semantic memories.\n\nRespond with this exact JSON structure:\n{\n  \"episodicMemories\": [\n    {\n      \"content\": \"string\",\n      \"memoryType\": \"interaction|decision|preference|feedback|milestone\",\n      \"importance\": 0.0-1.0,\n      \"context\": \"optional string\"\n    }\n  ],\n  \"semanticMemories\": [\n    {\n      \"category\": \"preference|skill|pattern|fact\",\n      \"key\": \"snake_case_key\",\n      \"value\": \"string\",\n      \"confidence\": 0.0-1.0,\n      \"source\": \"optional string\"\n    }\n  ],\n  \"summary\": \"Brief summary of what was extracted\",\n  \"processingNotes\": [\"Any notes about the extraction process\"]\n}`;\n\n  try {\n    const textContent = await callOpenAI(EXTRACTION_SYSTEM_PROMPT, userPrompt);\n\n    if (!textContent) {\n      throw new Error(\"No response from AI\");\n    }\n\n    // Parse JSON response\n    const result = JSON.parse(textContent) as AIIngestionResult;\n\n    // Validate and sanitize the result\n    return sanitizeIngestionResult(result, filename);\n  } catch (error) {\n    console.error(\"AI ingestion error:\", error);\n\n    // Return empty result on error\n    return {\n      episodicMemories: [],\n      semanticMemories: [],\n      summary: `Failed to process ${filename}`,\n      processingNotes: [\n        `Error: ${error instanceof Error ? error.message : \"Unknown error\"}`,\n      ],\n    };\n  }\n}\n\n/**\n * Validate and sanitize AI extraction results\n */\nfunction sanitizeIngestionResult(\n  result: AIIngestionResult,\n  filename: string\n): AIIngestionResult {\n  const validEpisodicTypes: EpisodicMemoryType[] = [\n    \"interaction\",\n    \"decision\",\n    \"preference\",\n    \"feedback\",\n    \"milestone\",\n  ];\n\n  const validSemanticCategories: SemanticCategory[] = [\n    \"preference\",\n    \"skill\",\n    \"pattern\",\n    \"fact\",\n  ];\n\n  // Sanitize episodic memories\n  const episodicMemories = (result.episodicMemories || [])\n    .filter((m) => m && typeof m.content === \"string\" && m.content.length > 10)\n    .map((m) => ({\n      content: m.content.slice(0, 500), // Limit length\n      memoryType: validEpisodicTypes.includes(m.memoryType)\n        ? m.memoryType\n        : \"interaction\",\n      importance: Math.max(0, Math.min(1, Number(m.importance) || 0.5)),\n      context: m.context ? String(m.context).slice(0, 200) : undefined,\n    }));\n\n  // Sanitize semantic memories\n  const semanticMemories = (result.semanticMemories || [])\n    .filter(\n      (m) =>\n        m &&\n        typeof m.key === \"string\" &&\n        m.key.length > 0 &&\n        typeof m.value === \"string\" &&\n        m.value.length > 0\n    )\n    .map((m) => ({\n      category: validSemanticCategories.includes(m.category)\n        ? m.category\n        : \"fact\",\n      key: m.key\n        .toLowerCase()\n        .replace(/[^a-z0-9_]/g, \"_\")\n        .slice(0, 50),\n      value: m.value.slice(0, 500),\n      confidence: Math.max(0, Math.min(1, Number(m.confidence) || 0.5)),\n      source: m.source\n        ? String(m.source).slice(0, 100)\n        : `Extracted from ${filename}`,\n    }));\n\n  return {\n    episodicMemories,\n    semanticMemories,\n    summary: result.summary || `Processed ${filename}`,\n    processingNotes: Array.isArray(result.processingNotes)\n      ? result.processingNotes.map((n) => String(n))\n      : [],\n  };\n}\n\n/**\n * Process multiple content chunks (for large files)\n */\nexport async function processLargeContent(\n  content: string,\n  filename: string,\n  chunkSize: number = 30000\n): Promise<AIIngestionResult> {\n  // If content is small enough, process directly\n  if (content.length <= chunkSize) {\n    return extractMemoriesWithAI(content, filename);\n  }\n\n  // Split into chunks at paragraph boundaries\n  const chunks: string[] = [];\n  let currentChunk = \"\";\n\n  const paragraphs = content.split(/\\n\\n+/);\n  for (const para of paragraphs) {\n    if (currentChunk.length + para.length > chunkSize) {\n      if (currentChunk) {\n        chunks.push(currentChunk);\n      }\n      currentChunk = para;\n    } else {\n      currentChunk += (currentChunk ? \"\\n\\n\" : \"\") + para;\n    }\n  }\n  if (currentChunk) {\n    chunks.push(currentChunk);\n  }\n\n  // Process each chunk\n  const results: AIIngestionResult[] = [];\n  for (let i = 0; i < chunks.length; i++) {\n    const chunkFilename = `${filename} (part ${i + 1}/${chunks.length})`;\n    const result = await extractMemoriesWithAI(chunks[i], chunkFilename);\n    results.push(result);\n  }\n\n  // Merge results\n  return mergeIngestionResults(results, filename);\n}\n\n/**\n * Merge multiple ingestion results\n */\nfunction mergeIngestionResults(\n  results: AIIngestionResult[],\n  filename: string\n): AIIngestionResult {\n  const allEpisodic: ExtractedEpisodicMemory[] = [];\n  const allSemantic: ExtractedSemanticMemory[] = [];\n  const allNotes: string[] = [];\n\n  for (const result of results) {\n    allEpisodic.push(...result.episodicMemories);\n    allSemantic.push(...result.semanticMemories);\n    allNotes.push(...result.processingNotes);\n  }\n\n  // Deduplicate semantic memories by key (keep highest confidence)\n  const semanticByKey = new Map<string, ExtractedSemanticMemory>();\n  for (const mem of allSemantic) {\n    const existing = semanticByKey.get(mem.key);\n    if (!existing || mem.confidence > existing.confidence) {\n      semanticByKey.set(mem.key, mem);\n    }\n  }\n\n  return {\n    episodicMemories: allEpisodic,\n    semanticMemories: Array.from(semanticByKey.values()),\n    summary: `Processed ${filename} in ${results.length} chunks`,\n    processingNotes: allNotes,\n  };\n}\n"],"names":[],"mappings":"urCAAO,OAAM,EACT,YAAY,CAAW,CAAE,CAAE,CAC3B,MAAM,CAAU,CAAE,CAAU,CAAgB,CAAE,OAAO,QAAQ,OAAO,CAAC,KAAO,CAC5E,SAAS,CAAa,CAAE,CAAU,CAAgB,CAAE,OAAO,QAAQ,OAAO,CAAC,KAAO,CACtF,uCAEmB,CACf,KAAM,CACF,aAAc,oBACd,UAAW,iBACX,OAAQ,cACR,mBAAoB,0BACpB,0BAA2B,iCAC3B,eAAgB,sBAChB,sBAAuB,6BACvB,kBAAmB,wBACvB,EACA,WAAY,CACR,YAAa,wBACjB,EACA,IAAK,CACD,aAAc,mBACd,mBAAoB,yBACpB,gBAAiB,sBACjB,eAAgB,qBAChB,eAAgB,qBAChB,UAAW,eACf,EACA,KAAM,CACF,cAAe,qBACf,YAAa,mBACb,WAAY,iBAChB,EACA,SAAU,CACN,KAAM,eACV,EACA,iBAAkB,CACd,KAAM,wBACN,kBAAmB,qCACnB,aAAc,gCACd,cAAe,gCACnB,EACA,SAAU,CACN,KAAM,gBACN,WAAY,sBACZ,YAAa,uBACb,gBAAiB,2BACjB,oBAAqB,+BACrB,iBAAkB,4BAClB,eAAgB,0BAChB,mBAAoB,8BACpB,eAAgB,yBACpB,EACA,WAAY,CACR,KAAM,kBACN,YAAa,yBACb,cAAe,2BACf,kBAAmB,+BACnB,cAAe,2BACf,kBAAmB,+BACnB,oBAAqB,gCACzB,EACA,aAAc,CACV,KAAM,oBACN,OAAQ,sBACR,OAAQ,sBACR,UAAW,yBACX,YAAa,2BACb,UAAW,yBACX,UAAW,wBACf,EACA,WAAY,CACR,QAAS,qBACT,oBAAqB,gCACzB,EACA,OAAQ,CACJ,UAAW,mBACX,WAAY,oBACZ,SAAU,kBACV,YAAa,qBACb,YAAa,qBACb,SAAU,kBACV,SAAU,kBACV,QAAS,iBACT,WAAY,oBACZ,WAAY,oBACZ,SAAU,kBACV,UAAW,kBACf,EACA,aAAc,CACV,UAAW,yBACX,aAAc,4BACd,WAAY,0BACZ,aAAc,4BACd,gBAAiB,+BACjB,eAAgB,8BAChB,eAAgB,8BAChB,QAAS,uBACT,QAAS,uBACT,WAAY,yBAChB,EACA,QAAS,CACL,qBAAsB,+BACtB,UAAW,oBACX,WAAY,qBACZ,aAAc,sBAClB,EACA,UAAW,CACP,WAAY,uBACZ,cAAe,0BACf,eAAgB,2BAChB,qBAAsB,iCACtB,UAAW,sBACX,qBAAsB,iCACtB,iBAAkB,4BACtB,EACA,SAAU,CACN,eAAgB,0BAChB,wBAAyB,mCACzB,eAAgB,0BAChB,kBAAmB,6BACnB,cAAe,yBACf,eAAgB,0BAChB,eAAgB,0BAChB,eAAgB,0BAChB,eAAgB,yBACpB,EACA,cAAe,CACX,iBAAkB,iCAClB,mBAAoB,mCACpB,kBAAmB,kCACnB,qBAAsB,qCACtB,wBAAyB,wCACzB,aAAc,4BAClB,EACA,QAAS,CACL,iBAAkB,2BAClB,eAAgB,yBAChB,uBAAwB,iCACxB,eAAgB,wBACpB,CAEJ,6BC7IA,EAAA,CAAA,CAAA,OAWO,IAAM,EAAc,UAChB,CACH,GAAI,eACJ,UAAW,QACX,SAAU,WACV,eAAgB,CAAC,CAAE,aAAc,mBAAoB,EAAE,CAC3D,gBAfgB,KACT,CACH,OAAQ,eACR,UAAW,kBACX,SAAU,SAAY,aACtB,iBAAkB,IAAM,CAAC,EAAC,CAAC,CAC/B,kBAYuB,CACvB,MAAO,CACH,QAAS,SAAY,GACzB,CACJ,6BClBA,IAAA,EAAA,EAAA,CAAA,CAAA,QAeA,IAAI,EAA8B,KAClC,SAAS,IAIP,OAHI,AAAC,IACH,EAAe,AAfnB,QAcqB,CAdZ,EACP,IAAM,EAAS,QAAQ,GAAG,CAAC,eAAe,CAC1C,GAAI,CAAC,EACH,MAAM,AAAI,AADC,MACK,oDAElB,GAAI,EAAO,MAAM,CAAG,GAClB,CADsB,KAChB,AAAI,MAAM,uDAElB,OAAO,CACT,GAMmB,EAEV,CACT,CAwBO,SAAS,EAAe,CAAgB,CAAE,CAAY,EAC3D,IAAM,EAVC,EAAA,OAAM,CAUK,AATf,UAAU,CAAC,SAAU,KACrB,MAAM,CAAC,AAQqB,GAP5B,MAAM,CAAC,OAQJ,EAAc,OAAO,IAAI,CAAC,GAC1B,EAAa,OAAO,IAAI,CAAC,UAE/B,AAAI,EAAY,MAAM,GAAK,EAAW,MAAM,EAAE,AAIvC,EAAA,OAAM,CAAC,eAAe,CAAC,EAAa,EAC7C,CAcO,SAAS,EAAY,CAAuB,EACjD,IAAM,EAAa,OAAO,IAAI,CAAC,KAAK,SAAS,CAAC,IAAU,QAAQ,CAAC,aAC3D,EAAY,EAAA,OAAM,CACrB,UAAU,CAAC,SAAU,KACrB,MAAM,CAAC,GACP,MAAM,CAAC,aACV,MAAO,CAAA,EAAG,EAAW,CAAC,EAAE,EAAA,CAAW,AACrC,CAKO,SAAS,EAAc,CAAyB,EACrD,GAAI,CAAC,EAAO,OAAO,KAEnB,IAAM,EAAQ,EAAM,KAAK,CAAC,KAC1B,GAAqB,IAAjB,EAAM,MAAM,CAAQ,OAAO,KAE/B,GAAM,CAAC,EAAY,EAAU,CAAG,EAG1B,EAAc,EAAA,OAAM,CACvB,UAAU,CAAC,SAAU,KACrB,MAAM,CAAC,GACP,MAAM,CAAC,aAEJ,EAAY,OAAO,IAAI,CAAC,GACxB,EAAiB,OAAO,IAAI,CAAC,GAEnC,GAAI,EAAU,MAAM,GAAK,EAAe,MAAM,EAC1C,CAAC,EAAA,OAAM,CAAC,eAAe,CAAC,EAAW,GADS,OAAO,KAIvD,EAHwD,CAGpD,CACF,IAAM,CAJuD,CAI7C,KAAK,KAAK,CAAC,OAAO,IAAI,CAAC,EAAY,aAAa,QAAQ,IAGxE,GAAI,KAAK,GAAG,GAAK,EAAQ,GAAG,CAAE,OAAO,KAErC,OAAO,CACT,CAAE,KAAM,CACN,OAAO,IACT,CACF,CAKO,SAAS,EAAmB,CAAgB,EACjD,OAAO,EAAY,CACjB,KAAM,QACN,QAAS,EACT,IAAK,KAAK,GAAG,GA5Fc,EA4FT,GACpB,AA7FkC,EA8FpC,CAKO,EAnGkC,KAAK,EAmG9B,EAAkB,CAAgB,EAChD,OAAO,EAAY,CACjB,KAAM,OACN,QAAS,EACT,IAAK,KAAK,GAAG,KAAK,IACpB,EACF,CAKO,SAAS,EAAkB,CAAwB,EACxD,OAAO,EAAY,CACjB,KAAM,OACN,QAAS,EACT,IAAK,KAAK,GAAG,GAjHa,EAiHR,EAjHY,EAkHhC,EACF,CAKO,AAxHgC,KAAK,IAwH5B,CAxHiC,CAwHf,CAAgB,EAChD,MAAO,GAAG,WAAqB,GAAU,AAC3C,CAKO,SAAS,EAAsB,CAAgB,EACpD,MAAO,UAAU,IAAI,CAAC,EACxB,uBAvI4B,8BAED,0OCtB3B,IAAA,EAAA,EAAA,CAAA,CAAA,OAqBO,OAAM,EACH,OAAkC,IAAK,AAE/C,aAAY,CAAkB,CAAE,CAC9B,MAAM,EAAM,GAAa,QAAQ,GAAG,CAAC,sBAAsB,AACvD,KAAK,AACP,IAAI,CAAC,MAAM,CAAG,IAAI,EAAA,gBAAgB,CAAC,EAAA,CAEvC,CAEQ,WAA8B,CACpC,GAAI,CAAC,IAAI,CAAC,MAAM,CAAE,CAChB,IAAM,EAAM,QAAQ,GAAG,CAAC,sBAAsB,CAC9C,GAAI,CAAC,EACH,GADQ,GACF,AAAI,MAAM,yCAElB,IAAI,CAAC,MAAM,CAAG,IAAI,EAAA,gBAAgB,CAAC,EACrC,CACA,OAAO,IAAI,CAAC,MAAM,AACpB,CAKQ,UAAU,CAAY,CAAE,CAE9B,GAAI,EAAA,GAAG,CAAE,CACP,IAAM,EAAQ,EAAK,KAAK,CAAC,KACrB,EAAW,EAAA,GAAG,CAClB,IAAK,IAAM,KAAQ,EACb,IACF,AAFsB,CACf,CACD,CAAG,CAAC,EAAA,AAAK,EAGnB,GAAI,EAAK,OAAO,CAClB,CAEA,OAAO,CACT,CAUA,MAAM,qBACJ,CAAc,CACd,CAAa,CACb,EAA+B,CAAC,CAAC,CACJ,CAC7B,GAAM,OACJ,EAAQ,EAAE,iBACV,GAAkB,CAAI,iBACtB,GAAkB,CAAI,WACtB,CAAS,CACV,CAAG,EAGE,CAAC,EAAU,EAAS,CAAG,MAAM,QAAQ,GAAG,CAAC,CAC7C,EACI,IAAI,CAAC,sBAAsB,CAAC,EAAQ,EAAO,EAAW,GACtD,EAAE,CACN,EACI,IAAI,CAAC,oBAAoB,CAAC,EAAQ,IAAI,CAAC,iBAAiB,CAAC,IACzD,EAAE,CACP,EAGK,EAAiB,IAAI,CAAC,mBAAmB,CAAC,EAAU,GAE1D,MAAO,UAAE,WAAU,iBAAU,CAAe,CAC9C,CAKA,MAAM,uBACJ,CAAc,CACd,CAAa,CACb,CAAiC,CACjC,EAAgB,EAAE,CACS,CAK3B,OAJgB,AAIT,MAJe,IAAI,CAAC,SAAS,GAAG,KAAK,CAC1C,IAAI,CAAC,SAAS,CAAC,2BACf,QAAE,QAAQ,YAAO,QAAW,CAAM,EAGtC,CAKA,MAAM,qBACJ,CAAc,CACd,CAA8B,CACH,CAK3B,OAJgB,AAIT,MAJe,IAAI,CAAC,SAAS,GAAG,KAAK,CAC1C,IAAI,CAAC,SAAS,CAAC,oCACf,CAAE,oBAAQ,CAAW,EAGzB,CAKA,MAAM,uBAAuB,CAAc,CAA6B,CAKtE,OAJgB,AAIT,MAJe,IAAI,CAAC,SAAS,GAAG,KAAK,CAC1C,IAAI,CAAC,SAAS,CAAC,2BACf,QAAE,CAAO,EAGb,CAKA,MAAM,kBACJ,CAAc,CACd,CAAiC,CACjC,EAAgB,EAAE,CACS,CAK3B,OAAO,AAJS,MAAM,IAAI,CAAC,SAAS,GAAG,KAAK,CAC1C,IAAI,CAAC,SAAS,CAAC,8BACf,QAAE,YAAQ,QAAW,CAAM,EAG/B,CASA,MAAM,oBACJ,CAAc,CACd,CAAe,CACf,CAA8B,CAC9B,CAAkB,CAClB,CAAiC,CACjC,CAOC,CACgC,CACjC,OAAO,MAAM,IAAI,CAAC,SAAS,GAAG,QAAQ,CACpC,IAAI,CAAC,SAAS,CAAC,0BACf,QAAE,YAAQ,UAAW,aAAS,EAAY,aAAY,UAAS,EAEnE,CAKA,MAAM,qBACJ,CAAc,CACd,CAA0B,CAC1B,CAAW,CACX,CAAa,CACb,CAAkB,CAClB,CAAc,CACmB,CACjC,OAAO,MAAM,IAAI,CAAC,SAAS,GAAG,QAAQ,CACpC,IAAI,CAAC,SAAS,CAAC,2BACf,QAAE,WAAQ,MAAU,QAAK,aAAO,EAAY,QAAO,EAEvD,CASA,MAAM,mBACJ,CAAc,CACd,CAAwB,CACxB,CAAiC,CAClB,CACf,IAAM,EAAa,IAAI,CAAC,mBAAmB,CAAC,GAG5C,GAAI,EAAa,GAAK,CACpB,IAAM,EAAa,IAAI,CAAC,mBAAmB,CAAC,GACtC,EAAU,IAAI,CAAC,oBAAoB,CAAC,EAE1C,OAAM,IAAI,CAAC,mBAAmB,CAC5B,EACA,EACA,EACA,EACA,EACA,CAAE,UAAW,EAAY,SAAS,AAAC,EAEvC,CAIA,IAAK,IAAM,KADM,IAAI,CAAC,CACA,SAAU,KADK,CAAC,GAEpC,MAAM,IAAI,CAAC,oBAAoB,CAC7B,EACA,EAAQ,QAAQ,CAChB,EAAQ,GAAG,CACX,EAAQ,KAAK,CACb,EAAQ,UAAU,CAClB,uBAGN,CASA,kBAAkB,CAAa,CAAsB,CACnD,IAAM,EAAiC,EAAE,CACnC,EAAa,EAAM,WAAW,GAgBpC,MAdI,wCAAwC,IAAI,CAAC,IAC/C,EAAW,IAAI,CAAC,EAD4C,YAG1D,kDAAkD,IAAI,CAAC,IACzD,EAAW,IAAI,CAAC,EADsD,OAGpE,2CAA2C,IAAI,CAAC,IAClD,EAAW,IAAI,CAAC,EAD+C,SAG7D,kCAAkC,IAAI,CAAC,IACzC,EAAW,IAAI,CAAC,EADsC,MAKjD,EAAW,MAAM,CAAG,EACvB,EACA,CAAC,aAAc,QAAS,UAAU,AACxC,CAKA,oBACE,CAA0B,CAC1B,CAA0B,CAClB,CACR,IAAM,EAAkB,EAAE,CAG1B,GAAI,EAAS,MAAM,CAAG,EAAG,CACvB,IAAM,EAAkB,EACrB,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,UAAU,CAAG,EAAE,UAAU,EAC1C,KAAK,CAAC,EAAG,GACT,GAAG,CAAC,AAAC,GAAM,CAAC,EAAE,EAAE,EAAE,QAAQ,CAAC,EAAE,EAAE,EAAE,KAAK,CAAA,CAAE,EACxC,IAAI,CAAC,MACR,EAAM,IAAI,CAAC,CAAC;AAAe,EAAE,EAAA,CAAiB,CAChD,CAGA,GAAI,EAAS,MAAM,CAAG,EAAG,CACvB,IAAM,EAAkB,EACrB,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,UAAU,CAAG,EAAE,UAAU,EAC1C,KAAK,CAAC,EAAG,GACT,GAAG,CAAC,AAAC,GAAM,CAAC,GAAG,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,EAAE,OAAO,CAAA,CAAE,EAC7C,IAAI,CAAC,MACR,EAAM,IAAI,CAAC,CAAC;AAAiB,EAAE,EAAA,CAAiB,CAClD,CAEA,OAAO,EAAM,IAAI,CAAC,OACpB,CAKA,oBAAoB,CAAwB,CAAU,CACpD,IAAI,EAAQ,GA4BZ,EA5BiB,IAIf,cAJiC,oCAIiB,IAAI,CACpD,EAAY,WAAW,GAEzB,CACA,GAAS,EAAA,EAIP,EAAY,SAAS,CAAC,MAAM,CAAG,GAAG,AACpC,IAAS,GAAA,EAKT,2CAA2C,IAAI,CAAC,EAAY,WAAW,GACvE,CACA,GAAS,EAAA,EAIP,EAAY,SAAS,CAAC,IAAI,CAAC,AAAC,GAAM,uBAAuB,IAAI,CAAC,KAAK,AACrE,IAAS,GAAA,EAGJ,KAAK,GAAG,CAAC,EAAO,EACzB,CAKA,oBAAoB,CAAwB,CAAsB,CAChE,IAAM,EAAM,EAAY,WAAW,CAAC,WAAW,SAG/C,AAAI,iDAAiD,IAAI,CAAC,GACjD,GADuD,QAK5D,iDAAiD,IAAI,CAAC,GACjD,GADuD,UAK5D,4CAA4C,IAAI,CAAC,GAC5C,GADkD,QAMzD,EAAY,SAAS,CAAC,IAAI,CAAC,AAAC,GAC1B,6CAA6C,IAAI,CAAC,IAG7C,CADP,WAIK,aACT,CAKA,qBAAqB,CAAwB,CAAU,CAErD,IAAM,EACJ,EAAY,WAAW,CAAC,MAAM,CAAG,IAC7B,EAAY,WAAW,CAAC,KAAK,CAAC,EAAG,KAAO,MACxC,EAAY,WAAW,QAE7B,AAAI,EAAY,SAAS,CAAC,MAAM,CAAG,EAC1B,CAD6B,AAC5B,OAAO,EAAE,EAAS,WAAW,EAAE,EAAY,SAAS,CAAC,IAAI,CAAC,MAAA,CAAO,CAEpE,CAAC,OAAO,EAAE,EAAS,CAAC,CAAC,AAC9B,CAKA,gBAAgB,CAAwB,CAAsB,CAC5D,IAAM,EAA+B,EAAE,CACjC,EAAM,EAAY,WAAW,CAAC,WAAW,GAgC/C,MA7BI,kDAAkD,IAAI,CAAC,IACzD,EAD+D,AACtD,IAAI,CAAC,CACZ,SAAU,aACV,IAAK,CAAC,KAAK,EAAE,KAAK,GAAG,GAAA,CAAI,CACzB,MAAO,EAAY,WAAW,CAAC,KAAK,CAAC,EAAG,KACxC,WAAY,EACd,GAIE,uDAAuD,IAAI,CAAC,IAC9D,EADoE,AAC3D,IAAI,CAAC,CACZ,SAAU,QACV,IAAK,CAAC,MAAM,EAAE,KAAK,GAAG,GAAA,CAAI,CAC1B,MAAO,EAAY,WAAW,CAAC,KAAK,CAAC,EAAG,KACxC,WAAY,EACd,GAIE,2CAA2C,IAAI,CAAC,IAClD,EADwD,AAC/C,IAAI,CAAC,CACZ,SAAU,UACV,IAAK,CAAC,QAAQ,EAAE,KAAK,GAAG,GAAA,CAAI,CAC5B,MAAO,EAAY,WAAW,CAAC,KAAK,CAAC,EAAG,KACxC,WAAY,EACd,GAGK,CACT,CASA,MAAM,qBACJ,CAAgC,CAChC,CAAc,CACC,CACf,MAAM,IAAI,CAAC,SAAS,GAAG,QAAQ,CAC7B,IAAI,CAAC,SAAS,CAAC,2BACf,UAAE,SAAU,CAAO,EAEvB,CAKA,MAAM,qBACJ,CAAgC,CAChC,CAAc,CACC,CACf,MAAM,IAAI,CAAC,SAAS,GAAG,QAAQ,CAC7B,IAAI,CAAC,SAAS,CAAC,2BACf,UAAE,SAAU,CAAO,EAEvB,CAKA,MAAM,SAAS,CAAc,CAAE,CAC7B,OAAO,MAAM,IAAI,CAAC,SAAS,GAAG,KAAK,CACjC,IAAI,CAAC,SAAS,CAAC,2BACf,QAAE,CAAO,EAEb,CACF,CAGA,IAAI,EAA8C,KAE3C,SAAS,IAId,OAHI,AAAC,IACH,EAAwB,IAAI,CAAA,EAEvB,CACT,SAJ8B,qDC5b9B,IAAM,EAA2B,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;qDAoCmB,CAAC,CAKtD,eAAe,EACb,CAAoB,CACpB,CAAkB,EAElB,IAAM,EAAS,QAAQ,GAAG,CAAC,cAAc,CACzC,GAAI,CAAC,EACH,MADW,AACL,AAAI,MAAM,iCAGlB,IAAM,EAAW,MAAM,MAAM,6CAA8C,CACzE,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,cAAe,CAAC,OAAO,EAAE,EAAA,CAAQ,AACnC,EACA,KAAM,KAAK,SAAS,CAAC,CACnB,MAAO,SACP,WAAY,KACZ,gBAAiB,CAAE,KAAM,aAAc,EACvC,SAAU,CACR,CAAE,KAAM,SAAU,QAAS,CAAa,EACxC,CAAE,KAAM,OAAQ,QAAS,CAAW,EACrC,AACH,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,kBAAkB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAO,CACnE,CAEA,IAAM,EAAO,MAAM,EAAS,IAAI,GAChC,OAAO,EAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAW,EAChD,CAKO,eAAe,EACpB,CAAe,CACf,CAAgB,CAChB,EAGI,CAAC,CAAC,EAEN,GAAM,CAAE,cAAc,EAAE,CAAE,cAAc,EAAE,CAAE,CAAG,EAGzC,EACJ,EAAQ,MAAM,CAAG,IACb,EAAQ,KAAK,CAAC,EAAG,KAAS,6BAC1B,EAEA,EAAa,CAAC,yCAAyC,EAAE,EAAS;;;AAG1E,EAAE,iBAAiB;;;cAGL,EAAE,EAAY,uBAAuB,EAAE,EAAY;;;;;;;;;;;;;;;;;;;;;;;CAuBhE,CAAC,CAEA,GAAI,KA+BJ,EACA,EA/BE,EA8BuB,IACT,EA/BR,EAAc,MAAM,EAAW,EAA0B,GAE/D,GAAI,CAAC,EACH,MAAM,AAAI,KADM,CACA,uBAOlB,OAAO,EAHQ,KAAK,KAAK,CAAC,KAGa,EAuBnC,EAA2C,CAC/C,CAxB+B,aAyB/B,WACA,aACA,WACA,YACD,CAEK,EAA8C,CAClD,aACA,QACA,UACA,OACD,CAuCM,CACL,iBArCuB,CAAC,EAAO,gBAAgB,EAAI,EAAA,AAAE,EACpD,MAAM,CAAC,AAAC,GAAM,GAA0B,UAArB,OAAO,EAAE,OAAO,EAAiB,EAAE,OAAO,CAAC,MAAM,CAAG,IACvE,GAAG,CAAC,AAAC,IAAM,AAAC,CACX,QAAS,EAAE,OAAO,CAAC,KAAK,CAAC,EAAG,KAC5B,WAAY,EAAmB,QAAQ,CAAC,EAAE,UAAU,EAChD,EAAE,UAAU,CACZ,cACJ,WAAY,KAAK,GAAG,CAAC,EAAG,KAAK,GAAG,CAAC,EAAG,OAAO,EAAE,UAAU,GAAK,KAC5D,QAAS,EAAE,OAAO,CAAG,OAAO,EAAE,OAAO,EAAE,KAAK,CAAC,EAAG,KAAO,MACzD,CAAC,GA6BD,iBA1BuB,CAAC,EAAO,gBAAgB,EAAI,EAAA,AAAE,EACpD,MAAM,CACL,AAAC,GACC,GACiB,UAAjB,OAAO,EAAE,GAAG,EACZ,EAAE,GAAG,CAAC,MAAM,CAAG,GACI,UAAnB,OAAO,EAAE,KAAK,EACd,EAAE,KAAK,CAAC,MAAM,CAAG,GAEpB,GAAG,CAAC,AAAC,IAAM,AAAC,CACX,SAAU,EAAwB,QAAQ,CAAC,EAAE,QAAQ,EACjD,EAAE,QAAQ,CACV,OACJ,IAAK,EAAE,GAAG,CACP,WAAW,GACX,OAAO,CAAC,cAAe,KACvB,KAAK,CAAC,EAAG,IACZ,MAAO,EAAE,KAAK,CAAC,KAAK,CAAC,EAAG,KACxB,WAAY,KAAK,GAAG,CAAC,EAAG,KAAK,GAAG,CAAC,EAAG,OAAO,EAAE,UAAU,GAAK,KAC5D,OAAQ,EAAE,MAAM,CACZ,OAAO,EAAE,MAAM,EAAE,KAAK,CAAC,EAAG,KAC1B,CAAC,eAAe,EAAE,EAAA,CAAU,CAClC,CAAC,EAKD,QAAS,EAAO,OAAO,EAAI,CAAC,UAAU,EAAE,EAAA,CAAU,CAClD,gBAAiB,MAAM,OAAO,CAAC,EAAO,eAAe,EACjD,EAAO,eAAe,CAAC,GAAG,CAAC,AAAC,GAAM,OAAO,IACzC,EAAE,AACR,CAjFA,CAAE,MAAO,EAAO,CAId,OAHA,QAAQ,KAAK,CAAC,sBAAuB,GAG9B,CACL,iBAAkB,EAAE,CACpB,iBAAkB,EAAE,CACpB,QAAS,CAAC,kBAAkB,EAAE,EAAA,CAAU,CACxC,gBAAiB,CACf,CAAC,OAAO,EAAE,aAAiB,MAAQ,EAAM,OAAO,CAAG,gBAAA,CAAiB,CACrE,AACH,CACF,CACF,CA0EO,eAAe,EACpB,CAAe,CACf,CAAgB,CAChB,EAAoB,GAAK,EAGzB,GAAI,EAAQ,MAAM,EAAI,EACpB,OAAO,EADwB,AACF,EAAS,GAIxC,IAAM,EAAmB,EAAE,CACvB,EAAe,GAGnB,IAAK,IAAM,KADQ,EAAQ,CACR,IADa,CAAC,MACF,GACzB,EAAa,MAAM,CAAG,EAAK,MAAM,CAAG,GAClC,GACF,EAAO,GAFwC,CAEpC,CAAC,GAEd,CAHkB,CAGH,GAEf,GAAgB,CAAC,EAAe,OAAS,EAAA,CAAE,CAAI,CAG/C,IACF,EAAO,IAAI,CAAC,GAId,AALkB,IAKZ,EAA+B,EAAE,CACvC,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAM,CAAE,IAAK,CACtC,IAAM,EAAgB,CAAA,EAAG,EAAS,OAAO,EAAE,EAAI,EAAE,CAAC,EAAE,EAAO,MAAM,CAAC,CAAC,CAAC,CAC9D,EAAS,MAAM,EAAsB,CAAM,CAAC,EAAE,CAAE,GACtD,EAAQ,IAAI,CAAC,EACf,CAGA,OAAO,AAMT,SAAS,AACP,CAA4B,CAC5B,CAAgB,EAEhB,IAAM,EAAyC,EAAE,CAC3C,EAAyC,EAAE,CAC3C,EAAqB,EAAE,CAE7B,IAAK,IAAM,KAAU,EACnB,EAAY,IADgB,AACZ,IAAI,EAAO,gBAAgB,EAC3C,EAAY,IAAI,IAAI,EAAO,gBAAgB,EAC3C,EAAS,IAAI,IAAI,EAAO,eAAe,EAIzC,IAAM,EAAgB,IAAI,IAC1B,IAAK,IAAM,KAAO,EAAa,CAC7B,IAAM,EAAW,EAAc,GAAG,CAAC,EAAI,GAAG,GACtC,CAAC,GAAY,EAAI,UAAU,CAAG,EAAS,UAAA,AAAU,EAAE,CACrD,EAAc,GAAG,CAAC,EAAI,GAAG,CAAE,EAE/B,CAEA,MAAO,CACL,iBAAkB,EAClB,iBAAkB,MAAM,IAAI,CAAC,EAAc,MAAM,IACjD,QAAS,CAAC,UAAU,EAAE,EAAS,IAAI,EAAE,EAAQ,MAAM,CAAC,OAAO,CAAC,CAC5D,gBAAiB,CACnB,CACF,EAnC+B,EAAS,EACxC"}