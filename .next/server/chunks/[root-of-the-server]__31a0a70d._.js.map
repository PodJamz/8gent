{"version":3,"sources":["../../../src/lib/lynkr/client.ts","../../../src/lib/ollama/client.ts","../../../src/app/api/health/providers/route.ts","../../../node_modules/.pnpm/next%4016.1.2_%40babel%2Bcore%407.29.0_%40opentelemetry%2Bapi%401.9.0_react-dom%4019.2.3_react%4019.2.3__react%4019.2.3/node_modules/next/dist/esm/build/templates/app-route.js"],"sourcesContent":["/**\n * Lynkr Client - Universal LLM Proxy Integration\n *\n * Lynkr is a self-hosted proxy that routes AI requests to:\n * - Local models (Ollama, llama.cpp, LM Studio)\n * - Cloud providers (OpenRouter, Anthropic, OpenAI, AWS Bedrock, etc.)\n *\n * This client connects to a Lynkr instance (local or via tunnel) and\n * sends requests in Anthropic format, which Lynkr converts as needed.\n *\n * SECURITY:\n * - API key required (min 32 chars for production)\n * - SSRF protection blocks internal IPs\n * - Audit logging for all requests\n */\n\n// ============================================================================\n// Security Constants\n// ============================================================================\n\n/** Minimum API key length for production use */\nconst MIN_API_KEY_LENGTH = 32;\n\n/** Internal IP patterns that should be blocked (SSRF protection) */\nconst BLOCKED_IP_PATTERNS = [\n  /^127\\./,                           // Loopback\n  /^10\\./,                            // Private Class A\n  /^172\\.(1[6-9]|2[0-9]|3[0-1])\\./,   // Private Class B\n  /^192\\.168\\./,                      // Private Class C\n  /^169\\.254\\./,                      // Link-local\n  /^0\\./,                             // \"This\" network\n  /^100\\.(6[4-9]|[7-9][0-9]|1[0-2][0-7])\\./,  // Carrier-grade NAT\n  /^::1$/,                            // IPv6 loopback\n  /^fc00:/i,                          // IPv6 unique local\n  /^fe80:/i,                          // IPv6 link-local\n  /^localhost$/i,                     // Hostname\n  /^.*\\.local$/i,                     // mDNS\n  /metadata\\.google\\.internal/i,      // GCP metadata\n  /169\\.254\\.169\\.254/,               // AWS/GCP/Azure metadata\n];\n\n/** Allowed URL schemes */\nconst ALLOWED_SCHEMES = ['https:', 'http:'];\n\nexport interface LynkrConfig {\n  /** Lynkr endpoint URL (e.g., http://localhost:8081 or https://tunnel.example.com) */\n  baseUrl: string;\n  /** API key - required for production (min 32 chars) */\n  apiKey?: string;\n  /** Request timeout in ms */\n  timeout?: number;\n  /** Default model to use (pinned to gpt-oss:20b) */\n  defaultModel?: string;\n  /** Skip API key validation (for local dev only) */\n  skipApiKeyValidation?: boolean;\n  /** Skip SSRF validation (for local dev only) */\n  skipSsrfValidation?: boolean;\n}\n\nexport interface LynkrMessage {\n  role: 'user' | 'assistant' | 'system';\n  content: string;\n}\n\nexport interface LynkrTool {\n  name: string;\n  description: string;\n  input_schema: {\n    type: 'object';\n    properties: Record<string, unknown>;\n    required?: string[];\n  };\n}\n\nexport interface LynkrChatRequest {\n  model: string;\n  messages: LynkrMessage[];\n  max_tokens?: number;\n  temperature?: number;\n  tools?: LynkrTool[];\n  system?: string;\n  stream?: boolean;\n}\n\nexport interface LynkrToolUse {\n  type: 'tool_use';\n  id: string;\n  name: string;\n  input: Record<string, unknown>;\n}\n\nexport interface LynkrTextContent {\n  type: 'text';\n  text: string;\n}\n\nexport type LynkrContentBlock = LynkrTextContent | LynkrToolUse;\n\nexport interface LynkrChatResponse {\n  id: string;\n  type: 'message';\n  role: 'assistant';\n  model: string;\n  content: LynkrContentBlock[];\n  stop_reason: 'end_turn' | 'tool_use' | 'max_tokens' | 'stop_sequence';\n  stop_sequence?: string | null;\n  usage: {\n    input_tokens: number;\n    output_tokens: number;\n    cache_creation_input_tokens?: number;\n    cache_read_input_tokens?: number;\n  };\n}\n\nexport interface LynkrHealthStatus {\n  connected: boolean;\n  latencyMs?: number;\n  error?: string;\n  provider?: string;\n  model?: string;\n  version?: string;\n  features?: {\n    memory?: boolean;\n    tools?: boolean;\n    streaming?: boolean;\n    embeddings?: boolean;\n  };\n}\n\nexport interface LynkrMetrics {\n  requestCount: number;\n  totalTokens: number;\n  avgLatency: number;\n  routingDecisions: {\n    local: number;\n    cloud: number;\n  };\n}\n\n// ============================================================================\n// Security Validation\n// ============================================================================\n\nexport interface LynkrSecurityError extends Error {\n  code: 'INVALID_API_KEY' | 'SSRF_BLOCKED' | 'INVALID_URL';\n}\n\n/**\n * Validate API key meets minimum security requirements\n */\nexport function validateApiKey(apiKey: string | undefined, skipValidation?: boolean): void {\n  if (skipValidation) return;\n\n  if (!apiKey || apiKey.length < MIN_API_KEY_LENGTH) {\n    const error = new Error(\n      `Lynkr API key must be at least ${MIN_API_KEY_LENGTH} characters. ` +\n      `Generate with: openssl rand -base64 48`\n    ) as LynkrSecurityError;\n    error.code = 'INVALID_API_KEY';\n    throw error;\n  }\n\n  // Block obviously insecure default keys\n  const insecureKeys = ['lynkr-local', 'dummy', 'test', 'local', 'dev'];\n  if (insecureKeys.includes(apiKey.toLowerCase())) {\n    const error = new Error(\n      'Lynkr API key cannot be a default/test value. Generate a secure key.'\n    ) as LynkrSecurityError;\n    error.code = 'INVALID_API_KEY';\n    throw error;\n  }\n}\n\n/**\n * Validate URL is not targeting internal networks (SSRF protection)\n */\nexport function validateUrlSafety(urlString: string, skipValidation?: boolean): void {\n  if (skipValidation) return;\n\n  try {\n    const url = new URL(urlString);\n\n    // Check scheme\n    if (!ALLOWED_SCHEMES.includes(url.protocol)) {\n      const error = new Error(\n        `URL scheme ${url.protocol} not allowed. Use http: or https:`\n      ) as LynkrSecurityError;\n      error.code = 'INVALID_URL';\n      throw error;\n    }\n\n    // Check hostname against blocked patterns\n    const hostname = url.hostname;\n    for (const pattern of BLOCKED_IP_PATTERNS) {\n      if (pattern.test(hostname)) {\n        const error = new Error(\n          `SSRF protection: ${hostname} is not allowed. Internal IPs are blocked.`\n        ) as LynkrSecurityError;\n        error.code = 'SSRF_BLOCKED';\n        throw error;\n      }\n    }\n  } catch (e) {\n    if ((e as LynkrSecurityError).code) throw e;\n\n    const error = new Error(`Invalid URL: ${urlString}`) as LynkrSecurityError;\n    error.code = 'INVALID_URL';\n    throw error;\n  }\n}\n\n/**\n * Check if running in local development mode\n */\nfunction isLocalDev(): boolean {\n  if (typeof window !== 'undefined') return false;\n  return process.env.NODE_ENV === 'development' ||\n         process.env.LYNKR_SKIP_SECURITY === 'true';\n}\n\n// ============================================================================\n// Audit Logging\n// ============================================================================\n\nexport interface LynkrAuditLog {\n  timestamp: number;\n  action: 'chat' | 'stream' | 'health' | 'metrics';\n  model?: string;\n  baseUrl: string;\n  latencyMs?: number;\n  success: boolean;\n  error?: string;\n  inputTokens?: number;\n  outputTokens?: number;\n}\n\n/** Audit log callback - set this to capture all Lynkr requests */\nexport let auditLogCallback: ((log: LynkrAuditLog) => void) | null = null;\n\n/**\n * Set the audit log callback for security monitoring\n */\nexport function setAuditLogCallback(callback: ((log: LynkrAuditLog) => void) | null): void {\n  auditLogCallback = callback;\n}\n\nfunction logAudit(log: LynkrAuditLog): void {\n  if (auditLogCallback) {\n    try {\n      auditLogCallback(log);\n    } catch (error) {\n      // Log audit failures to console as fallback - don't lose security events silently\n      console.error('[Lynkr AUDIT FAILURE] Failed to log audit event:', error);\n      console.error('[Lynkr AUDIT FAILURE] Event data:', JSON.stringify(log));\n    }\n  }\n\n  // Also log to console in development\n  if (isLocalDev()) {\n    console.log('[Lynkr Audit]', JSON.stringify(log));\n  }\n}\n\n// ============================================================================\n// Lynkr Client\n// ============================================================================\n\n/**\n * Lynkr Client\n *\n * Connects to a Lynkr proxy instance and sends AI requests.\n * Lynkr handles routing to the appropriate provider (local or cloud).\n *\n * SECURITY FEATURES:\n * - API key validation (min 32 chars)\n * - SSRF protection (blocks internal IPs)\n * - Audit logging for all requests\n */\nexport class LynkrClient {\n  private config: Required<Omit<LynkrConfig, 'skipApiKeyValidation' | 'skipSsrfValidation'>> & {\n    skipApiKeyValidation: boolean;\n    skipSsrfValidation: boolean;\n  };\n\n  constructor(config: LynkrConfig) {\n    const skipSecurity = isLocalDev();\n    const skipApiKeyValidation = config.skipApiKeyValidation ?? skipSecurity;\n    const skipSsrfValidation = config.skipSsrfValidation ?? skipSecurity;\n\n    // Validate security requirements\n    if (!skipApiKeyValidation) {\n      validateApiKey(config.apiKey, false);\n    }\n\n    if (!skipSsrfValidation) {\n      validateUrlSafety(config.baseUrl, false);\n    }\n\n    this.config = {\n      baseUrl: config.baseUrl.replace(/\\/$/, ''), // Remove trailing slash\n      apiKey: config.apiKey ?? '',\n      timeout: config.timeout ?? 120000, // 2 minutes default\n      defaultModel: config.defaultModel ?? 'gpt-oss:20b', // Pinned to local model\n      skipApiKeyValidation,\n      skipSsrfValidation,\n    };\n  }\n\n  /**\n   * Check if Lynkr is healthy and reachable\n   */\n  async checkHealth(): Promise<LynkrHealthStatus> {\n    const start = Date.now();\n\n    try {\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), 5000);\n\n      const response = await fetch(`${this.config.baseUrl}/health`, {\n        method: 'GET',\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeoutId);\n\n      if (!response.ok) {\n        return {\n          connected: false,\n          latencyMs: Date.now() - start,\n          error: `HTTP ${response.status}: ${response.statusText}`,\n        };\n      }\n\n      const data = await response.json();\n\n      return {\n        connected: true,\n        latencyMs: Date.now() - start,\n        provider: data.provider,\n        model: data.model,\n        version: data.version,\n        features: {\n          memory: data.memory?.enabled ?? false,\n          tools: data.tools?.enabled ?? true,\n          streaming: data.streaming?.enabled ?? true,\n          embeddings: data.embeddings?.enabled ?? false,\n        },\n      };\n    } catch (error) {\n      return {\n        connected: false,\n        latencyMs: Date.now() - start,\n        error: error instanceof Error ? error.message : 'Connection failed',\n      };\n    }\n  }\n\n  /**\n   * Get Lynkr metrics\n   */\n  async getMetrics(): Promise<LynkrMetrics | null> {\n    try {\n      const response = await fetch(`${this.config.baseUrl}/metrics`, {\n        method: 'GET',\n        signal: AbortSignal.timeout(5000),\n      });\n\n      if (!response.ok) return null;\n\n      return await response.json();\n    } catch {\n      return null;\n    }\n  }\n\n  /**\n   * Send a chat request through Lynkr\n   * Uses Anthropic message format (Lynkr converts as needed)\n   */\n  async chat(request: Omit<LynkrChatRequest, 'model'> & { model?: string }): Promise<LynkrChatResponse> {\n    const start = Date.now();\n    const model = request.model ?? this.config.defaultModel;\n\n    const body: LynkrChatRequest = {\n      model,\n      messages: request.messages,\n      max_tokens: request.max_tokens ?? 4096,\n      temperature: request.temperature ?? 0.7,\n      tools: request.tools,\n      system: request.system,\n      stream: false,\n    };\n\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), this.config.timeout);\n\n    try {\n      const response = await fetch(`${this.config.baseUrl}/v1/messages`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'x-api-key': this.config.apiKey,\n          'anthropic-version': '2023-06-01',\n        },\n        body: JSON.stringify(body),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeoutId);\n\n      if (!response.ok) {\n        const errorText = await response.text();\n        const error = new Error(`Lynkr request failed: ${response.status} - ${errorText}`);\n\n        logAudit({\n          timestamp: Date.now(),\n          action: 'chat',\n          model,\n          baseUrl: this.config.baseUrl,\n          latencyMs: Date.now() - start,\n          success: false,\n          error: error.message,\n        });\n\n        throw error;\n      }\n\n      const result: LynkrChatResponse = await response.json();\n\n      logAudit({\n        timestamp: Date.now(),\n        action: 'chat',\n        model,\n        baseUrl: this.config.baseUrl,\n        latencyMs: Date.now() - start,\n        success: true,\n        inputTokens: result.usage?.input_tokens,\n        outputTokens: result.usage?.output_tokens,\n      });\n\n      return result;\n    } catch (error) {\n      clearTimeout(timeoutId);\n\n      // Log if not already logged\n      if (!(error instanceof Error && error.message.includes('Lynkr request failed'))) {\n        logAudit({\n          timestamp: Date.now(),\n          action: 'chat',\n          model,\n          baseUrl: this.config.baseUrl,\n          latencyMs: Date.now() - start,\n          success: false,\n          error: error instanceof Error ? error.message : 'Unknown error',\n        });\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Send a streaming chat request through Lynkr\n   * Returns an async generator of content deltas\n   */\n  async *chatStream(\n    request: Omit<LynkrChatRequest, 'model' | 'stream'> & { model?: string }\n  ): AsyncGenerator<{\n    type: 'content_block_delta' | 'message_start' | 'message_stop' | 'content_block_start' | 'content_block_stop';\n    delta?: { type: 'text_delta'; text: string } | { type: 'tool_use'; id: string; name: string; input: string };\n    index?: number;\n    content_block?: LynkrContentBlock;\n    message?: Partial<LynkrChatResponse>;\n  }> {\n    const body: LynkrChatRequest = {\n      model: request.model ?? this.config.defaultModel,\n      messages: request.messages,\n      max_tokens: request.max_tokens ?? 4096,\n      temperature: request.temperature ?? 0.7,\n      tools: request.tools,\n      system: request.system,\n      stream: true,\n    };\n\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), this.config.timeout);\n\n    try {\n      const response = await fetch(`${this.config.baseUrl}/v1/messages`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'x-api-key': this.config.apiKey,\n          'anthropic-version': '2023-06-01',\n        },\n        body: JSON.stringify(body),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeoutId);\n\n      if (!response.ok) {\n        const errorText = await response.text();\n        throw new Error(`Lynkr stream failed: ${response.status} - ${errorText}`);\n      }\n\n      if (!response.body) {\n        throw new Error('No response body for streaming');\n      }\n\n      const reader = response.body.getReader();\n      const decoder = new TextDecoder();\n      let buffer = '';\n\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() ?? '';\n\n        for (const line of lines) {\n          if (line.startsWith('data: ')) {\n            const data = line.slice(6).trim();\n            if (data === '[DONE]') return;\n\n            try {\n              const event = JSON.parse(data);\n              yield event;\n            } catch {\n              // Skip invalid JSON\n            }\n          }\n        }\n      }\n    } catch (error) {\n      clearTimeout(timeoutId);\n      throw error;\n    }\n  }\n\n  /**\n   * Extract text content from a Lynkr response\n   */\n  static extractText(response: LynkrChatResponse): string {\n    return response.content\n      .filter((block): block is LynkrTextContent => block.type === 'text')\n      .map((block) => block.text)\n      .join('');\n  }\n\n  /**\n   * Extract tool calls from a Lynkr response\n   */\n  static extractToolCalls(response: LynkrChatResponse): LynkrToolUse[] {\n    return response.content.filter((block): block is LynkrToolUse => block.type === 'tool_use');\n  }\n\n  /**\n   * Check if response contains tool calls\n   */\n  static hasToolCalls(response: LynkrChatResponse): boolean {\n    return response.stop_reason === 'tool_use' || response.content.some((block) => block.type === 'tool_use');\n  }\n}\n\n/**\n * Get a configured Lynkr client\n *\n * SECURITY: In production, requires:\n * - LYNKR_API_KEY env var with min 32 chars\n * - Non-internal baseUrl (SSRF protection)\n *\n * In development (NODE_ENV=development), security checks are relaxed.\n */\nexport function getLynkrClient(config?: Partial<LynkrConfig>): LynkrClient {\n  // Environment variables are only available on the server\n  const env = typeof window === 'undefined' ? {\n    baseUrl: process.env.LYNKR_BASE_URL,\n    apiKey: process.env.LYNKR_API_KEY,\n    timeout: process.env.LYNKR_TIMEOUT,\n    defaultModel: process.env.LYNKR_DEFAULT_MODEL,\n    skipSecurity: process.env.LYNKR_SKIP_SECURITY === 'true' ||\n                  process.env.NODE_ENV === 'development',\n  } : { skipSecurity: false };\n\n  const skipSecurity = config?.skipApiKeyValidation ?? config?.skipSsrfValidation ?? env.skipSecurity;\n\n  return new LynkrClient({\n    baseUrl: config?.baseUrl ?? env.baseUrl ?? 'http://localhost:8081',\n    apiKey: config?.apiKey ?? env.apiKey,\n    timeout: config?.timeout ?? parseInt(env.timeout ?? '120000', 10),\n    defaultModel: config?.defaultModel ?? env.defaultModel ?? 'gpt-oss:20b', // Pinned to local model\n    skipApiKeyValidation: skipSecurity,\n    skipSsrfValidation: skipSecurity,\n  });\n}\n\n/**\n * Check Lynkr health with a simple function\n *\n * Health checks skip security validation because:\n * 1. They don't require authentication (just checking connectivity)\n * 2. They may use tunnel URLs that would fail SSRF checks\n */\nexport async function checkLynkrHealth(baseUrl?: string): Promise<LynkrHealthStatus> {\n  // Health checks skip security validation - no auth needed for connectivity test\n  const client = getLynkrClient({\n    baseUrl,\n    skipApiKeyValidation: true,\n    skipSsrfValidation: true,\n  });\n  return client.checkHealth();\n}\n","/**\n * Ollama Client - Phase 3 Local LLM Integration\n *\n * Client library for interacting with local Ollama server.\n * Supports chat, generate, model listing, and health checks.\n */\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport interface OllamaConfig {\n  baseUrl: string;\n  timeout?: number; // ms\n  defaultModel?: string;\n}\n\nexport interface OllamaModel {\n  name: string;\n  modified_at: string;\n  size: number;\n  digest: string;\n  details?: {\n    format: string;\n    family: string;\n    parameter_size: string;\n    quantization_level: string;\n  };\n}\n\nexport interface OllamaMessage {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n\nexport interface OllamaChatRequest {\n  model: string;\n  messages: OllamaMessage[];\n  stream?: boolean;\n  options?: {\n    temperature?: number;\n    top_p?: number;\n    top_k?: number;\n    num_predict?: number;\n    stop?: string[];\n  };\n}\n\nexport interface OllamaChatResponse {\n  model: string;\n  created_at: string;\n  message: OllamaMessage;\n  done: boolean;\n  total_duration?: number;\n  load_duration?: number;\n  prompt_eval_count?: number;\n  eval_count?: number;\n  eval_duration?: number;\n}\n\nexport interface OllamaGenerateRequest {\n  model: string;\n  prompt: string;\n  stream?: boolean;\n  system?: string;\n  options?: {\n    temperature?: number;\n    top_p?: number;\n    top_k?: number;\n    num_predict?: number;\n    stop?: string[];\n  };\n}\n\nexport interface OllamaGenerateResponse {\n  model: string;\n  created_at: string;\n  response: string;\n  done: boolean;\n  context?: number[];\n  total_duration?: number;\n  load_duration?: number;\n  prompt_eval_count?: number;\n  eval_count?: number;\n  eval_duration?: number;\n}\n\nexport interface OllamaHealthStatus {\n  connected: boolean;\n  version?: string;\n  models: OllamaModel[];\n  error?: string;\n  latencyMs?: number;\n}\n\n// ============================================================================\n// Client Class\n// ============================================================================\n\nexport class OllamaClient {\n  private baseUrl: string;\n  private timeout: number;\n  private defaultModel: string;\n\n  constructor(config: OllamaConfig) {\n    this.baseUrl = config.baseUrl.replace(/\\/$/, ''); // Remove trailing slash\n    this.timeout = config.timeout ?? 30000;\n    this.defaultModel = config.defaultModel ?? 'gpt-oss:20b';\n  }\n\n  /**\n   * Check if Ollama server is reachable and get available models\n   */\n  async health(): Promise<OllamaHealthStatus> {\n    const start = Date.now();\n\n    try {\n      // Try to list models (this also verifies server is running)\n      const response = await this.fetchWithTimeout(`${this.baseUrl}/api/tags`, {\n        method: 'GET',\n      });\n\n      if (!response.ok) {\n        return {\n          connected: false,\n          models: [],\n          error: `Server returned ${response.status}`,\n          latencyMs: Date.now() - start,\n        };\n      }\n\n      const data = await response.json();\n      const models: OllamaModel[] = data.models || [];\n\n      // Also try to get version\n      let version: string | undefined;\n      try {\n        const versionResponse = await this.fetchWithTimeout(`${this.baseUrl}/api/version`, {\n          method: 'GET',\n        });\n        if (versionResponse.ok) {\n          const versionData = await versionResponse.json();\n          version = versionData.version;\n        }\n      } catch (error) {\n        // Version endpoint might not exist in older versions - log at debug level\n        console.debug('[Ollama] Version endpoint not available:', error);\n      }\n\n      return {\n        connected: true,\n        version,\n        models,\n        latencyMs: Date.now() - start,\n      };\n    } catch (error) {\n      return {\n        connected: false,\n        models: [],\n        error: error instanceof Error ? error.message : 'Connection failed',\n        latencyMs: Date.now() - start,\n      };\n    }\n  }\n\n  /**\n   * List available models\n   */\n  async listModels(): Promise<OllamaModel[]> {\n    const response = await this.fetchWithTimeout(`${this.baseUrl}/api/tags`, {\n      method: 'GET',\n    });\n\n    if (!response.ok) {\n      throw new Error(`Failed to list models: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.models || [];\n  }\n\n  /**\n   * Chat with a model (non-streaming)\n   */\n  async chat(request: OllamaChatRequest): Promise<OllamaChatResponse> {\n    const response = await this.fetchWithTimeout(`${this.baseUrl}/api/chat`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        ...request,\n        model: request.model || this.defaultModel,\n        stream: false,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`Chat failed: ${response.status} - ${error}`);\n    }\n\n    return response.json();\n  }\n\n  /**\n   * Chat with a model (streaming)\n   * Returns an async generator that yields partial responses\n   */\n  async *chatStream(request: OllamaChatRequest): AsyncGenerator<OllamaChatResponse> {\n    const response = await this.fetchWithTimeout(`${this.baseUrl}/api/chat`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        ...request,\n        model: request.model || this.defaultModel,\n        stream: true,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`Chat stream failed: ${response.status} - ${error}`);\n    }\n\n    const reader = response.body?.getReader();\n    if (!reader) {\n      throw new Error('No response body');\n    }\n\n    const decoder = new TextDecoder();\n    let buffer = '';\n\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() || '';\n\n        for (const line of lines) {\n          if (line.trim()) {\n            try {\n              const data = JSON.parse(line) as OllamaChatResponse;\n              yield data;\n            } catch (error) {\n              // Log malformed JSON for debugging but continue processing\n              console.error('[Ollama] Malformed JSON in chat stream:', line.substring(0, 100), error);\n            }\n          }\n        }\n      }\n\n      // Process remaining buffer\n      if (buffer.trim()) {\n        try {\n          const data = JSON.parse(buffer) as OllamaChatResponse;\n          yield data;\n        } catch (error) {\n          // Log malformed JSON for debugging\n          console.error('[Ollama] Malformed JSON in chat buffer:', buffer.substring(0, 100), error);\n        }\n      }\n    } finally {\n      reader.releaseLock();\n    }\n  }\n\n  /**\n   * Generate text (non-streaming)\n   */\n  async generate(request: OllamaGenerateRequest): Promise<OllamaGenerateResponse> {\n    const response = await this.fetchWithTimeout(`${this.baseUrl}/api/generate`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        ...request,\n        model: request.model || this.defaultModel,\n        stream: false,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`Generate failed: ${response.status} - ${error}`);\n    }\n\n    return response.json();\n  }\n\n  /**\n   * Generate text (streaming)\n   */\n  async *generateStream(request: OllamaGenerateRequest): AsyncGenerator<OllamaGenerateResponse> {\n    const response = await this.fetchWithTimeout(`${this.baseUrl}/api/generate`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        ...request,\n        model: request.model || this.defaultModel,\n        stream: true,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`Generate stream failed: ${response.status} - ${error}`);\n    }\n\n    const reader = response.body?.getReader();\n    if (!reader) {\n      throw new Error('No response body');\n    }\n\n    const decoder = new TextDecoder();\n    let buffer = '';\n\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() || '';\n\n        for (const line of lines) {\n          if (line.trim()) {\n            try {\n              const data = JSON.parse(line) as OllamaGenerateResponse;\n              yield data;\n            } catch (error) {\n              // Log malformed JSON for debugging but continue processing\n              console.error('[Ollama] Malformed JSON in generate stream:', line.substring(0, 100), error);\n            }\n          }\n        }\n      }\n\n      // Process remaining buffer\n      if (buffer.trim()) {\n        try {\n          const data = JSON.parse(buffer) as OllamaGenerateResponse;\n          yield data;\n        } catch (error) {\n          // Log malformed JSON for debugging\n          console.error('[Ollama] Malformed JSON in generate buffer:', buffer.substring(0, 100), error);\n        }\n      }\n    } finally {\n      reader.releaseLock();\n    }\n  }\n\n  /**\n   * Pull a model from Ollama registry\n   */\n  async pullModel(modelName: string): Promise<void> {\n    const response = await fetch(`${this.baseUrl}/api/pull`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ name: modelName }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      throw new Error(`Failed to pull model: ${response.status} - ${error}`);\n    }\n\n    // Wait for the model to be pulled (this can take a while)\n    const reader = response.body?.getReader();\n    if (reader) {\n      const decoder = new TextDecoder();\n      while (true) {\n        const { done } = await reader.read();\n        if (done) break;\n      }\n      reader.releaseLock();\n    }\n  }\n\n  /**\n   * Fetch with timeout\n   */\n  private async fetchWithTimeout(url: string, options: RequestInit): Promise<Response> {\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), this.timeout);\n\n    try {\n      const response = await fetch(url, {\n        ...options,\n        signal: controller.signal,\n      });\n      return response;\n    } catch (error) {\n      if (error instanceof Error && error.name === 'AbortError') {\n        throw new Error(`Request timed out after ${this.timeout}ms`);\n      }\n      throw error;\n    } finally {\n      clearTimeout(timeoutId);\n    }\n  }\n}\n\n// ============================================================================\n// Singleton Instance\n// ============================================================================\n\nlet defaultClient: OllamaClient | null = null;\n\n/**\n * Get the default Ollama client\n * Uses OLLAMA_BASE_URL env var or defaults to localhost:11434\n */\nexport function getOllamaClient(config?: Partial<OllamaConfig>): OllamaClient {\n  if (!defaultClient || config) {\n    defaultClient = new OllamaClient({\n      baseUrl: config?.baseUrl ?? process.env.OLLAMA_BASE_URL ?? 'http://localhost:11434',\n      timeout: config?.timeout ?? 30000,\n      defaultModel: config?.defaultModel ?? process.env.OLLAMA_DEFAULT_MODEL ?? 'gpt-oss:20b',\n    });\n  }\n  return defaultClient;\n}\n\n/**\n * Quick health check for Ollama\n */\nexport async function checkOllamaHealth(baseUrl?: string): Promise<OllamaHealthStatus> {\n  const client = new OllamaClient({\n    baseUrl: baseUrl ?? process.env.OLLAMA_BASE_URL ?? 'http://localhost:11434',\n    timeout: 5000, // Quick health check\n  });\n  return client.health();\n}\n","/**\n * AI Provider Health Check Endpoint - Phase 3 Local LLM Integration\n *\n * GET /api/health/providers\n *\n * Returns connection status for all AI providers:\n * - Ollama (local LLM)\n * - Lynkr (universal LLM proxy - local models from anywhere)\n * - Whisper (local STT)\n * - Cloud (OpenAI/Anthropic)\n */\n\nimport { NextRequest, NextResponse } from 'next/server';\nimport { checkOllamaHealth, type OllamaHealthStatus } from '@/lib/ollama';\nimport { checkLynkrHealth, type LynkrHealthStatus } from '@/lib/lynkr';\n\n// ============================================================================\n// Types\n// ============================================================================\n\ninterface ProviderStatus {\n  connected: boolean;\n  latencyMs?: number;\n  error?: string;\n  models?: string[];\n  version?: string;\n}\n\ninterface LynkrStatus extends ProviderStatus {\n  baseUrl: string;\n  tunnelUrl?: string;\n  provider?: string;\n  features?: {\n    memory?: boolean;\n    tools?: boolean;\n    streaming?: boolean;\n    embeddings?: boolean;\n  };\n}\n\ninterface HealthResponse {\n  timestamp: number;\n  providers: {\n    ollama: ProviderStatus & {\n      baseUrl: string;\n    };\n    lynkr: LynkrStatus;\n    whisper: ProviderStatus & {\n      enabled: boolean;\n    };\n    openai: ProviderStatus;\n    anthropic: ProviderStatus;\n  };\n  summary: {\n    localAvailable: boolean;\n    lynkrAvailable: boolean;\n    cloudAvailable: boolean;\n    recommendedProvider: 'local' | 'lynkr' | 'cloud';\n  };\n}\n\n// ============================================================================\n// Health Check Functions\n// ============================================================================\n\n/**\n * Check Ollama health\n */\nasync function checkOllama(baseUrl: string): Promise<OllamaHealthStatus> {\n  return checkOllamaHealth(baseUrl);\n}\n\n/**\n * Check Whisper local availability\n * TODO: Implement actual whisper check when local whisper is set up\n */\nasync function checkWhisper(): Promise<ProviderStatus & { enabled: boolean }> {\n  const whisperEnabled = process.env.WHISPER_LOCAL_ENABLED === 'true';\n\n  if (!whisperEnabled) {\n    return {\n      connected: false,\n      enabled: false,\n      error: 'Local Whisper not enabled',\n    };\n  }\n\n  // TODO: Implement actual whisper health check\n  // For now, return enabled status\n  return {\n    connected: whisperEnabled,\n    enabled: whisperEnabled,\n    latencyMs: 0,\n  };\n}\n\n/**\n * Check OpenAI API health\n */\nasync function checkOpenAI(): Promise<ProviderStatus> {\n  const apiKey = process.env.OPENAI_API_KEY;\n\n  if (!apiKey) {\n    return {\n      connected: false,\n      error: 'OPENAI_API_KEY not configured',\n    };\n  }\n\n  const start = Date.now();\n\n  try {\n    // Quick models list to verify API key works\n    const response = await fetch('https://api.openai.com/v1/models', {\n      method: 'GET',\n      headers: {\n        Authorization: `Bearer ${apiKey}`,\n      },\n      signal: AbortSignal.timeout(5000),\n    });\n\n    if (!response.ok) {\n      return {\n        connected: false,\n        error: `API returned ${response.status}`,\n        latencyMs: Date.now() - start,\n      };\n    }\n\n    const data = await response.json();\n    const models = data.data\n      ?.filter((m: { id: string }) => m.id.startsWith('gpt-'))\n      ?.map((m: { id: string }) => m.id)\n      ?.slice(0, 10) || [];\n\n    return {\n      connected: true,\n      latencyMs: Date.now() - start,\n      models,\n    };\n  } catch (error) {\n    return {\n      connected: false,\n      error: error instanceof Error ? error.message : 'Connection failed',\n      latencyMs: Date.now() - start,\n    };\n  }\n}\n\n/**\n * Check Anthropic API health\n */\nasync function checkAnthropic(): Promise<ProviderStatus> {\n  const apiKey = process.env.ANTHROPIC_API_KEY;\n\n  if (!apiKey) {\n    return {\n      connected: false,\n      error: 'ANTHROPIC_API_KEY not configured',\n    };\n  }\n\n  const start = Date.now();\n\n  try {\n    // Simple request to verify API key\n    // Anthropic doesn't have a /models endpoint, so we do a minimal completion\n    const response = await fetch('https://api.anthropic.com/v1/messages', {\n      method: 'POST',\n      headers: {\n        'x-api-key': apiKey,\n        'anthropic-version': '2023-06-01',\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        model: 'claude-3-haiku-20240307',\n        max_tokens: 1,\n        messages: [{ role: 'user', content: 'hi' }],\n      }),\n      signal: AbortSignal.timeout(5000),\n    });\n\n    // Even if we get rate limited (429), the key is valid\n    if (response.ok || response.status === 429) {\n      return {\n        connected: true,\n        latencyMs: Date.now() - start,\n        models: ['claude-3-opus', 'claude-3-sonnet', 'claude-3-haiku'],\n      };\n    }\n\n    return {\n      connected: false,\n      error: `API returned ${response.status}`,\n      latencyMs: Date.now() - start,\n    };\n  } catch (error) {\n    return {\n      connected: false,\n      error: error instanceof Error ? error.message : 'Connection failed',\n      latencyMs: Date.now() - start,\n    };\n  }\n}\n\n/**\n * Check Lynkr proxy health\n * Tries tunnel URL first (for production/remote access), then local URL\n */\nasync function checkLynkr(baseUrl: string, tunnelUrl?: string): Promise<LynkrStatus> {\n  // Try tunnel URL first if available (for remote access)\n  const urlsToTry = tunnelUrl ? [tunnelUrl, baseUrl] : [baseUrl];\n\n  for (const url of urlsToTry) {\n    const status = await checkLynkrHealth(url);\n\n    if (status.connected) {\n      return {\n        baseUrl,\n        tunnelUrl: tunnelUrl,\n        connected: true,\n        latencyMs: status.latencyMs,\n        provider: status.provider,\n        version: status.version,\n        features: status.features,\n      };\n    }\n  }\n\n  // All URLs failed\n  const lastStatus = await checkLynkrHealth(urlsToTry[urlsToTry.length - 1]);\n  return {\n    baseUrl,\n    tunnelUrl,\n    connected: false,\n    latencyMs: lastStatus.latencyMs,\n    error: lastStatus.error ?? 'Lynkr not reachable',\n  };\n}\n\n// ============================================================================\n// Route Handler\n// ============================================================================\n\nexport async function GET(request: NextRequest) {\n  const { searchParams } = new URL(request.url);\n  const ollamaUrl = searchParams.get('ollamaUrl') ?? process.env.OLLAMA_BASE_URL ?? 'http://localhost:11434';\n  const lynkrUrl = searchParams.get('lynkrUrl') ?? process.env.LYNKR_BASE_URL ?? 'http://localhost:8081';\n  const lynkrTunnelUrl = searchParams.get('lynkrTunnelUrl') ?? process.env.LYNKR_TUNNEL_URL;\n  const checkCloud = searchParams.get('checkCloud') !== 'false';\n  const checkLynkrFlag = searchParams.get('checkLynkr') !== 'false';\n\n  // Run health checks in parallel\n  const [ollamaStatus, lynkrStatus, whisperStatus, openaiStatus, anthropicStatus] = await Promise.all([\n    checkOllama(ollamaUrl),\n    checkLynkrFlag ? checkLynkr(lynkrUrl, lynkrTunnelUrl) : Promise.resolve({\n      baseUrl: lynkrUrl,\n      connected: false,\n      error: 'Skipped',\n    } as LynkrStatus),\n    checkWhisper(),\n    checkCloud ? checkOpenAI() : Promise.resolve({ connected: false, error: 'Skipped' } as ProviderStatus),\n    checkCloud ? checkAnthropic() : Promise.resolve({ connected: false, error: 'Skipped' } as ProviderStatus),\n  ]);\n\n  // Determine availability\n  const localAvailable = ollamaStatus.connected;\n  const lynkrAvailable = lynkrStatus.connected;\n  const cloudAvailable = openaiStatus.connected || anthropicStatus.connected;\n\n  // Recommend provider based on availability and latency\n  // Priority: Lynkr (if available) > Local Ollama > Cloud\n  let recommendedProvider: 'local' | 'lynkr' | 'cloud' = 'cloud';\n\n  if (lynkrAvailable) {\n    // Lynkr is available - use it for \"anywhere\" access\n    recommendedProvider = 'lynkr';\n  } else if (localAvailable && (!cloudAvailable || (ollamaStatus.latencyMs ?? 0) < 1000)) {\n    // Local Ollama is available and fast\n    recommendedProvider = 'local';\n  }\n\n  const response: HealthResponse = {\n    timestamp: Date.now(),\n    providers: {\n      ollama: {\n        baseUrl: ollamaUrl,\n        connected: ollamaStatus.connected,\n        latencyMs: ollamaStatus.latencyMs,\n        error: ollamaStatus.error,\n        models: ollamaStatus.models.map(m => m.name),\n        version: ollamaStatus.version,\n      },\n      lynkr: lynkrStatus,\n      whisper: whisperStatus,\n      openai: openaiStatus,\n      anthropic: anthropicStatus,\n    },\n    summary: {\n      localAvailable,\n      lynkrAvailable,\n      cloudAvailable,\n      recommendedProvider,\n    },\n  };\n\n  return NextResponse.json(response);\n}\n","import { AppRouteRouteModule } from \"next/dist/esm/server/route-modules/app-route/module.compiled\";\nimport { RouteKind } from \"next/dist/esm/server/route-kind\";\nimport { patchFetch as _patchFetch } from \"next/dist/esm/server/lib/patch-fetch\";\nimport { addRequestMeta, getRequestMeta } from \"next/dist/esm/server/request-meta\";\nimport { getTracer, SpanKind } from \"next/dist/esm/server/lib/trace/tracer\";\nimport { setManifestsSingleton } from \"next/dist/esm/server/app-render/manifests-singleton\";\nimport { normalizeAppPath } from \"next/dist/esm/shared/lib/router/utils/app-paths\";\nimport { NodeNextRequest, NodeNextResponse } from \"next/dist/esm/server/base-http/node\";\nimport { NextRequestAdapter, signalFromNodeResponse } from \"next/dist/esm/server/web/spec-extension/adapters/next-request\";\nimport { BaseServerSpan } from \"next/dist/esm/server/lib/trace/constants\";\nimport { getRevalidateReason } from \"next/dist/esm/server/instrumentation/utils\";\nimport { sendResponse } from \"next/dist/esm/server/send-response\";\nimport { fromNodeOutgoingHttpHeaders, toNodeOutgoingHttpHeaders } from \"next/dist/esm/server/web/utils\";\nimport { getCacheControlHeader } from \"next/dist/esm/server/lib/cache-control\";\nimport { INFINITE_CACHE, NEXT_CACHE_TAGS_HEADER } from \"next/dist/esm/lib/constants\";\nimport { NoFallbackError } from \"next/dist/esm/shared/lib/no-fallback-error.external\";\nimport { CachedRouteKind } from \"next/dist/esm/server/response-cache\";\nimport * as userland from \"INNER_APP_ROUTE\";\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\nconst nextConfigOutput = \"\"\nconst routeModule = new AppRouteRouteModule({\n    definition: {\n        kind: RouteKind.APP_ROUTE,\n        page: \"/api/health/providers/route\",\n        pathname: \"/api/health/providers\",\n        filename: \"route\",\n        bundlePath: \"\"\n    },\n    distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n    relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n    resolvedPagePath: \"[project]/src/app/api/health/providers/route.ts\",\n    nextConfigOutput,\n    userland\n});\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule;\nfunction patchFetch() {\n    return _patchFetch({\n        workAsyncStorage,\n        workUnitAsyncStorage\n    });\n}\nexport { routeModule, workAsyncStorage, workUnitAsyncStorage, serverHooks, patchFetch,  };\nexport async function handler(req, res, ctx) {\n    if (routeModule.isDev) {\n        addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint());\n    }\n    let srcPage = \"/api/health/providers/route\";\n    // turbopack doesn't normalize `/index` in the page name\n    // so we need to to process dynamic routes properly\n    // TODO: fix turbopack providing differing value from webpack\n    if (process.env.TURBOPACK) {\n        srcPage = srcPage.replace(/\\/index$/, '') || '/';\n    } else if (srcPage === '/index') {\n        // we always normalize /index specifically\n        srcPage = '/';\n    }\n    const multiZoneDraftMode = process.env.__NEXT_MULTI_ZONE_DRAFT_MODE;\n    const prepareResult = await routeModule.prepare(req, res, {\n        srcPage,\n        multiZoneDraftMode\n    });\n    if (!prepareResult) {\n        res.statusCode = 400;\n        res.end('Bad Request');\n        ctx.waitUntil == null ? void 0 : ctx.waitUntil.call(ctx, Promise.resolve());\n        return null;\n    }\n    const { buildId, params, nextConfig, parsedUrl, isDraftMode, prerenderManifest, routerServerContext, isOnDemandRevalidate, revalidateOnlyGenerated, resolvedPathname, clientReferenceManifest, serverActionsManifest } = prepareResult;\n    const normalizedSrcPage = normalizeAppPath(srcPage);\n    let isIsr = Boolean(prerenderManifest.dynamicRoutes[normalizedSrcPage] || prerenderManifest.routes[resolvedPathname]);\n    const render404 = async ()=>{\n        // TODO: should route-module itself handle rendering the 404\n        if (routerServerContext == null ? void 0 : routerServerContext.render404) {\n            await routerServerContext.render404(req, res, parsedUrl, false);\n        } else {\n            res.end('This page could not be found');\n        }\n        return null;\n    };\n    if (isIsr && !isDraftMode) {\n        const isPrerendered = Boolean(prerenderManifest.routes[resolvedPathname]);\n        const prerenderInfo = prerenderManifest.dynamicRoutes[normalizedSrcPage];\n        if (prerenderInfo) {\n            if (prerenderInfo.fallback === false && !isPrerendered) {\n                if (nextConfig.experimental.adapterPath) {\n                    return await render404();\n                }\n                throw new NoFallbackError();\n            }\n        }\n    }\n    let cacheKey = null;\n    if (isIsr && !routeModule.isDev && !isDraftMode) {\n        cacheKey = resolvedPathname;\n        // ensure /index and / is normalized to one key\n        cacheKey = cacheKey === '/index' ? '/' : cacheKey;\n    }\n    const supportsDynamicResponse = // If we're in development, we always support dynamic HTML\n    routeModule.isDev === true || // If this is not SSG or does not have static paths, then it supports\n    // dynamic HTML.\n    !isIsr;\n    // This is a revalidation request if the request is for a static\n    // page and it is not being resumed from a postponed render and\n    // it is not a dynamic RSC request then it is a revalidation\n    // request.\n    const isStaticGeneration = isIsr && !supportsDynamicResponse;\n    // Before rendering (which initializes component tree modules), we have to\n    // set the reference manifests to our global store so Server Action's\n    // encryption util can access to them at the top level of the page module.\n    if (serverActionsManifest && clientReferenceManifest) {\n        setManifestsSingleton({\n            page: srcPage,\n            clientReferenceManifest,\n            serverActionsManifest\n        });\n    }\n    const method = req.method || 'GET';\n    const tracer = getTracer();\n    const activeSpan = tracer.getActiveScopeSpan();\n    const context = {\n        params,\n        prerenderManifest,\n        renderOpts: {\n            experimental: {\n                authInterrupts: Boolean(nextConfig.experimental.authInterrupts)\n            },\n            cacheComponents: Boolean(nextConfig.cacheComponents),\n            supportsDynamicResponse,\n            incrementalCache: getRequestMeta(req, 'incrementalCache'),\n            cacheLifeProfiles: nextConfig.cacheLife,\n            waitUntil: ctx.waitUntil,\n            onClose: (cb)=>{\n                res.on('close', cb);\n            },\n            onAfterTaskError: undefined,\n            onInstrumentationRequestError: (error, _request, errorContext, silenceLog)=>routeModule.onRequestError(req, error, errorContext, silenceLog, routerServerContext)\n        },\n        sharedContext: {\n            buildId\n        }\n    };\n    const nodeNextReq = new NodeNextRequest(req);\n    const nodeNextRes = new NodeNextResponse(res);\n    const nextReq = NextRequestAdapter.fromNodeNextRequest(nodeNextReq, signalFromNodeResponse(res));\n    try {\n        const invokeRouteModule = async (span)=>{\n            return routeModule.handle(nextReq, context).finally(()=>{\n                if (!span) return;\n                span.setAttributes({\n                    'http.status_code': res.statusCode,\n                    'next.rsc': false\n                });\n                const rootSpanAttributes = tracer.getRootSpanAttributes();\n                // We were unable to get attributes, probably OTEL is not enabled\n                if (!rootSpanAttributes) {\n                    return;\n                }\n                if (rootSpanAttributes.get('next.span_type') !== BaseServerSpan.handleRequest) {\n                    console.warn(`Unexpected root span type '${rootSpanAttributes.get('next.span_type')}'. Please report this Next.js issue https://github.com/vercel/next.js`);\n                    return;\n                }\n                const route = rootSpanAttributes.get('next.route');\n                if (route) {\n                    const name = `${method} ${route}`;\n                    span.setAttributes({\n                        'next.route': route,\n                        'http.route': route,\n                        'next.span_name': name\n                    });\n                    span.updateName(name);\n                } else {\n                    span.updateName(`${method} ${srcPage}`);\n                }\n            });\n        };\n        const isMinimalMode = Boolean(process.env.MINIMAL_MODE || getRequestMeta(req, 'minimalMode'));\n        const handleResponse = async (currentSpan)=>{\n            var _cacheEntry_value;\n            const responseGenerator = async ({ previousCacheEntry })=>{\n                try {\n                    if (!isMinimalMode && isOnDemandRevalidate && revalidateOnlyGenerated && !previousCacheEntry) {\n                        res.statusCode = 404;\n                        // on-demand revalidate always sets this header\n                        res.setHeader('x-nextjs-cache', 'REVALIDATED');\n                        res.end('This page could not be found');\n                        return null;\n                    }\n                    const response = await invokeRouteModule(currentSpan);\n                    req.fetchMetrics = context.renderOpts.fetchMetrics;\n                    let pendingWaitUntil = context.renderOpts.pendingWaitUntil;\n                    // Attempt using provided waitUntil if available\n                    // if it's not we fallback to sendResponse's handling\n                    if (pendingWaitUntil) {\n                        if (ctx.waitUntil) {\n                            ctx.waitUntil(pendingWaitUntil);\n                            pendingWaitUntil = undefined;\n                        }\n                    }\n                    const cacheTags = context.renderOpts.collectedTags;\n                    // If the request is for a static response, we can cache it so long\n                    // as it's not edge.\n                    if (isIsr) {\n                        const blob = await response.blob();\n                        // Copy the headers from the response.\n                        const headers = toNodeOutgoingHttpHeaders(response.headers);\n                        if (cacheTags) {\n                            headers[NEXT_CACHE_TAGS_HEADER] = cacheTags;\n                        }\n                        if (!headers['content-type'] && blob.type) {\n                            headers['content-type'] = blob.type;\n                        }\n                        const revalidate = typeof context.renderOpts.collectedRevalidate === 'undefined' || context.renderOpts.collectedRevalidate >= INFINITE_CACHE ? false : context.renderOpts.collectedRevalidate;\n                        const expire = typeof context.renderOpts.collectedExpire === 'undefined' || context.renderOpts.collectedExpire >= INFINITE_CACHE ? undefined : context.renderOpts.collectedExpire;\n                        // Create the cache entry for the response.\n                        const cacheEntry = {\n                            value: {\n                                kind: CachedRouteKind.APP_ROUTE,\n                                status: response.status,\n                                body: Buffer.from(await blob.arrayBuffer()),\n                                headers\n                            },\n                            cacheControl: {\n                                revalidate,\n                                expire\n                            }\n                        };\n                        return cacheEntry;\n                    } else {\n                        // send response without caching if not ISR\n                        await sendResponse(nodeNextReq, nodeNextRes, response, context.renderOpts.pendingWaitUntil);\n                        return null;\n                    }\n                } catch (err) {\n                    // if this is a background revalidate we need to report\n                    // the request error here as it won't be bubbled\n                    if (previousCacheEntry == null ? void 0 : previousCacheEntry.isStale) {\n                        const silenceLog = false;\n                        await routeModule.onRequestError(req, err, {\n                            routerKind: 'App Router',\n                            routePath: srcPage,\n                            routeType: 'route',\n                            revalidateReason: getRevalidateReason({\n                                isStaticGeneration,\n                                isOnDemandRevalidate\n                            })\n                        }, silenceLog, routerServerContext);\n                    }\n                    throw err;\n                }\n            };\n            const cacheEntry = await routeModule.handleResponse({\n                req,\n                nextConfig,\n                cacheKey,\n                routeKind: RouteKind.APP_ROUTE,\n                isFallback: false,\n                prerenderManifest,\n                isRoutePPREnabled: false,\n                isOnDemandRevalidate,\n                revalidateOnlyGenerated,\n                responseGenerator,\n                waitUntil: ctx.waitUntil,\n                isMinimalMode\n            });\n            // we don't create a cacheEntry for ISR\n            if (!isIsr) {\n                return null;\n            }\n            if ((cacheEntry == null ? void 0 : (_cacheEntry_value = cacheEntry.value) == null ? void 0 : _cacheEntry_value.kind) !== CachedRouteKind.APP_ROUTE) {\n                var _cacheEntry_value1;\n                throw Object.defineProperty(new Error(`Invariant: app-route received invalid cache entry ${cacheEntry == null ? void 0 : (_cacheEntry_value1 = cacheEntry.value) == null ? void 0 : _cacheEntry_value1.kind}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E701\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            if (!isMinimalMode) {\n                res.setHeader('x-nextjs-cache', isOnDemandRevalidate ? 'REVALIDATED' : cacheEntry.isMiss ? 'MISS' : cacheEntry.isStale ? 'STALE' : 'HIT');\n            }\n            // Draft mode should never be cached\n            if (isDraftMode) {\n                res.setHeader('Cache-Control', 'private, no-cache, no-store, max-age=0, must-revalidate');\n            }\n            const headers = fromNodeOutgoingHttpHeaders(cacheEntry.value.headers);\n            if (!(isMinimalMode && isIsr)) {\n                headers.delete(NEXT_CACHE_TAGS_HEADER);\n            }\n            // If cache control is already set on the response we don't\n            // override it to allow users to customize it via next.config\n            if (cacheEntry.cacheControl && !res.getHeader('Cache-Control') && !headers.get('Cache-Control')) {\n                headers.set('Cache-Control', getCacheControlHeader(cacheEntry.cacheControl));\n            }\n            await sendResponse(nodeNextReq, nodeNextRes, // @ts-expect-error - Argument of type 'Buffer<ArrayBufferLike>' is not assignable to parameter of type 'BodyInit | null | undefined'.\n            new Response(cacheEntry.value.body, {\n                headers,\n                status: cacheEntry.value.status || 200\n            }));\n            return null;\n        };\n        // TODO: activeSpan code path is for when wrapped by\n        // next-server can be removed when this is no longer used\n        if (activeSpan) {\n            await handleResponse(activeSpan);\n        } else {\n            await tracer.withPropagatedContext(req.headers, ()=>tracer.trace(BaseServerSpan.handleRequest, {\n                    spanName: `${method} ${srcPage}`,\n                    kind: SpanKind.SERVER,\n                    attributes: {\n                        'http.method': method,\n                        'http.target': req.url\n                    }\n                }, handleResponse));\n        }\n    } catch (err) {\n        if (!(err instanceof NoFallbackError)) {\n            const silenceLog = false;\n            await routeModule.onRequestError(req, err, {\n                routerKind: 'App Router',\n                routePath: normalizedSrcPage,\n                routeType: 'route',\n                revalidateReason: getRevalidateReason({\n                    isStaticGeneration,\n                    isOnDemandRevalidate\n                })\n            }, silenceLog, routerServerContext);\n        }\n        // rethrow so that we can handle serving error page\n        // If this is during static generation, throw the error again.\n        if (isIsr) throw err;\n        // Otherwise, send a 500 response.\n        await sendResponse(nodeNextReq, nodeNextRes, new Response(null, {\n            status: 500\n        }));\n        return null;\n    }\n}\n\n//# sourceMappingURL=app-route.js.map\n"],"names":[],"mappings":"m4BAwBA,IAAM,EAAsB,CAC1B,SACA,QACA,iCACA,cACA,cACA,OACA,0CACA,QACA,UACA,UACA,eACA,eACA,8BACA,qBACD,CAGK,EAAkB,CAAC,SAAU,QAAQ,CA4K3C,SAAS,IAEP,MAC2C,CADpC,QACA,QAAQ,GAAG,CAAC,mBAAmB,AACxC,CA4BA,SAAS,EA9ByB,AA8BhB,CAAkB,EAY9B,KACF,QAAQ,CADQ,EACL,CAAC,gBAAiB,KAAK,SAAS,CAAC,GAEhD,CAiBO,MAAM,EACH,MAGN,AAEF,aAAY,CAAmB,CAAE,CAC/B,MAAM,EAAe,IACf,EAAuB,EAAO,oBAAoB,EAAI,EACtD,EAAqB,EAAO,kBAAkB,EAAI,CAGpD,CAAC,GACH,AA7IC,SAAS,AAAe,CAA0B,CAAE,CAAwB,EACjF,IAAI,CA2IyB,EAzI7B,GAAI,CAAC,GAAU,EAAO,IAFF,EAEQ,CApIH,EAoIM,CAAoB,CACjD,IAAM,EAAQ,AAAI,MAChB,CAAC,+BAA+B,EAAE,mBAAmB,aAAa,CAAC,GACnE,CAAC,gBAGH,OADA,EAAM,IAAI,CAAG,QAF4B,CAAC,SAGpC,CACR,CAIA,GADqB,AACjB,CADkB,cAAe,QAAS,OAAQ,QAAS,MAAM,CACpD,QAAQ,CAAC,EAAO,WAAW,IAAK,CAC/C,IAAM,EAAQ,AAAI,MAChB,uEAGF,OADA,EAAM,IAAI,CAAG,kBACP,CACR,EACF,EAwHqB,EAAO,MAAM,EAAE,GAG5B,AAAC,GACH,AAvHC,SAAS,AAAkB,CAAiB,CAAE,CAAwB,EAC3E,GAqH2B,CArHvB,EAEJ,GAAI,CACF,IAAM,EAAM,IAHM,AAGF,IAAI,GAGpB,GAAI,CAAC,EAAgB,QAAQ,CAAC,EAAI,QAAQ,EAAG,CAC3C,IAAM,EAAQ,AAAI,MAChB,CAAC,WAAW,EAAE,EAAI,QAAQ,CAAC,iCAAiC,CAAC,CAG/D,OADA,EAAM,IAAI,CAAG,cACP,CACR,CAGA,IAAM,EAAW,EAAI,QAAQ,CAC7B,IAAK,IAAM,KAAW,EACpB,GAAI,EAAQ,IAAI,CAAC,GAAW,CAC1B,IAFuC,AAEjC,EAAQ,AAAI,MAChB,CAAC,iBAAiB,EAAE,EAAS,0CAA0C,CAAC,CAG1E,OADA,EAAM,IAAI,CAAG,eACP,CACR,CAEJ,CAAE,MAAO,EAAG,CACV,GAAK,EAAyB,IAAI,CAAE,MAAM,EAE1C,IAAM,EAAQ,AAAI,MAAM,CAAC,aAAa,EAAE,EAAA,CAAW,CAEnD,OADA,EAAM,IAAI,CAAG,cACP,CACR,CACF,EAsFwB,EAAO,OAAO,CAAE,IAGpC,IAAI,CAAC,MAAM,CAAG,CACZ,QAAS,EAAO,OAAO,CAAC,OAAO,CAAC,MAAO,IACvC,OAAQ,EAAO,MAAM,EAAI,GACzB,QAAS,EAAO,OAAO,EAAI,KAC3B,aAAc,EAAO,YAAY,EAAI,mCACrC,qBACA,CACF,CACF,CAKA,MAAM,aAA0C,CAC9C,IAAM,EAAQ,KAAK,GAAG,GAEtB,GAAI,CACF,IAAM,EAAa,IAAI,gBACjB,EAAY,WAAW,IAAM,EAAW,KAAK,GAAI,KAEjD,EAAW,MAAM,MAAM,CAAA,EAAG,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,CAAE,CAC5D,OAAQ,MACR,OAAQ,EAAW,MAAM,AAC3B,GAIA,GAFA,aAAa,GAET,CAAC,EAAS,EAAE,CACd,CADgB,KACT,CACL,WAAW,EACX,UAAW,KAAK,GAAG,GAAK,EACxB,MAAO,CAAC,KAAK,EAAE,EAAS,MAAM,CAAC,EAAE,EAAE,EAAS,UAAU,CAAA,CAAE,AAC1D,EAGF,IAAM,EAAO,MAAM,EAAS,IAAI,GAEhC,MAAO,CACL,UAAW,GACX,UAAW,KAAK,GAAG,GAAK,EACxB,SAAU,EAAK,QAAQ,CACvB,MAAO,EAAK,KAAK,CACjB,QAAS,EAAK,OAAO,CACrB,SAAU,CACR,OAAQ,EAAK,MAAM,EAAE,UAAW,EAChC,MAAO,EAAK,KAAK,EAAE,UAAW,EAC9B,UAAW,EAAK,SAAS,EAAE,UAAW,EACtC,WAAY,EAAK,UAAU,EAAE,UAAW,CAC1C,CACF,CACF,CAAE,MAAO,EAAO,CACd,MAAO,CACL,WAAW,EACX,UAAW,KAAK,GAAG,GAAK,EACxB,MAAO,aAAiB,MAAQ,EAAM,OAAO,CAAG,mBAClD,CACF,CACF,CAKA,MAAM,YAA2C,CAC/C,GAAI,CACF,IAAM,EAAW,MAAM,MAAM,CAAA,EAAG,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAE,CAC7D,OAAQ,MACR,OAAQ,YAAY,OAAO,CAAC,IAC9B,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,OAAO,KAEzB,OAAO,MAAM,EAAS,IAAI,EAC5B,CAAE,KAAM,CACN,OAAO,IACT,CACF,CAMA,MAAM,KAAK,CAA6D,CAA8B,CACpG,IAAM,EAAQ,KAAK,GAAG,GAChB,EAAQ,EAAQ,KAAK,EAAI,IAAI,CAAC,MAAM,CAAC,YAAY,CAEjD,EAAyB,OAC7B,EACA,SAAU,EAAQ,QAAQ,CAC1B,WAAY,EAAQ,UAAU,EAAI,KAClC,YAAa,EAAQ,WAAW,EAAI,GACpC,MAAO,EAAQ,KAAK,CACpB,OAAQ,EAAQ,MAAM,CACtB,OAAQ,EACV,EAEM,EAAa,IAAI,gBACjB,EAAY,WAAW,IAAM,EAAW,KAAK,GAAI,IAAI,CAAC,MAAM,CAAC,OAAO,EAE1E,GAAI,CACF,IAAM,EAAW,MAAM,MAAM,CAAA,EAAG,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,YAAY,CAAC,CAAE,CACjE,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,YAAa,IAAI,CAAC,MAAM,CAAC,MAAM,CAC/B,oBAAqB,YACvB,EACA,KAAM,KAAK,SAAS,CAAC,GACrB,OAAQ,EAAW,MACrB,AAD2B,GAK3B,GAFA,aAAa,GAET,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAY,MAAM,EAAS,IAAI,GAC/B,EAAQ,AAAI,MAAM,CAAC,sBAAsB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAW,CAYjF,OAVA,EAAS,CACP,UAAW,KAAK,GAAG,GACnB,OAAQ,aACR,EACA,QAAS,IAAI,CAAC,MAAM,CAAC,OAAO,CAC5B,UAAW,KAAK,GAAG,GAAK,EACxB,SAAS,EACT,MAAO,EAAM,OAAO,AACtB,GAEM,CACR,CAEA,IAAM,EAA4B,MAAM,EAAS,IAAI,GAarD,OAXA,EAAS,CACP,UAAW,KAAK,GAAG,GACnB,OAAQ,aACR,EACA,QAAS,IAAI,CAAC,MAAM,CAAC,OAAO,CAC5B,UAAW,KAAK,GAAG,GAAK,EACxB,SAAS,EACT,YAAa,EAAO,KAAK,EAAE,aAC3B,aAAc,EAAO,KAAK,EAAE,aAC9B,GAEO,CACT,CAAE,MAAO,EAAO,CAgBd,MAfA,aAAa,GAGT,AAAE,CAAD,YAAkB,OAAS,EAAM,OAAO,CAAC,QAAQ,CAAC,uBAAuB,EAC5E,CAD+E,CACtE,CACP,UAAW,KAAK,GAAG,GACnB,OAAQ,aACR,EACA,QAAS,IAAI,CAAC,MAAM,CAAC,OAAO,CAC5B,UAAW,KAAK,GAAG,GAAK,EACxB,SAAS,EACT,MAAO,aAAiB,MAAQ,EAAM,OAAO,CAAG,eAClD,GAGI,CACR,CACF,CAMA,OAAO,WACL,CAAwE,CAOvE,CACD,IAAM,EAAyB,CAC7B,MAAO,EAAQ,KAAK,EAAI,IAAI,CAAC,MAAM,CAAC,YAAY,CAChD,SAAU,EAAQ,QAAQ,CAC1B,WAAY,EAAQ,UAAU,EAAI,KAClC,YAAa,EAAQ,WAAW,EAAI,GACpC,MAAO,EAAQ,KAAK,CACpB,OAAQ,EAAQ,MAAM,CACtB,QAAQ,CACV,EAEM,EAAa,IAAI,gBACjB,EAAY,WAAW,IAAM,EAAW,KAAK,GAAI,IAAI,CAAC,MAAM,CAAC,OAAO,EAE1E,GAAI,CACF,IAAM,EAAW,MAAM,MAAM,CAAA,EAAG,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,YAAY,CAAC,CAAE,CACjE,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,YAAa,IAAI,CAAC,MAAM,CAAC,MAAM,CAC/B,oBAAqB,YACvB,EACA,KAAM,KAAK,SAAS,CAAC,GACrB,OAAQ,EAAW,MAAM,AAC3B,GAIA,GAFA,aAAa,GAET,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAY,MAAM,EAAS,IAAI,EACrC,OAAM,AAAI,MAAM,CAAC,qBAAqB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAW,CAC1E,CAEA,GAAI,CAAC,EAAS,IAAI,CAChB,CADkB,KACZ,AAAI,MAAM,kCAGlB,IAAM,EAAS,EAAS,IAAI,CAAC,SAAS,GAChC,EAAU,IAAI,YAChB,EAAS,GAEb,MAAO,CAAM,CACX,GAAM,MAAE,CAAI,OAAE,CAAK,CAAE,CAAG,MAAM,EAAO,IAAI,GACzC,GAAI,EAAM,MAGV,IAAM,EAAQ,CADd,GAAU,EAAQ,MAAM,CAAC,EAAO,CAAE,QAAQ,CAAK,EAAA,EAC1B,KAAK,CAAC,MAG3B,IAAK,IAAM,KAFX,EAAS,EAAM,GAAG,IAAM,GAEL,GACjB,GADwB,AACpB,EAAK,UAAU,CAAC,UAAW,CAC7B,IAAM,EAAO,EAAK,KAAK,CAAC,GAAG,IAAI,GAC/B,GAAa,WAAT,EAAmB,OAEvB,GAAI,CACF,IAAM,EAAQ,KAAK,KAAK,CAAC,EACzB,OAAM,CACR,CAAE,KAAM,CAER,CACF,CAEJ,CACF,CAAE,MAAO,EAAO,CAEd,MADA,aAAa,GACP,CACR,CACF,CAKA,OAAO,YAAY,CAA2B,CAAU,CACtD,OAAO,EAAS,OAAO,CACpB,MAAM,CAAC,AAAC,GAAoD,SAAf,EAAM,IAAI,EACvD,GAAG,CAAC,AAAC,GAAU,EAAM,IAAI,EACzB,IAAI,CAAC,GACV,CAKA,OAAO,iBAAiB,CAA2B,CAAkB,CACnE,OAAO,EAAS,OAAO,CAAC,MAAM,CAAC,AAAC,GAAgD,aAAf,EAAM,IAAI,CAC7E,CAKA,OAAO,aAAa,CAA2B,CAAW,CACxD,MAAO,AAAyB,eAAhB,WAAW,EAAmB,EAAS,OAAO,CAAC,IAAI,CAAC,AAAC,GAAyB,aAAf,EAAM,IAAI,CAC3F,CACF,CAWO,SAAS,EAAe,CAA6B,EAE1D,IAAM,EAAsC,CAC1C,GADU,KACD,QAAQ,GAAG,CAAC,cAAc,CACnC,OAAQ,QAAQ,GAAG,CAAC,aAAa,CACjC,QAAS,QAAQ,GAAG,CAAC,aAAa,CAClC,aAAc,QAAQ,GAAG,CAAC,mBAAmB,CAC7C,aAAkD,SAApC,CACA,OADQ,GAAG,CAAC,mBAAmB,AAE/C,EAEM,EAAe,AAFjB,GAEyB,cAHY,QAGY,GAAQ,oBAAsB,EAAI,YAAY,CAEnG,OAAO,IAAI,EAAY,CACrB,QAAS,GAAQ,SAAW,EAAI,OAAO,EAAI,wBAC3C,OAAQ,GAAQ,QAAU,EAAI,MAAM,CACpC,QAAS,GAAQ,SAAW,SAAS,EAAI,OAAO,EAAI,SAAU,IAC9D,aAAc,GAAQ,cAAgB,EAAI,YAAY,EAAI,cAC1D,qBAAsB,EACtB,mBAAoB,CACtB,EACF,CASO,eAAe,EAAiB,CAAgB,EAOrD,OALe,AAKR,EALuB,SAC5B,EACA,sBAAsB,EACtB,oBAAoB,CACtB,GACc,WAAW,EAC3B,6GCngBO,OAAM,EACH,OAAgB,CAChB,OAAgB,CAChB,YAAqB,AAE7B,aAAY,CAAoB,CAAE,CAChC,IAAI,CAAC,OAAO,CAAG,EAAO,OAAO,CAAC,OAAO,CAAC,MAAO,IAC7C,CADkD,GAC9C,CAAC,OAAO,CAAG,EAAO,OAAO,EAAI,CADyC,GAE1E,IAAI,CAAC,YAAY,CAAG,EAAO,YAAY,EAAI,aAC7C,CAKA,MAAM,QAAsC,CAC1C,IAAM,EAAQ,KAAK,GAAG,GAEtB,GAAI,CAEF,IAiBI,EAjBE,EAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,SAAS,CAAC,CAAE,CACvE,OAAQ,KACV,GAEA,GAAI,CAAC,EAAS,EAAE,CACd,CADgB,KACT,CACL,WAAW,EACX,OAAQ,EAAE,CACV,MAAO,CAAC,gBAAgB,EAAE,EAAS,MAAM,CAAA,CAAE,CAC3C,UAAW,KAAK,GAAG,GAAK,CAC1B,EAIF,IAAM,EAAwB,CADjB,MAAM,EAAS,IAAI,EAAA,EACG,MAAM,EAAI,EAAE,CAI/C,GAAI,CACF,IAAM,EAAkB,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,CAAE,CACjF,OAAQ,KACV,GACI,EAAgB,EAAE,EAAE,AAEtB,GAAU,AADU,OAAM,EAAgB,IAAI,EAAA,EACxB,OAAO,AAAP,CAE1B,CAAE,MAAO,EAAO,CAEd,QAAQ,KAAK,CAAC,2CAA4C,EAC5D,CAEA,MAAO,CACL,WAAW,UACX,SACA,EACA,UAAW,KAAK,GAAG,GAAK,CAC1B,CACF,CAAE,MAAO,EAAO,CACd,MAAO,CACL,WAAW,EACX,OAAQ,EAAE,CACV,MAAO,aAAiB,MAAQ,EAAM,OAAO,CAAG,oBAChD,UAAW,KAAK,GAAG,GAAK,CAC1B,CACF,CACF,CAKA,MAAM,YAAqC,CACzC,IAAM,EAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,SAAS,CAAC,CAAE,CACvE,OAAQ,KACV,GAEA,GAAI,CAAC,EAAS,EAAE,CACd,CADgB,KACV,AAAI,MAAM,CAAC,uBAAuB,EAAE,EAAS,MAAM,CAAA,CAAE,EAI7D,MAAO,CADM,MAAM,EAAS,IAAI,EAAA,EACpB,MAAM,EAAI,EAAE,AAC1B,CAKA,MAAM,KAAK,CAA0B,CAA+B,CAClE,IAAM,EAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,SAAS,CAAC,CAAE,CACvE,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,SAAS,CAAC,CACnB,GAAG,CAAO,CACV,MAAO,EAAQ,KAAK,EAAI,IAAI,CAAC,YAAY,CACzC,QAAQ,CACV,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,aAAa,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAO,CAC9D,CAEA,OAAO,EAAS,IAAI,EACtB,CAMA,OAAO,WAAW,CAA0B,CAAsC,CAChF,IAAM,EAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,SAAS,CAAC,CAAE,CACvE,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,SAAS,CAAC,CACnB,GAAG,CAAO,CACV,MAAO,EAAQ,KAAK,EAAI,IAAI,CAAC,YAAY,CACzC,OAAQ,EACV,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,oBAAoB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAO,CACrE,CAEA,IAAM,EAAS,EAAS,IAAI,EAAE,YAC9B,GAAI,CAAC,EACH,MADW,AACL,AAAI,MAAM,oBAGlB,IAAM,EAAU,IAAI,YAChB,EAAS,GAEb,GAAI,CACF,MAAO,CAAM,CACX,GAAM,MAAE,CAAI,OAAE,CAAK,CAAE,CAAG,MAAM,EAAO,IAAI,GAEzC,GAAI,EAAM,MAGV,IAAM,EADN,AACc,IADJ,EAAQ,MAAM,CAAC,EAAO,CAAE,QAAQ,CAAK,EAAA,EAC1B,KAAK,CAAC,MAG3B,IAAK,IAAM,KAFX,EAAS,EAAM,GAAG,IAAM,GAEL,GACjB,GADwB,AACpB,EAAK,IAAI,GACX,CADe,EACX,CACF,IAAM,EAAO,KAAK,KAAK,CAAC,EACxB,OAAM,CACR,CAAE,MAAO,EAAO,CAEd,QAAQ,KAAK,CAAC,0CAA2C,EAAK,SAAS,CAAC,EAAG,KAAM,EACnF,CAGN,CAGA,GAAI,EAAO,IAAI,GACb,CADiB,EACb,CACF,IAAM,EAAO,KAAK,KAAK,CAAC,EACxB,OAAM,CACR,CAAE,MAAO,EAAO,CAEd,QAAQ,KAAK,CAAC,0CAA2C,EAAO,SAAS,CAAC,EAAG,KAAM,EACrF,CAEJ,QAAU,CACR,EAAO,WAAW,EACpB,CACF,CAKA,MAAM,SAAS,CAA8B,CAAmC,CAC9E,IAAM,EAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,aAAa,CAAC,CAAE,CAC3E,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,SAAS,CAAC,CACnB,GAAG,CAAO,CACV,MAAO,EAAQ,KAAK,EAAI,IAAI,CAAC,YAAY,CACzC,QAAQ,CACV,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,iBAAiB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAO,CAClE,CAEA,OAAO,EAAS,IAAI,EACtB,CAKA,OAAO,eAAe,CAA8B,CAA0C,CAC5F,IAAM,EAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,aAAa,CAAC,CAAE,CAC3E,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,SAAS,CAAC,CACnB,GAAG,CAAO,CACV,MAAO,EAAQ,KAAK,EAAI,IAAI,CAAC,YAAY,CACzC,QAAQ,CACV,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAU,AAAJ,MAAU,CAAC,wBAAwB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAO,CACzE,CAEA,IAAM,EAAS,EAAS,IAAI,EAAE,YAC9B,GAAI,CAAC,EACH,MAAU,AAAJ,AADK,MACK,oBAGlB,IAAM,EAAU,IAAI,YAChB,EAAS,GAEb,GAAI,CACF,MAAO,CAAM,CACX,GAAM,MAAE,CAAI,OAAE,CAAK,CAAE,CAAG,MAAM,EAAO,IAAI,GAEzC,GAAI,EAAM,MAGV,IAAM,EAAQ,CADd,GAAU,EAAQ,MAAM,CAAC,EAAO,CAAE,QAAQ,CAAK,EAAA,EAC1B,KAAK,CAAC,MAG3B,IAAK,IAAM,KAFX,EAAS,EAAM,GAAG,IAAM,GAEL,GACjB,GADwB,AACpB,EAAK,IAAI,GACX,CADe,EACX,CACF,IAAM,EAAO,KAAK,KAAK,CAAC,EACxB,OAAM,CACR,CAAE,MAAO,EAAO,CAEd,QAAQ,KAAK,CAAC,8CAA+C,EAAK,SAAS,CAAC,EAAG,KAAM,EACvF,CAGN,CAGA,GAAI,EAAO,IAAI,GACb,CADiB,EACb,CACF,IAAM,EAAO,KAAK,KAAK,CAAC,EACxB,OAAM,CACR,CAAE,MAAO,EAAO,CAEd,QAAQ,KAAK,CAAC,8CAA+C,EAAO,SAAS,CAAC,EAAG,KAAM,EACzF,CAEJ,QAAU,CACR,EAAO,WAAW,EACpB,CACF,CAKA,MAAM,UAAU,CAAiB,CAAiB,CAChD,IAAM,EAAW,MAAM,MAAM,CAAA,EAAG,IAAI,CAAC,OAAO,CAAC,SAAS,CAAC,CAAE,CACvD,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,SAAS,CAAC,CAAE,KAAM,CAAU,EACzC,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,sBAAsB,EAAE,EAAS,MAAM,CAAC,GAAG,EAAE,EAAA,CAAO,CACvE,CAGA,IAAM,EAAS,EAAS,IAAI,EAAE,YAC9B,GAAI,EAAQ,CAEV,IADgB,EACT,EADa,cACP,CACX,GAAM,MAAE,CAAI,CAAE,CAAG,MAAM,EAAO,IAAI,GAClC,GAAI,EAAM,KACZ,CACA,EAAO,WAAW,EACpB,CACF,CAKA,MAAc,iBAAiB,CAAW,CAAE,CAAoB,CAAqB,CACnF,IAAM,EAAa,IAAI,gBACjB,EAAY,WAAW,IAAM,EAAW,KAAK,GAAI,IAAI,CAAC,OAAO,EAEnE,GAAI,CAKF,OAJiB,AAIV,MAJgB,MAAM,EAAK,CAChC,GAAG,CAAO,CACV,OAAQ,EAAW,MAAM,AAC3B,EAEF,CAAE,MAAO,EAAO,CACd,GAAI,aAAiB,OAAwB,cAAc,CAA7B,EAAM,IAAI,CACtC,MAAM,AAAI,MAAM,CAAC,wBAAwB,EAAE,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,CAE7D,OAAM,CACR,QAAU,CACR,aAAa,EACf,CACF,CACF,CA0BO,eAAe,EAAkB,CAAgB,EAKtD,OAJe,AAIR,IAJY,EAAa,CAC9B,QAAS,GAAW,QAAQ,GAAG,CAAC,eAAe,EAAI,yBACnD,QAAS,GACX,GACc,MAAM,EACtB,sGErbA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,CAAA,CAAA,OAAA,IAAA,EAAA,EAAA,CAAA,CAAA,QDJA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,QAAA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,CAAA,CAAA,QAAA,IAAA,EAAA,EAAA,CAAA,CAAA,QAsDA,eAAe,EAAY,CAAe,EACxC,MAAO,CAAA,EAAA,EAAA,iBAAiB,AAAjB,EAAkB,EAC3B,CAMA,eAAe,IACb,IAAM,EAAuD,SAAtC,QAAQ,GAAG,CAAC,qBAAqB,QAExD,AAAK,EAUE,CACL,CAXE,SAWS,EACX,CAZmB,OAYV,EACT,UAAW,CACb,EAbS,CACL,WAAW,EACX,SAAS,EACT,MAAO,2BACT,CAUJ,CAKA,eAAe,IACb,IAAM,EAAS,QAAQ,GAAG,CAAC,cAAc,CAEzC,GAAI,CAAC,EACH,MADW,AACJ,CACL,WAAW,EACX,MAAO,+BACT,EAGF,IAAM,EAAQ,KAAK,GAAG,GAEtB,GAAI,CAEF,IAAM,EAAW,MAAM,MAAM,mCAAoC,CAC/D,OAAQ,MACR,QAAS,CACP,cAAe,CAAC,OAAO,EAAE,EAAA,CAAQ,AACnC,EACA,OAAQ,YAAY,OAAO,CAAC,IAC9B,GAEA,GAAI,CAAC,EAAS,EAAE,CACd,CADgB,KACT,CACL,WAAW,EACX,MAAO,CAAC,aAAa,EAAE,EAAS,MAAM,CAAA,CAAE,CACxC,UAAW,KAAK,GAAG,GAAK,CAC1B,EAGF,IAAM,EAAO,MAAM,EAAS,IAAI,GAC1B,EAAS,EAAK,IAAI,EACpB,OAAQ,AAAD,GAAuB,EAAE,EAAE,CAAC,UAAU,CAAC,UAC9C,IAAI,AAAC,GAAsB,EAAE,EAAE,GAC/B,MAAM,EAAG,KAAO,EAAE,CAEtB,MAAO,CACL,WAAW,EACX,UAAW,KAAK,GAAG,GAAK,SACxB,CACF,CACF,CAAE,MAAO,EAAO,CACd,MAAO,CACL,WAAW,EACX,MAAO,aAAiB,MAAQ,EAAM,OAAO,CAAG,oBAChD,UAAW,KAAK,GAAG,GAAK,CAC1B,CACF,CACF,CAKA,eAAe,IACb,IAAM,EAAS,QAAQ,GAAG,CAAC,iBAAiB,CAE5C,GAAI,CAAC,EACH,MADW,AACJ,CACL,WAAW,EACX,MAAO,kCACT,EAGF,IAAM,EAAQ,KAAK,GAAG,GAEtB,GAAI,CAGF,IAAM,EAAW,MAAM,MAAM,wCAAyC,CACpE,OAAQ,OACR,QAAS,CACP,YAAa,EACb,oBAAqB,aACrB,eAAgB,kBAClB,EACA,KAAM,KAAK,SAAS,CAAC,CACnB,MAAO,0BACP,WAAY,EACZ,SAAU,CAAC,CAAE,KAAM,OAAQ,QAAS,IAAK,EAAE,AAC7C,GACA,OAAQ,YAAY,OAAO,CAAC,IAC9B,GAGA,GAAI,EAAS,EAAE,EAAwB,KAAK,CAAzB,EAAS,MAAM,CAChC,MAAO,CACL,WAAW,EACX,UAAW,KAAK,GAAG,GAAK,EACxB,OAAQ,CAAC,gBAAiB,kBAAmB,iBAAiB,AAChE,EAGF,MAAO,CACL,WAAW,EACX,MAAO,CAAC,aAAa,EAAE,EAAS,MAAM,CAAA,CAAE,CACxC,UAAW,KAAK,GAAG,GAAK,CAC1B,CACF,CAAE,MAAO,EAAO,CACd,MAAO,CACL,WAAW,EACX,MAAO,aAAiB,MAAQ,EAAM,OAAO,CAAG,oBAChD,UAAW,KAAK,GAAG,GAAK,CAC1B,CACF,CACF,CAMA,eAAe,EAAW,CAAe,CAAE,CAAkB,EAE3D,IAAM,EAAY,EAAY,CAAC,EAAW,EAAQ,CAAG,CAAC,EAAQ,CAE9D,IAAK,IAAM,KAAO,EAAW,CAC3B,IAAM,EAAS,MAAM,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,GAEtC,GAAI,EAAO,SAAS,CAClB,CADoB,KACb,SACL,EACA,UAAW,EACX,WAAW,EACX,UAAW,EAAO,SAAS,CAC3B,SAAU,EAAO,QAAQ,CACzB,QAAS,EAAO,OAAO,CACvB,SAAU,EAAO,QAAQ,AAC3B,CAEJ,CAGA,IAAM,EAAa,MAAM,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,CAAS,CAAC,EAAU,MAAM,CAAG,EAAE,EACzE,MAAO,SACL,YACA,EACA,WAAW,EACX,UAAW,EAAW,SAAS,CAC/B,MAAO,EAAW,KAAK,EAAI,qBAC7B,CACF,CAMO,eAAe,EAAI,CAAoB,EAC5C,GAAM,cAAE,CAAY,CAAE,CAAG,IAAI,IAAI,EAAQ,GAAG,EACtC,EAAY,EAAa,GAAG,CAAC,cAAgB,QAAQ,GAAG,CAAC,eAAe,EAAI,yBAC5E,EAAW,EAAa,GAAG,CAAC,aAAe,QAAQ,GAAG,CAAC,cAAc,EAAI,wBACzE,EAAiB,EAAa,GAAG,CAAC,mBAAqB,QAAQ,GAAG,CAAC,gBAAgB,CACnF,EAAgD,UAAnC,EAAa,GAAG,CAAC,cAC9B,EAAoD,UAAnC,EAAa,GAAG,CAAC,cAGlC,CAAC,EAAc,EAAa,EAAe,EAAc,EAAgB,CAAG,MAAM,QAAQ,GAAG,CAAC,CAClG,EAAY,GACZ,EAAiB,EAAW,EAAU,GAAkB,QAAQ,OAAO,CAAC,CACtE,QAAS,EACT,WAAW,EACX,MAAO,SACT,GACA,IACA,EAAa,IAAgB,QAAQ,OAAO,CAAC,CAAE,WAAW,EAAO,MAAO,SAAU,GAClF,EAAa,IAAmB,QAAQ,OAAO,CAAC,CAAE,WAAW,EAAO,MAAO,SAAU,GACtF,EAGK,EAAiB,EAAa,SAAS,CACvC,EAAiB,EAAY,SAAS,CACtC,EAAiB,EAAa,SAAS,EAAI,EAAgB,SAAS,CAItE,EAAmD,QAEnD,EAEF,EAAsB,QACb,IAAmB,AAHV,CAGW,GAAkB,CAAC,EAAa,OAAlC,EAA2C,GAAI,CAAC,CAAI,GAAA,CAAI,GAAG,AAEtF,EAAsB,OAAA,EAGxB,IAAM,EAA2B,CAC/B,UAAW,KAAK,GAAG,GACnB,UAAW,CACT,OAAQ,CACN,QAAS,EACT,UAAW,EAAa,SAAS,CACjC,UAAW,EAAa,SAAS,CACjC,MAAO,EAAa,KAAK,CACzB,OAAQ,EAAa,MAAM,CAAC,GAAG,CAAC,GAAK,EAAE,IAAI,EAC3C,QAAS,EAAa,OAAO,AAC/B,EACA,MAAO,EACP,QAAS,EACT,OAAQ,EACR,UAAW,CACb,EACA,QAAS,gBACP,iBACA,EACA,qCACA,CACF,CACF,EAEA,OAAO,EAAA,YAAY,CAAC,IAAI,CAAC,EAC3B,2BClSA,IAAA,EAAA,EAAA,CAAA,CAAA,QAIA,IAAM,EAAc,IAAI,EAAA,mBAAmB,CAAC,CACxC,WAAY,CACR,KAAM,EAAA,SAAS,CAAC,SAAS,CACzB,KAAM,8BACN,SAAU,wBACV,SAAU,QACV,WAAY,EAChB,EACA,QAAS,CAAA,OACT,IADiD,eACc,CAA3C,EACpB,iBAAkB,kDAClB,iBAZqB,GAarB,SAAA,CACJ,GAIM,kBAAE,CAAgB,sBAAE,CAAoB,aAAE,CAAW,CAAE,CAAG,EAChE,SAAS,IACL,MAAO,CAAA,EAAA,EAAA,UAAA,AAAW,EAAC,kBACf,uBACA,CACJ,EACJ,CAEO,eAAe,EAAQ,CAAG,CAAE,CAAG,CAAE,CAAG,EACnC,EAAY,KAAK,EAAE,AACnB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,+BAAgC,QAAQ,MAAM,CAAC,MAAM,IAE7E,IAAI,EAAU,8BAKV,EAAU,EAAQ,OAAO,CAAC,WAAY,KAAO,IAMjD,IAAM,EAAgB,MAAM,EAAY,OAAO,CAAC,EAAK,EAAK,SACtD,EACA,mBAHE,CAAA,CAIN,GACA,GAAI,CAAC,EAID,OAHA,EAAI,IADY,MACF,CAAG,IACjB,EAAI,GAAG,CAAC,eACS,MAAjB,CAAwB,CAApB,IAAyB,KAAhB,EAAoB,EAAI,SAAS,CAAC,IAAI,CAAC,EAAK,QAAQ,OAAO,IACjE,KAEX,GAAM,SAAE,CAAO,QAAE,CAAM,YAAE,CAAU,WAAE,CAAS,aAAE,CAAW,mBAAE,CAAiB,qBAAE,CAAmB,sBAAE,CAAoB,yBAAE,CAAuB,kBAAE,CAAgB,yBAAE,CAAuB,uBAAE,CAAqB,CAAE,CAAG,EACnN,EAAoB,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,GACvC,EAAQ,EAAQ,GAAkB,aAAa,CAAC,EAAkB,EAAI,EAAkB,MAAM,CAAC,EAAA,AAAiB,EAC9G,EAAY,WAEa,MAAvB,EAA8B,KAAK,EAAI,EAAoB,SAAA,AAAS,EAAE,AACtE,MAAM,EAAoB,SAAS,CAAC,EAAK,EAAK,GAAW,GAEzD,EAAI,GAAG,CAAC,gCAEL,MAEX,GAAI,GAAS,CAAC,EAAa,CACvB,IAAM,GAAgB,CAAQ,EAAkB,MAAM,CAAC,EAAiB,CAClE,EAAgB,EAAkB,aAAa,CAAC,EAAkB,CACxE,GAAI,GACI,CAA2B,MAAb,KADH,GACW,EAAc,CAAC,EAAe,CACpD,GAAI,EAAW,YAAY,CAAC,WAAW,CACnC,CADqC,MAC9B,MAAM,GAEjB,OAAM,IAAI,EAAA,eAAe,AAC7B,CAER,CACA,IAAI,EAAW,MACX,GAAU,EAAY,IAAb,CAAkB,EAAK,EAAD,EAG/B,EAAW,AAAa,OAHqB,KAC7C,EAAW,CAAA,EAEwB,IAAM,CAAA,EAE7C,IAAM,GACgB,IAAtB,EAAY,EAAkB,GAAb,EAEjB,CAAC,EAKK,EAAqB,GAAS,CAAC,EAIjC,GAAyB,GACzB,CAAA,EAAA,EAAA,iBADkD,IAClD,AAAqB,EAAC,CAClB,KAAM,aAbqF,aAc3F,wBACA,CACJ,GAEJ,IAAM,EAAS,EAAI,MAAM,EAAI,MACvB,EAAS,CAAA,EAAA,EAAA,SAAA,AAAS,IAClB,EAAa,EAAO,kBAAkB,GACtC,EAAU,QACZ,EACA,oBACA,WAAY,CACR,aAAc,CACV,gBAAgB,CAAQ,EAAW,YAAY,CAAC,cAAc,AAClE,EACA,iBAAiB,CAAQ,EAAW,eAAe,yBACnD,EACA,iBAAkB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,oBACtC,kBAAmB,EAAW,SAAS,CACvC,UAAW,EAAI,SAAS,CACxB,QAAS,AAAC,IACN,EAAI,EAAE,CAAC,QAAS,EACpB,EACA,sBAAkB,EAClB,8BAA+B,CAAC,EAAO,EAAU,EAAc,IAAa,EAAY,cAAc,CAAC,EAAK,EAAO,EAAc,EAAY,EACjJ,EACA,cAAe,SACX,CACJ,CACJ,EACM,EAAc,IAAI,EAAA,eAAe,CAAC,GAClC,EAAc,IAAI,EAAA,gBAAgB,CAAC,GACnC,EAAU,EAAA,kBAAkB,CAAC,mBAAmB,CAAC,EAAa,CAAA,EAAA,EAAA,sBAAA,AAAsB,EAAC,IAC3F,GAAI,CACA,IAAM,EAAoB,MAAO,GACtB,EAAY,MAAM,CAAC,EAAS,GAAS,OAAO,CAAC,KAChD,GAAI,CAAC,EAAM,OACX,EAAK,aAAa,CAAC,CACf,mBAAoB,EAAI,UAAU,CAClC,YAAY,CAChB,GACA,IAAM,EAAqB,EAAO,qBAAqB,GAEvD,GAAI,CAAC,EACD,OAEJ,GAAI,EAAmB,GAAG,CAAC,EAHF,kBAGwB,EAAA,cAAc,CAAC,aAAa,CAAE,YAC3E,QAAQ,IAAI,CAAC,CAAC,2BAA2B,EAAE,EAAmB,GAAG,CAAC,kBAAkB,qEAAqE,CAAC,EAG9J,IAAM,EAAQ,EAAmB,GAAG,CAAC,cACrC,GAAI,EAAO,CACP,IAAM,EAAO,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAO,CACjC,EAAK,aAAa,CAAC,CACf,aAAc,EACd,aAAc,EACd,iBAAkB,CACtB,GACA,EAAK,UAAU,CAAC,EACpB,MACI,CADG,CACE,UAAU,CAAC,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAE9C,GAEE,GAAgB,CAAoC,CAAA,EAAA,EAAA,EAA5B,YAA4B,AAAc,EAAC,EAAK,eACxE,EAAiB,MAAO,QACtB,EA4FI,EA3FR,IAAM,EAAoB,MAAO,oBAAE,CAAkB,CAAE,IACnD,GAAI,CACA,GAAI,CAAC,GAAiB,GAAwB,GAA2B,CAAC,EAKtE,OAJA,EAAI,SADsF,CAC5E,CAAG,IAEjB,EAAI,SAAS,CAAC,iBAAkB,eAChC,EAAI,GAAG,CAAC,gCACD,KAEX,IAAM,EAAW,MAAM,EAAkB,EACzC,GAAI,YAAY,CAAG,EAAQ,UAAU,CAAC,YAAY,CAClD,IAAI,EAAmB,EAAQ,UAAU,CAAC,gBAAgB,CAGtD,GACI,EAAI,SAAS,EAAE,CACf,CAFc,CAEV,SAAS,CAAC,GACd,EAAmB,QAG3B,IAAM,EAAY,EAAQ,UAAU,CAAC,aAAa,CAGlD,IAAI,EA6BA,OADA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,EAAU,EAAQ,UAAU,CAAC,gBAAgB,EACnF,IA7BA,EACP,IAAM,EAAO,MAAM,EAAS,IAAI,GAE1B,EAAU,CAAA,EAAA,EAAA,yBAAyB,AAAzB,EAA0B,EAAS,OAAO,EACtD,IACA,CAAO,CAAC,EAAA,GADG,mBACmB,CAAC,CAAG,CAAA,EAElC,CAAC,CAAO,CAAC,eAAe,EAAI,EAAK,IAAI,EAAE,CACvC,CAAO,CAAC,eAAe,CAAG,EAAK,IAAI,AAAJ,EAEnC,IAAM,EAAa,KAAkD,IAA3C,EAAQ,UAAU,CAAC,mBAAmB,IAAoB,EAAQ,UAAU,CAAC,mBAAmB,EAAI,EAAA,cAAA,AAAc,GAAW,AAAR,EAAgB,UAAU,CAAC,mBAAmB,CACvL,EAAS,KAA8C,IAAvC,EAAQ,UAAU,CAAC,eAAe,EAAoB,EAAQ,UAAU,CAAC,eAAe,EAAI,EAAA,cAAc,MAAG,EAAY,EAAQ,UAAU,CAAC,eAAe,CAcjL,MAZmB,CAYZ,AAXH,MAAO,CACH,KAAM,EAAA,eAAe,CAAC,SAAS,CAC/B,OAAQ,EAAS,MAAM,CACvB,KAAM,OAAO,IAAI,CAAC,MAAM,EAAK,WAAW,YACxC,CACJ,EACA,aAAc,YACV,SACA,CACJ,CACJ,CAEJ,CAKJ,CAAE,KALS,CAKF,EAAK,CAeV,MAZ0B,MAAtB,EAA6B,KAAK,EAAI,EAAmB,OAAA,AAAO,EAAE,CAElE,MAAM,EAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAmB,AAAnB,EAAoB,oBAClC,EACA,sBACJ,EACJ,GAAG,AATgB,EASJ,GAEb,CACV,CACJ,EACM,EAAa,MAAM,EAAY,cAAc,CAAC,KAChD,aACA,WACA,EACA,UAAW,EAAA,SAAS,CAAC,SAAS,CAC9B,YAAY,oBACZ,EACA,kBAAmB,wBACnB,0BACA,oBACA,EACA,UAAW,EAAI,SAAS,eACxB,CACJ,GAEA,GAAI,CAAC,EACD,KADQ,EACD,KAEX,GAAI,CAAe,MAAd,CAAqB,EAAmD,AAA1C,GAAJ,IAAK,EAAoB,EAAW,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,IAAM,EAAA,eAAe,CAAC,SAAS,CAE9I,CAFgJ,KAE1I,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,kDAAkD,EAAgB,MAAd,CAAqB,EAAS,AAA2C,GAA/C,IAAK,EAAqB,EAAW,KAAA,AAAK,EAAY,KAAK,EAAI,EAAmB,IAAI,CAAA,CAAE,EAAG,oBAAqB,CACjO,MAAO,OACP,WAAY,GACZ,aAAc,EAClB,EAEA,CAAC,GACD,EAAI,SAAS,CADG,AACF,iBAAkB,EAAuB,cAAgB,EAAW,MAAM,CAAG,OAAS,EAAW,OAAO,CAAG,QAAU,OAGnI,GACA,EAAI,QADS,CACA,CAAC,gBAAiB,2DAEnC,IAAM,EAAU,CAAA,EAAA,EAAA,2BAAA,AAA2B,EAAC,EAAW,KAAK,CAAC,OAAO,EAcpE,OAbI,AAAE,CAAD,EAAkB,GACnB,EADwB,AAChB,GADmB,GACb,CAAC,EAAA,sBAAsB,GAIrC,EAAW,YAAY,EAAK,EAAI,AAAL,SAAc,CAAC,kBAAqB,EAAD,AAAS,GAAG,CAAC,kBAAkB,AAC7F,EAAQ,GAAG,CAAC,gBAAiB,CAAA,EAAA,EAAA,qBAAqB,AAArB,EAAsB,EAAW,YAAY,GAE9E,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAChC,IAAI,SAAS,EAAW,KAAK,CAAC,IAAI,CAAE,SAChC,EACA,OAAQ,EAAW,KAAK,CAAC,MAAM,EAAI,GACvC,IACO,IACX,EAGI,EACA,MAAM,EAAe,EADT,CAGZ,MAAM,EAAO,qBAAqB,CAAC,EAAI,OAAO,CAAE,IAAI,EAAO,KAAK,CAAC,EAAA,cAAc,CAAC,aAAa,CAAE,CACvF,SAAU,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAChC,KAAM,EAAA,QAAQ,CAAC,MAAM,CACrB,WAAY,CACR,cAAe,EACf,cAAe,EAAI,GACvB,AAD0B,CAE9B,EAAG,GAEf,CAAE,MAAO,EAAK,CAeV,GAdM,aAAe,EAAA,eAAe,EAEhC,CAFmC,KAE7B,EAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,oBAClC,uBACA,CACJ,EACJ,GAAG,AATgB,EASJ,GAIf,EAAO,MAAM,EAKjB,OAHA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,IAAI,SAAS,KAAM,CAC5D,OAAQ,GACZ,IACO,IACX,CACJ,EAEA,qCAAqC","ignoreList":[3]}