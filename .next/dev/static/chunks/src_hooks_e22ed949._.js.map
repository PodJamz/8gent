{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useFileAttachment.ts"],"sourcesContent":["'use client';\n\nimport { useState, useCallback, useRef } from 'react';\n\nexport interface FileAttachment {\n  id: string;\n  file: File;\n  name: string;\n  type: string;\n  size: number;\n  preview?: string; // Base64 data URL for images\n}\n\nexport interface UseFileAttachmentOptions {\n  maxFiles?: number;\n  maxSizeBytes?: number;\n  acceptedTypes?: string[];\n  onError?: (error: string) => void;\n}\n\nconst DEFAULT_MAX_SIZE = 10 * 1024 * 1024; // 10MB\nconst DEFAULT_MAX_FILES = 5;\nconst DEFAULT_ACCEPTED_TYPES = [\n  'image/*',\n  'application/pdf',\n  'text/plain',\n  'text/markdown',\n  'application/json',\n  'text/csv',\n];\n\nexport function useFileAttachment(options: UseFileAttachmentOptions = {}) {\n  const {\n    maxFiles = DEFAULT_MAX_FILES,\n    maxSizeBytes = DEFAULT_MAX_SIZE,\n    acceptedTypes = DEFAULT_ACCEPTED_TYPES,\n    onError,\n  } = options;\n\n  const [attachments, setAttachments] = useState<FileAttachment[]>([]);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const fileInputRef = useRef<HTMLInputElement>(null);\n\n  const generateId = () => `attach_${Date.now()}_${Math.random().toString(36).slice(2, 9)}`;\n\n  const isAcceptedType = useCallback((file: File): boolean => {\n    return acceptedTypes.some(type => {\n      if (type.endsWith('/*')) {\n        const category = type.split('/')[0];\n        return file.type.startsWith(`${category}/`);\n      }\n      return file.type === type;\n    });\n  }, [acceptedTypes]);\n\n  const createPreview = useCallback((file: File): Promise<string | undefined> => {\n    return new Promise((resolve) => {\n      if (!file.type.startsWith('image/')) {\n        resolve(undefined);\n        return;\n      }\n\n      const reader = new FileReader();\n      reader.onload = () => resolve(reader.result as string);\n      reader.onerror = () => resolve(undefined);\n      reader.readAsDataURL(file);\n    });\n  }, []);\n\n  const addFiles = useCallback(async (files: FileList | File[]) => {\n    const fileArray = Array.from(files);\n\n    // Check max files limit\n    if (attachments.length + fileArray.length > maxFiles) {\n      onError?.(`Maximum ${maxFiles} files allowed`);\n      return;\n    }\n\n    setIsProcessing(true);\n\n    const newAttachments: FileAttachment[] = [];\n\n    for (const file of fileArray) {\n      // Validate file type\n      if (!isAcceptedType(file)) {\n        onError?.(`File type not supported: ${file.type || 'unknown'}`);\n        continue;\n      }\n\n      // Validate file size\n      if (file.size > maxSizeBytes) {\n        const maxSizeMB = Math.round(maxSizeBytes / (1024 * 1024));\n        onError?.(`File too large: ${file.name} (max ${maxSizeMB}MB)`);\n        continue;\n      }\n\n      const preview = await createPreview(file);\n\n      newAttachments.push({\n        id: generateId(),\n        file,\n        name: file.name,\n        type: file.type,\n        size: file.size,\n        preview,\n      });\n    }\n\n    setAttachments(prev => [...prev, ...newAttachments]);\n    setIsProcessing(false);\n  }, [attachments.length, maxFiles, maxSizeBytes, isAcceptedType, createPreview, onError]);\n\n  const removeAttachment = useCallback((id: string) => {\n    setAttachments(prev => prev.filter(a => a.id !== id));\n  }, []);\n\n  const clearAttachments = useCallback(() => {\n    setAttachments([]);\n  }, []);\n\n  const openFilePicker = useCallback(() => {\n    fileInputRef.current?.click();\n  }, []);\n\n  const handleFileInputChange = useCallback((e: React.ChangeEvent<HTMLInputElement>) => {\n    if (e.target.files && e.target.files.length > 0) {\n      addFiles(e.target.files);\n      // Reset input so same file can be selected again\n      e.target.value = '';\n    }\n  }, [addFiles]);\n\n  // Format file size for display\n  const formatFileSize = useCallback((bytes: number): string => {\n    if (bytes < 1024) return `${bytes} B`;\n    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`;\n    return `${(bytes / (1024 * 1024)).toFixed(1)} MB`;\n  }, []);\n\n  // Get files ready for upload (as FormData-compatible array)\n  const getFilesForUpload = useCallback(() => {\n    return attachments.map(a => a.file);\n  }, [attachments]);\n\n  // Convert attachments to base64 for API calls\n  const getAttachmentsAsBase64 = useCallback(async (): Promise<Array<{\n    name: string;\n    type: string;\n    data: string;\n  }>> => {\n    const results = await Promise.all(\n      attachments.map(async (attachment) => {\n        const data = await new Promise<string>((resolve) => {\n          const reader = new FileReader();\n          reader.onload = () => {\n            const base64 = (reader.result as string).split(',')[1];\n            resolve(base64);\n          };\n          reader.readAsDataURL(attachment.file);\n        });\n\n        return {\n          name: attachment.name,\n          type: attachment.type,\n          data,\n        };\n      })\n    );\n\n    return results;\n  }, [attachments]);\n\n  return {\n    attachments,\n    isProcessing,\n    fileInputRef,\n    addFiles,\n    removeAttachment,\n    clearAttachments,\n    openFilePicker,\n    handleFileInputChange,\n    formatFileSize,\n    getFilesForUpload,\n    getAttachmentsAsBase64,\n    hasAttachments: attachments.length > 0,\n    acceptedTypesString: acceptedTypes.join(','),\n  };\n}\n"],"names":[],"mappings":";;;;AAEA;;AAFA;;AAoBA,MAAM,mBAAmB,KAAK,OAAO,MAAM,OAAO;AAClD,MAAM,oBAAoB;AAC1B,MAAM,yBAAyB;IAC7B;IACA;IACA;IACA;IACA;IACA;CACD;AAEM,SAAS,kBAAkB,UAAoC,CAAC,CAAC;;IACtE,MAAM,EACJ,WAAW,iBAAiB,EAC5B,eAAe,gBAAgB,EAC/B,gBAAgB,sBAAsB,EACtC,OAAO,EACR,GAAG;IAEJ,MAAM,CAAC,aAAa,eAAe,GAAG,IAAA,kXAAQ,EAAmB,EAAE;IACnE,MAAM,CAAC,cAAc,gBAAgB,GAAG,IAAA,kXAAQ,EAAC;IACjD,MAAM,eAAe,IAAA,gXAAM,EAAmB;IAE9C,MAAM,aAAa,IAAM,CAAC,OAAO,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,KAAK,CAAC,GAAG,IAAI;IAEzF,MAAM,iBAAiB,IAAA,qXAAW;yDAAC,CAAC;YAClC,OAAO,cAAc,IAAI;iEAAC,CAAA;oBACxB,IAAI,KAAK,QAAQ,CAAC,OAAO;wBACvB,MAAM,WAAW,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBACnC,OAAO,KAAK,IAAI,CAAC,UAAU,CAAC,GAAG,SAAS,CAAC,CAAC;oBAC5C;oBACA,OAAO,KAAK,IAAI,KAAK;gBACvB;;QACF;wDAAG;QAAC;KAAc;IAElB,MAAM,gBAAgB,IAAA,qXAAW;wDAAC,CAAC;YACjC,OAAO,IAAI;gEAAQ,CAAC;oBAClB,IAAI,CAAC,KAAK,IAAI,CAAC,UAAU,CAAC,WAAW;wBACnC,QAAQ;wBACR;oBACF;oBAEA,MAAM,SAAS,IAAI;oBACnB,OAAO,MAAM;wEAAG,IAAM,QAAQ,OAAO,MAAM;;oBAC3C,OAAO,OAAO;wEAAG,IAAM,QAAQ;;oBAC/B,OAAO,aAAa,CAAC;gBACvB;;QACF;uDAAG,EAAE;IAEL,MAAM,WAAW,IAAA,qXAAW;mDAAC,OAAO;YAClC,MAAM,YAAY,MAAM,IAAI,CAAC;YAE7B,wBAAwB;YACxB,IAAI,YAAY,MAAM,GAAG,UAAU,MAAM,GAAG,UAAU;gBACpD,UAAU,CAAC,QAAQ,EAAE,SAAS,cAAc,CAAC;gBAC7C;YACF;YAEA,gBAAgB;YAEhB,MAAM,iBAAmC,EAAE;YAE3C,KAAK,MAAM,QAAQ,UAAW;gBAC5B,qBAAqB;gBACrB,IAAI,CAAC,eAAe,OAAO;oBACzB,UAAU,CAAC,yBAAyB,EAAE,KAAK,IAAI,IAAI,WAAW;oBAC9D;gBACF;gBAEA,qBAAqB;gBACrB,IAAI,KAAK,IAAI,GAAG,cAAc;oBAC5B,MAAM,YAAY,KAAK,KAAK,CAAC,eAAe,CAAC,OAAO,IAAI;oBACxD,UAAU,CAAC,gBAAgB,EAAE,KAAK,IAAI,CAAC,MAAM,EAAE,UAAU,GAAG,CAAC;oBAC7D;gBACF;gBAEA,MAAM,UAAU,MAAM,cAAc;gBAEpC,eAAe,IAAI,CAAC;oBAClB,IAAI;oBACJ;oBACA,MAAM,KAAK,IAAI;oBACf,MAAM,KAAK,IAAI;oBACf,MAAM,KAAK,IAAI;oBACf;gBACF;YACF;YAEA;2DAAe,CAAA,OAAQ;2BAAI;2BAAS;qBAAe;;YACnD,gBAAgB;QAClB;kDAAG;QAAC,YAAY,MAAM;QAAE;QAAU;QAAc;QAAgB;QAAe;KAAQ;IAEvF,MAAM,mBAAmB,IAAA,qXAAW;2DAAC,CAAC;YACpC;mEAAe,CAAA,OAAQ,KAAK,MAAM;2EAAC,CAAA,IAAK,EAAE,EAAE,KAAK;;;QACnD;0DAAG,EAAE;IAEL,MAAM,mBAAmB,IAAA,qXAAW;2DAAC;YACnC,eAAe,EAAE;QACnB;0DAAG,EAAE;IAEL,MAAM,iBAAiB,IAAA,qXAAW;yDAAC;YACjC,aAAa,OAAO,EAAE;QACxB;wDAAG,EAAE;IAEL,MAAM,wBAAwB,IAAA,qXAAW;gEAAC,CAAC;YACzC,IAAI,EAAE,MAAM,CAAC,KAAK,IAAI,EAAE,MAAM,CAAC,KAAK,CAAC,MAAM,GAAG,GAAG;gBAC/C,SAAS,EAAE,MAAM,CAAC,KAAK;gBACvB,iDAAiD;gBACjD,EAAE,MAAM,CAAC,KAAK,GAAG;YACnB;QACF;+DAAG;QAAC;KAAS;IAEb,+BAA+B;IAC/B,MAAM,iBAAiB,IAAA,qXAAW;yDAAC,CAAC;YAClC,IAAI,QAAQ,MAAM,OAAO,GAAG,MAAM,EAAE,CAAC;YACrC,IAAI,QAAQ,OAAO,MAAM,OAAO,GAAG,CAAC,QAAQ,IAAI,EAAE,OAAO,CAAC,GAAG,GAAG,CAAC;YACjE,OAAO,GAAG,CAAC,QAAQ,CAAC,OAAO,IAAI,CAAC,EAAE,OAAO,CAAC,GAAG,GAAG,CAAC;QACnD;wDAAG,EAAE;IAEL,4DAA4D;IAC5D,MAAM,oBAAoB,IAAA,qXAAW;4DAAC;YACpC,OAAO,YAAY,GAAG;oEAAC,CAAA,IAAK,EAAE,IAAI;;QACpC;2DAAG;QAAC;KAAY;IAEhB,8CAA8C;IAC9C,MAAM,yBAAyB,IAAA,qXAAW;iEAAC;YAKzC,MAAM,UAAU,MAAM,QAAQ,GAAG,CAC/B,YAAY,GAAG;yEAAC,OAAO;oBACrB,MAAM,OAAO,MAAM,IAAI;iFAAgB,CAAC;4BACtC,MAAM,SAAS,IAAI;4BACnB,OAAO,MAAM;yFAAG;oCACd,MAAM,SAAS,AAAC,OAAO,MAAM,CAAY,KAAK,CAAC,IAAI,CAAC,EAAE;oCACtD,QAAQ;gCACV;;4BACA,OAAO,aAAa,CAAC,WAAW,IAAI;wBACtC;;oBAEA,OAAO;wBACL,MAAM,WAAW,IAAI;wBACrB,MAAM,WAAW,IAAI;wBACrB;oBACF;gBACF;;YAGF,OAAO;QACT;gEAAG;QAAC;KAAY;IAEhB,OAAO;QACL;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,gBAAgB,YAAY,MAAM,GAAG;QACrC,qBAAqB,cAAc,IAAI,CAAC;IAC1C;AACF;GA5JgB"}},
    {"offset": {"line": 213, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useVoiceRecorder.ts"],"sourcesContent":["'use client';\n\nimport { useState, useCallback, useRef, useEffect } from 'react';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport type RecordingStatus = 'idle' | 'recording' | 'processing' | 'error';\n\nexport interface RecordingError {\n  type: 'permission-denied' | 'not-supported' | 'no-audio' | 'unknown';\n  message: string;\n}\n\nexport interface UseVoiceRecorderReturn {\n  // State\n  status: RecordingStatus;\n  isRecording: boolean;\n  duration: number; // seconds\n  audioLevels: number[]; // Array of recent audio levels (0-1) for waveform\n  error: RecordingError | null;\n\n  // Capabilities\n  isSupported: boolean;\n\n  // Actions\n  startRecording: () => Promise<void>;\n  stopRecording: () => Promise<Blob | null>;\n  cancelRecording: () => void;\n}\n\nexport interface UseVoiceRecorderOptions {\n  maxDuration?: number; // Max recording duration in seconds (default: 120)\n  sampleRate?: number; // Audio sample rate (default: 16000 for Whisper)\n  levelsCount?: number; // Number of audio levels to track for waveform (default: 20)\n  onMaxDurationReached?: () => void;\n}\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst DEFAULT_MAX_DURATION = 120; // 2 minutes\nconst DEFAULT_SAMPLE_RATE = 16000; // Optimal for Whisper\nconst DEFAULT_LEVELS_COUNT = 20;\n\n// ============================================================================\n// Helpers\n// ============================================================================\n\nfunction getErrorMessage(type: RecordingError['type']): string {\n  switch (type) {\n    case 'permission-denied':\n      return 'Microphone access denied. Please enable microphone permissions.';\n    case 'not-supported':\n      return 'Audio recording is not supported in this browser.';\n    case 'no-audio':\n      return 'No audio input detected. Please check your microphone.';\n    default:\n      return 'An error occurred while recording. Please try again.';\n  }\n}\n\n// ============================================================================\n// Hook\n// ============================================================================\n\nexport function useVoiceRecorder(\n  options: UseVoiceRecorderOptions = {}\n): UseVoiceRecorderReturn {\n  const {\n    maxDuration = DEFAULT_MAX_DURATION,\n    levelsCount = DEFAULT_LEVELS_COUNT,\n    onMaxDurationReached,\n  } = options;\n\n  // State\n  const [status, setStatus] = useState<RecordingStatus>('idle');\n  const [duration, setDuration] = useState(0);\n  const [audioLevels, setAudioLevels] = useState<number[]>(\n    Array(levelsCount).fill(0)\n  );\n  const [error, setError] = useState<RecordingError | null>(null);\n\n  // Refs\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const streamRef = useRef<MediaStream | null>(null);\n  const chunksRef = useRef<Blob[]>([]);\n  const durationIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const levelsIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const startTimeRef = useRef<number>(0);\n\n  // Check browser support\n  const isSupported =\n    typeof window !== 'undefined' &&\n    typeof navigator !== 'undefined' &&\n    !!navigator.mediaDevices?.getUserMedia &&\n    typeof MediaRecorder !== 'undefined';\n\n  // Cleanup function\n  const cleanup = useCallback(() => {\n    // Stop intervals\n    if (durationIntervalRef.current) {\n      clearInterval(durationIntervalRef.current);\n      durationIntervalRef.current = null;\n    }\n    if (levelsIntervalRef.current) {\n      clearInterval(levelsIntervalRef.current);\n      levelsIntervalRef.current = null;\n    }\n\n    // Stop media recorder\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\n      try {\n        mediaRecorderRef.current.stop();\n      } catch {\n        // Ignore errors when stopping\n      }\n    }\n\n    // Stop all tracks\n    if (streamRef.current) {\n      streamRef.current.getTracks().forEach((track) => track.stop());\n      streamRef.current = null;\n    }\n\n    // Close audio context\n    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\n      audioContextRef.current.close();\n      audioContextRef.current = null;\n    }\n\n    analyserRef.current = null;\n    mediaRecorderRef.current = null;\n    chunksRef.current = [];\n  }, []);\n\n  // Update audio levels for waveform visualization\n  const updateAudioLevels = useCallback(() => {\n    if (!analyserRef.current) return;\n\n    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);\n    analyserRef.current.getByteFrequencyData(dataArray);\n\n    // Calculate average level\n    let sum = 0;\n    for (let i = 0; i < dataArray.length; i++) {\n      sum += dataArray[i];\n    }\n    const average = sum / dataArray.length / 255; // Normalize to 0-1\n\n    // Add new level and remove oldest\n    setAudioLevels((prev) => {\n      const newLevels = [...prev.slice(1), average];\n      return newLevels;\n    });\n  }, []);\n\n  // Start recording\n  const startRecording = useCallback(async () => {\n    if (!isSupported) {\n      const err: RecordingError = {\n        type: 'not-supported',\n        message: getErrorMessage('not-supported'),\n      };\n      setError(err);\n      setStatus('error');\n      return;\n    }\n\n    // Reset state\n    setError(null);\n    setDuration(0);\n    setAudioLevels(Array(levelsCount).fill(0));\n    chunksRef.current = [];\n\n    try {\n      // Request microphone access\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          echoCancellation: true,\n          noiseSuppression: true,\n          autoGainControl: true,\n        },\n      });\n      streamRef.current = stream;\n\n      // Set up audio context and analyser for levels\n      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;\n      const audioContext = new AudioContextClass();\n      audioContextRef.current = audioContext;\n\n      const analyser = audioContext.createAnalyser();\n      analyser.fftSize = 256;\n      analyser.smoothingTimeConstant = 0.5;\n      analyserRef.current = analyser;\n\n      const source = audioContext.createMediaStreamSource(stream);\n      source.connect(analyser);\n\n      // Determine the best mime type\n      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')\n        ? 'audio/webm;codecs=opus'\n        : MediaRecorder.isTypeSupported('audio/webm')\n        ? 'audio/webm'\n        : MediaRecorder.isTypeSupported('audio/mp4')\n        ? 'audio/mp4'\n        : 'audio/wav';\n\n      // Create media recorder\n      const mediaRecorder = new MediaRecorder(stream, {\n        mimeType,\n      });\n      mediaRecorderRef.current = mediaRecorder;\n\n      // Handle data available\n      mediaRecorder.ondataavailable = (event) => {\n        if (event.data.size > 0) {\n          chunksRef.current.push(event.data);\n        }\n      };\n\n      // Start recording\n      mediaRecorder.start(100); // Collect data every 100ms\n      setStatus('recording');\n      startTimeRef.current = Date.now();\n\n      // Start duration timer\n      durationIntervalRef.current = setInterval(() => {\n        const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);\n        setDuration(elapsed);\n\n        // Check max duration\n        if (elapsed >= maxDuration) {\n          onMaxDurationReached?.();\n        }\n      }, 100);\n\n      // Start audio levels updates\n      levelsIntervalRef.current = setInterval(updateAudioLevels, 50);\n    } catch (err) {\n      cleanup();\n\n      let errorType: RecordingError['type'] = 'unknown';\n      if (err instanceof DOMException) {\n        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {\n          errorType = 'permission-denied';\n        } else if (err.name === 'NotFoundError') {\n          errorType = 'no-audio';\n        }\n      }\n\n      const recordingError: RecordingError = {\n        type: errorType,\n        message: getErrorMessage(errorType),\n      };\n      setError(recordingError);\n      setStatus('error');\n    }\n  }, [isSupported, levelsCount, maxDuration, onMaxDurationReached, cleanup, updateAudioLevels]);\n\n  // Stop recording and return audio blob\n  const stopRecording = useCallback(async (): Promise<Blob | null> => {\n    if (!mediaRecorderRef.current || status !== 'recording') {\n      return null;\n    }\n\n    setStatus('processing');\n\n    return new Promise((resolve) => {\n      const mediaRecorder = mediaRecorderRef.current!;\n\n      mediaRecorder.onstop = () => {\n        // Create blob from chunks\n        const mimeType = mediaRecorder.mimeType;\n        const blob = new Blob(chunksRef.current, { type: mimeType });\n\n        cleanup();\n        setStatus('idle');\n        setAudioLevels(Array(levelsCount).fill(0));\n\n        resolve(blob);\n      };\n\n      mediaRecorder.stop();\n    });\n  }, [status, cleanup, levelsCount]);\n\n  // Cancel recording without returning audio\n  const cancelRecording = useCallback(() => {\n    cleanup();\n    setStatus('idle');\n    setDuration(0);\n    setAudioLevels(Array(levelsCount).fill(0));\n    setError(null);\n  }, [cleanup, levelsCount]);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      cleanup();\n    };\n  }, [cleanup]);\n\n  return {\n    // State\n    status,\n    isRecording: status === 'recording',\n    duration,\n    audioLevels,\n    error,\n\n    // Capabilities\n    isSupported,\n\n    // Actions\n    startRecording,\n    stopRecording,\n    cancelRecording,\n  };\n}\n"],"names":[],"mappings":";;;;AAEA;;AAFA;;AAuCA,+EAA+E;AAC/E,YAAY;AACZ,+EAA+E;AAE/E,MAAM,uBAAuB,KAAK,YAAY;AAC9C,MAAM,sBAAsB,OAAO,sBAAsB;AACzD,MAAM,uBAAuB;AAE7B,+EAA+E;AAC/E,UAAU;AACV,+EAA+E;AAE/E,SAAS,gBAAgB,IAA4B;IACnD,OAAQ;QACN,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;AAMO,SAAS,iBACd,UAAmC,CAAC,CAAC;;IAErC,MAAM,EACJ,cAAc,oBAAoB,EAClC,cAAc,oBAAoB,EAClC,oBAAoB,EACrB,GAAG;IAEJ,QAAQ;IACR,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,kXAAQ,EAAkB;IACtD,MAAM,CAAC,UAAU,YAAY,GAAG,IAAA,kXAAQ,EAAC;IACzC,MAAM,CAAC,aAAa,eAAe,GAAG,IAAA,kXAAQ,EAC5C,MAAM,aAAa,IAAI,CAAC;IAE1B,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,kXAAQ,EAAwB;IAE1D,OAAO;IACP,MAAM,mBAAmB,IAAA,gXAAM,EAAuB;IACtD,MAAM,kBAAkB,IAAA,gXAAM,EAAsB;IACpD,MAAM,cAAc,IAAA,gXAAM,EAAsB;IAChD,MAAM,YAAY,IAAA,gXAAM,EAAqB;IAC7C,MAAM,YAAY,IAAA,gXAAM,EAAS,EAAE;IACnC,MAAM,sBAAsB,IAAA,gXAAM,EAAwB;IAC1D,MAAM,oBAAoB,IAAA,gXAAM,EAAwB;IACxD,MAAM,eAAe,IAAA,gXAAM,EAAS;IAEpC,wBAAwB;IACxB,MAAM,cACJ,+CAAkB,eAClB,OAAO,cAAc,eACrB,CAAC,CAAC,UAAU,YAAY,EAAE,gBAC1B,OAAO,kBAAkB;IAE3B,mBAAmB;IACnB,MAAM,UAAU,IAAA,qXAAW;iDAAC;YAC1B,iBAAiB;YACjB,IAAI,oBAAoB,OAAO,EAAE;gBAC/B,cAAc,oBAAoB,OAAO;gBACzC,oBAAoB,OAAO,GAAG;YAChC;YACA,IAAI,kBAAkB,OAAO,EAAE;gBAC7B,cAAc,kBAAkB,OAAO;gBACvC,kBAAkB,OAAO,GAAG;YAC9B;YAEA,sBAAsB;YACtB,IAAI,iBAAiB,OAAO,IAAI,iBAAiB,OAAO,CAAC,KAAK,KAAK,YAAY;gBAC7E,IAAI;oBACF,iBAAiB,OAAO,CAAC,IAAI;gBAC/B,EAAE,OAAM;gBACN,8BAA8B;gBAChC;YACF;YAEA,kBAAkB;YAClB,IAAI,UAAU,OAAO,EAAE;gBACrB,UAAU,OAAO,CAAC,SAAS,GAAG,OAAO;6DAAC,CAAC,QAAU,MAAM,IAAI;;gBAC3D,UAAU,OAAO,GAAG;YACtB;YAEA,sBAAsB;YACtB,IAAI,gBAAgB,OAAO,IAAI,gBAAgB,OAAO,CAAC,KAAK,KAAK,UAAU;gBACzE,gBAAgB,OAAO,CAAC,KAAK;gBAC7B,gBAAgB,OAAO,GAAG;YAC5B;YAEA,YAAY,OAAO,GAAG;YACtB,iBAAiB,OAAO,GAAG;YAC3B,UAAU,OAAO,GAAG,EAAE;QACxB;gDAAG,EAAE;IAEL,iDAAiD;IACjD,MAAM,oBAAoB,IAAA,qXAAW;2DAAC;YACpC,IAAI,CAAC,YAAY,OAAO,EAAE;YAE1B,MAAM,YAAY,IAAI,WAAW,YAAY,OAAO,CAAC,iBAAiB;YACtE,YAAY,OAAO,CAAC,oBAAoB,CAAC;YAEzC,0BAA0B;YAC1B,IAAI,MAAM;YACV,IAAK,IAAI,IAAI,GAAG,IAAI,UAAU,MAAM,EAAE,IAAK;gBACzC,OAAO,SAAS,CAAC,EAAE;YACrB;YACA,MAAM,UAAU,MAAM,UAAU,MAAM,GAAG,KAAK,mBAAmB;YAEjE,kCAAkC;YAClC;mEAAe,CAAC;oBACd,MAAM,YAAY;2BAAI,KAAK,KAAK,CAAC;wBAAI;qBAAQ;oBAC7C,OAAO;gBACT;;QACF;0DAAG,EAAE;IAEL,kBAAkB;IAClB,MAAM,iBAAiB,IAAA,qXAAW;wDAAC;YACjC,IAAI,CAAC,aAAa;gBAChB,MAAM,MAAsB;oBAC1B,MAAM;oBACN,SAAS,gBAAgB;gBAC3B;gBACA,SAAS;gBACT,UAAU;gBACV;YACF;YAEA,cAAc;YACd,SAAS;YACT,YAAY;YACZ,eAAe,MAAM,aAAa,IAAI,CAAC;YACvC,UAAU,OAAO,GAAG,EAAE;YAEtB,IAAI;gBACF,4BAA4B;gBAC5B,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;oBACvD,OAAO;wBACL,kBAAkB;wBAClB,kBAAkB;wBAClB,iBAAiB;oBACnB;gBACF;gBACA,UAAU,OAAO,GAAG;gBAEpB,+CAA+C;gBAC/C,MAAM,oBAAoB,OAAO,YAAY,IAAI,AAAC,OAAkE,kBAAkB;gBACtI,MAAM,eAAe,IAAI;gBACzB,gBAAgB,OAAO,GAAG;gBAE1B,MAAM,WAAW,aAAa,cAAc;gBAC5C,SAAS,OAAO,GAAG;gBACnB,SAAS,qBAAqB,GAAG;gBACjC,YAAY,OAAO,GAAG;gBAEtB,MAAM,SAAS,aAAa,uBAAuB,CAAC;gBACpD,OAAO,OAAO,CAAC;gBAEf,+BAA+B;gBAC/B,MAAM,WAAW,cAAc,eAAe,CAAC,4BAC3C,2BACA,cAAc,eAAe,CAAC,gBAC9B,eACA,cAAc,eAAe,CAAC,eAC9B,cACA;gBAEJ,wBAAwB;gBACxB,MAAM,gBAAgB,IAAI,cAAc,QAAQ;oBAC9C;gBACF;gBACA,iBAAiB,OAAO,GAAG;gBAE3B,wBAAwB;gBACxB,cAAc,eAAe;oEAAG,CAAC;wBAC/B,IAAI,MAAM,IAAI,CAAC,IAAI,GAAG,GAAG;4BACvB,UAAU,OAAO,CAAC,IAAI,CAAC,MAAM,IAAI;wBACnC;oBACF;;gBAEA,kBAAkB;gBAClB,cAAc,KAAK,CAAC,MAAM,2BAA2B;gBACrD,UAAU;gBACV,aAAa,OAAO,GAAG,KAAK,GAAG;gBAE/B,uBAAuB;gBACvB,oBAAoB,OAAO,GAAG;oEAAY;wBACxC,MAAM,UAAU,KAAK,KAAK,CAAC,CAAC,KAAK,GAAG,KAAK,aAAa,OAAO,IAAI;wBACjE,YAAY;wBAEZ,qBAAqB;wBACrB,IAAI,WAAW,aAAa;4BAC1B;wBACF;oBACF;mEAAG;gBAEH,6BAA6B;gBAC7B,kBAAkB,OAAO,GAAG,YAAY,mBAAmB;YAC7D,EAAE,OAAO,KAAK;gBACZ;gBAEA,IAAI,YAAoC;gBACxC,IAAI,eAAe,cAAc;oBAC/B,IAAI,IAAI,IAAI,KAAK,qBAAqB,IAAI,IAAI,KAAK,yBAAyB;wBAC1E,YAAY;oBACd,OAAO,IAAI,IAAI,IAAI,KAAK,iBAAiB;wBACvC,YAAY;oBACd;gBACF;gBAEA,MAAM,iBAAiC;oBACrC,MAAM;oBACN,SAAS,gBAAgB;gBAC3B;gBACA,SAAS;gBACT,UAAU;YACZ;QACF;uDAAG;QAAC;QAAa;QAAa;QAAa;QAAsB;QAAS;KAAkB;IAE5F,uCAAuC;IACvC,MAAM,gBAAgB,IAAA,qXAAW;uDAAC;YAChC,IAAI,CAAC,iBAAiB,OAAO,IAAI,WAAW,aAAa;gBACvD,OAAO;YACT;YAEA,UAAU;YAEV,OAAO,IAAI;+DAAQ,CAAC;oBAClB,MAAM,gBAAgB,iBAAiB,OAAO;oBAE9C,cAAc,MAAM;uEAAG;4BACrB,0BAA0B;4BAC1B,MAAM,WAAW,cAAc,QAAQ;4BACvC,MAAM,OAAO,IAAI,KAAK,UAAU,OAAO,EAAE;gCAAE,MAAM;4BAAS;4BAE1D;4BACA,UAAU;4BACV,eAAe,MAAM,aAAa,IAAI,CAAC;4BAEvC,QAAQ;wBACV;;oBAEA,cAAc,IAAI;gBACpB;;QACF;sDAAG;QAAC;QAAQ;QAAS;KAAY;IAEjC,2CAA2C;IAC3C,MAAM,kBAAkB,IAAA,qXAAW;yDAAC;YAClC;YACA,UAAU;YACV,YAAY;YACZ,eAAe,MAAM,aAAa,IAAI,CAAC;YACvC,SAAS;QACX;wDAAG;QAAC;QAAS;KAAY;IAEzB,qBAAqB;IACrB,IAAA,mXAAS;sCAAC;YACR;8CAAO;oBACL;gBACF;;QACF;qCAAG;QAAC;KAAQ;IAEZ,OAAO;QACL,QAAQ;QACR;QACA,aAAa,WAAW;QACxB;QACA;QACA;QAEA,eAAe;QACf;QAEA,UAAU;QACV;QACA;QACA;IACF;AACF;GA/PgB"}},
    {"offset": {"line": 497, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useSpeechRecognition.ts"],"sourcesContent":["'use client';\n\nimport { useState, useEffect, useCallback, useRef } from 'react';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport type SpeechRecognitionStatus =\n  | 'idle'\n  | 'listening'\n  | 'processing'\n  | 'error'\n  | 'unsupported';\n\nexport interface SpeechRecognitionError {\n  type: 'not-allowed' | 'no-speech' | 'network' | 'aborted' | 'unknown';\n  message: string;\n}\n\nexport interface UseSpeechRecognitionReturn {\n  // State\n  transcript: string;\n  interimTranscript: string;\n  status: SpeechRecognitionStatus;\n  error: SpeechRecognitionError | null;\n  isListening: boolean;\n  isSupported: boolean;\n  isMicrophoneAvailable: boolean;\n\n  // Actions\n  startListening: () => void;\n  stopListening: () => void;\n  resetTranscript: () => void;\n}\n\nexport interface UseSpeechRecognitionOptions {\n  continuous?: boolean;\n  interimResults?: boolean;\n  language?: string;\n  onResult?: (transcript: string, isFinal: boolean) => void;\n  onError?: (error: SpeechRecognitionError) => void;\n  onEnd?: () => void;\n  onStart?: () => void;\n  autoStop?: boolean; // Auto-stop after silence\n  silenceTimeout?: number; // ms before auto-stop (default 2000)\n}\n\n// ============================================================================\n// Browser Type Definitions\n// ============================================================================\n\ninterface SpeechRecognitionEvent extends Event {\n  resultIndex: number;\n  results: SpeechRecognitionResultList;\n}\n\ninterface SpeechRecognitionResultList {\n  length: number;\n  item(index: number): SpeechRecognitionResult;\n  [index: number]: SpeechRecognitionResult;\n}\n\ninterface SpeechRecognitionResult {\n  isFinal: boolean;\n  length: number;\n  item(index: number): SpeechRecognitionAlternative;\n  [index: number]: SpeechRecognitionAlternative;\n}\n\ninterface SpeechRecognitionAlternative {\n  transcript: string;\n  confidence: number;\n}\n\ninterface SpeechRecognitionErrorEvent extends Event {\n  error: string;\n  message?: string;\n}\n\ninterface SpeechRecognitionInstance extends EventTarget {\n  continuous: boolean;\n  interimResults: boolean;\n  lang: string;\n  maxAlternatives: number;\n  start: () => void;\n  stop: () => void;\n  abort: () => void;\n  onresult: ((event: SpeechRecognitionEvent) => void) | null;\n  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;\n  onend: (() => void) | null;\n  onstart: (() => void) | null;\n  onspeechend: (() => void) | null;\n  onaudiostart: (() => void) | null;\n  onaudioend: (() => void) | null;\n}\n\n// ============================================================================\n// Helpers\n// ============================================================================\n\nfunction getSpeechRecognition(): (new () => SpeechRecognitionInstance) | null {\n  if (typeof window === 'undefined') return null;\n\n  const SpeechRecognition =\n    (window as unknown as { SpeechRecognition?: new () => SpeechRecognitionInstance }).SpeechRecognition ||\n    (window as unknown as { webkitSpeechRecognition?: new () => SpeechRecognitionInstance }).webkitSpeechRecognition;\n\n  return SpeechRecognition || null;\n}\n\nfunction mapErrorType(errorCode: string): SpeechRecognitionError['type'] {\n  switch (errorCode) {\n    case 'not-allowed':\n    case 'service-not-allowed':\n      return 'not-allowed';\n    case 'no-speech':\n      return 'no-speech';\n    case 'network':\n      return 'network';\n    case 'aborted':\n      return 'aborted';\n    default:\n      return 'unknown';\n  }\n}\n\nfunction getErrorMessage(type: SpeechRecognitionError['type']): string {\n  switch (type) {\n    case 'not-allowed':\n      return 'Microphone access denied. Please enable microphone permissions.';\n    case 'no-speech':\n      return 'No speech detected. Please try again.';\n    case 'network':\n      return 'Network error. Please check your connection.';\n    case 'aborted':\n      return 'Speech recognition was cancelled.';\n    default:\n      return 'An error occurred. Please try again.';\n  }\n}\n\n// ============================================================================\n// Hook\n// ============================================================================\n\nexport function useSpeechRecognition(\n  options: UseSpeechRecognitionOptions = {}\n): UseSpeechRecognitionReturn {\n  const {\n    continuous = false,\n    interimResults = true,\n    language = 'en-US',\n    onResult,\n    onError,\n    onEnd,\n    onStart,\n    autoStop = true,\n    silenceTimeout = 2000,\n  } = options;\n\n  // State\n  const [transcript, setTranscript] = useState('');\n  const [interimTranscript, setInterimTranscript] = useState('');\n  const [status, setStatus] = useState<SpeechRecognitionStatus>('idle');\n  const [error, setError] = useState<SpeechRecognitionError | null>(null);\n  const [isMicrophoneAvailable, setIsMicrophoneAvailable] = useState(true);\n\n  // Refs\n  const recognitionRef = useRef<SpeechRecognitionInstance | null>(null);\n  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);\n  const isListeningRef = useRef(false);\n\n  // Check browser support\n  const isSupported = typeof window !== 'undefined' && getSpeechRecognition() !== null;\n\n  // Clear silence timer\n  const clearSilenceTimer = useCallback(() => {\n    if (silenceTimerRef.current) {\n      clearTimeout(silenceTimerRef.current);\n      silenceTimerRef.current = null;\n    }\n  }, []);\n\n  // Reset silence timer\n  const resetSilenceTimer = useCallback(() => {\n    clearSilenceTimer();\n    if (autoStop && isListeningRef.current) {\n      silenceTimerRef.current = setTimeout(() => {\n        if (recognitionRef.current && isListeningRef.current) {\n          recognitionRef.current.stop();\n        }\n      }, silenceTimeout);\n    }\n  }, [autoStop, silenceTimeout, clearSilenceTimer]);\n\n  // Stop listening\n  const stopListening = useCallback(() => {\n    clearSilenceTimer();\n    if (recognitionRef.current && isListeningRef.current) {\n      isListeningRef.current = false;\n      try {\n        recognitionRef.current.stop();\n      } catch {\n        // Ignore errors when stopping\n      }\n    }\n    setStatus('idle');\n  }, [clearSilenceTimer]);\n\n  // Start listening\n  const startListening = useCallback(() => {\n    if (!isSupported) {\n      setStatus('unsupported');\n      const err: SpeechRecognitionError = {\n        type: 'unknown',\n        message: 'Speech recognition is not supported in this browser.',\n      };\n      setError(err);\n      onError?.(err);\n      return;\n    }\n\n    // Reset state\n    setError(null);\n    setInterimTranscript('');\n\n    const SpeechRecognitionClass = getSpeechRecognition();\n    if (!SpeechRecognitionClass) return;\n\n    // Create new instance\n    const recognition = new SpeechRecognitionClass();\n    recognitionRef.current = recognition;\n\n    // Configure\n    recognition.continuous = continuous;\n    recognition.interimResults = interimResults;\n    recognition.lang = language;\n    recognition.maxAlternatives = 1;\n\n    // Handle results\n    recognition.onresult = (event: SpeechRecognitionEvent) => {\n      clearSilenceTimer();\n\n      let finalTranscript = '';\n      let interim = '';\n\n      for (let i = event.resultIndex; i < event.results.length; i++) {\n        const result = event.results[i];\n        const text = result[0].transcript;\n\n        if (result.isFinal) {\n          finalTranscript += text;\n        } else {\n          interim += text;\n        }\n      }\n\n      if (finalTranscript) {\n        setTranscript((prev) => prev + finalTranscript);\n        onResult?.(finalTranscript, true);\n      }\n\n      setInterimTranscript(interim);\n      if (interim) {\n        onResult?.(interim, false);\n      }\n\n      // Reset silence timer on any speech\n      resetSilenceTimer();\n    };\n\n    // Handle errors\n    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {\n      const errorType = mapErrorType(event.error);\n      const err: SpeechRecognitionError = {\n        type: errorType,\n        message: event.message || getErrorMessage(errorType),\n      };\n\n      setError(err);\n      setStatus('error');\n\n      if (errorType === 'not-allowed') {\n        setIsMicrophoneAvailable(false);\n      }\n\n      onError?.(err);\n      isListeningRef.current = false;\n    };\n\n    // Handle end\n    recognition.onend = () => {\n      clearSilenceTimer();\n      isListeningRef.current = false;\n\n      if (status !== 'error') {\n        setStatus('idle');\n      }\n\n      setInterimTranscript('');\n      onEnd?.();\n    };\n\n    // Handle start\n    recognition.onstart = () => {\n      isListeningRef.current = true;\n      setStatus('listening');\n      onStart?.();\n      resetSilenceTimer();\n    };\n\n    // Start recognition\n    try {\n      recognition.start();\n    } catch (e) {\n      const err: SpeechRecognitionError = {\n        type: 'unknown',\n        message: e instanceof Error ? e.message : 'Failed to start speech recognition',\n      };\n      setError(err);\n      setStatus('error');\n      onError?.(err);\n    }\n  }, [\n    isSupported,\n    continuous,\n    interimResults,\n    language,\n    onResult,\n    onError,\n    onEnd,\n    onStart,\n    clearSilenceTimer,\n    resetSilenceTimer,\n    status,\n  ]);\n\n  // Reset transcript\n  const resetTranscript = useCallback(() => {\n    setTranscript('');\n    setInterimTranscript('');\n  }, []);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      clearSilenceTimer();\n      if (recognitionRef.current) {\n        try {\n          recognitionRef.current.abort();\n        } catch {\n          // Ignore\n        }\n      }\n    };\n  }, [clearSilenceTimer]);\n\n  // Check initial support\n  useEffect(() => {\n    if (!isSupported) {\n      setStatus('unsupported');\n    }\n  }, [isSupported]);\n\n  return {\n    transcript,\n    interimTranscript,\n    status,\n    error,\n    isListening: status === 'listening',\n    isSupported,\n    isMicrophoneAvailable,\n    startListening,\n    stopListening,\n    resetTranscript,\n  };\n}\n"],"names":[],"mappings":";;;;AAEA;;AAFA;;AAiGA,+EAA+E;AAC/E,UAAU;AACV,+EAA+E;AAE/E,SAAS;IACP;;IAEA,MAAM,oBACJ,AAAC,OAAkF,iBAAiB,IACpG,AAAC,OAAwF,uBAAuB;IAElH,OAAO,qBAAqB;AAC9B;AAEA,SAAS,aAAa,SAAiB;IACrC,OAAQ;QACN,KAAK;QACL,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;AAEA,SAAS,gBAAgB,IAAoC;IAC3D,OAAQ;QACN,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;AAMO,SAAS,qBACd,UAAuC,CAAC,CAAC;;IAEzC,MAAM,EACJ,aAAa,KAAK,EAClB,iBAAiB,IAAI,EACrB,WAAW,OAAO,EAClB,QAAQ,EACR,OAAO,EACP,KAAK,EACL,OAAO,EACP,WAAW,IAAI,EACf,iBAAiB,IAAI,EACtB,GAAG;IAEJ,QAAQ;IACR,MAAM,CAAC,YAAY,cAAc,GAAG,IAAA,kXAAQ,EAAC;IAC7C,MAAM,CAAC,mBAAmB,qBAAqB,GAAG,IAAA,kXAAQ,EAAC;IAC3D,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,kXAAQ,EAA0B;IAC9D,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,kXAAQ,EAAgC;IAClE,MAAM,CAAC,uBAAuB,yBAAyB,GAAG,IAAA,kXAAQ,EAAC;IAEnE,OAAO;IACP,MAAM,iBAAiB,IAAA,gXAAM,EAAmC;IAChE,MAAM,kBAAkB,IAAA,gXAAM,EAAwB;IACtD,MAAM,iBAAiB,IAAA,gXAAM,EAAC;IAE9B,wBAAwB;IACxB,MAAM,cAAc,+CAAkB,eAAe,2BAA2B;IAEhF,sBAAsB;IACtB,MAAM,oBAAoB,IAAA,qXAAW;+DAAC;YACpC,IAAI,gBAAgB,OAAO,EAAE;gBAC3B,aAAa,gBAAgB,OAAO;gBACpC,gBAAgB,OAAO,GAAG;YAC5B;QACF;8DAAG,EAAE;IAEL,sBAAsB;IACtB,MAAM,oBAAoB,IAAA,qXAAW;+DAAC;YACpC;YACA,IAAI,YAAY,eAAe,OAAO,EAAE;gBACtC,gBAAgB,OAAO,GAAG;2EAAW;wBACnC,IAAI,eAAe,OAAO,IAAI,eAAe,OAAO,EAAE;4BACpD,eAAe,OAAO,CAAC,IAAI;wBAC7B;oBACF;0EAAG;YACL;QACF;8DAAG;QAAC;QAAU;QAAgB;KAAkB;IAEhD,iBAAiB;IACjB,MAAM,gBAAgB,IAAA,qXAAW;2DAAC;YAChC;YACA,IAAI,eAAe,OAAO,IAAI,eAAe,OAAO,EAAE;gBACpD,eAAe,OAAO,GAAG;gBACzB,IAAI;oBACF,eAAe,OAAO,CAAC,IAAI;gBAC7B,EAAE,OAAM;gBACN,8BAA8B;gBAChC;YACF;YACA,UAAU;QACZ;0DAAG;QAAC;KAAkB;IAEtB,kBAAkB;IAClB,MAAM,iBAAiB,IAAA,qXAAW;4DAAC;YACjC,IAAI,CAAC,aAAa;gBAChB,UAAU;gBACV,MAAM,MAA8B;oBAClC,MAAM;oBACN,SAAS;gBACX;gBACA,SAAS;gBACT,UAAU;gBACV;YACF;YAEA,cAAc;YACd,SAAS;YACT,qBAAqB;YAErB,MAAM,yBAAyB;YAC/B,IAAI,CAAC,wBAAwB;YAE7B,sBAAsB;YACtB,MAAM,cAAc,IAAI;YACxB,eAAe,OAAO,GAAG;YAEzB,YAAY;YACZ,YAAY,UAAU,GAAG;YACzB,YAAY,cAAc,GAAG;YAC7B,YAAY,IAAI,GAAG;YACnB,YAAY,eAAe,GAAG;YAE9B,iBAAiB;YACjB,YAAY,QAAQ;oEAAG,CAAC;oBACtB;oBAEA,IAAI,kBAAkB;oBACtB,IAAI,UAAU;oBAEd,IAAK,IAAI,IAAI,MAAM,WAAW,EAAE,IAAI,MAAM,OAAO,CAAC,MAAM,EAAE,IAAK;wBAC7D,MAAM,SAAS,MAAM,OAAO,CAAC,EAAE;wBAC/B,MAAM,OAAO,MAAM,CAAC,EAAE,CAAC,UAAU;wBAEjC,IAAI,OAAO,OAAO,EAAE;4BAClB,mBAAmB;wBACrB,OAAO;4BACL,WAAW;wBACb;oBACF;oBAEA,IAAI,iBAAiB;wBACnB;gFAAc,CAAC,OAAS,OAAO;;wBAC/B,WAAW,iBAAiB;oBAC9B;oBAEA,qBAAqB;oBACrB,IAAI,SAAS;wBACX,WAAW,SAAS;oBACtB;oBAEA,oCAAoC;oBACpC;gBACF;;YAEA,gBAAgB;YAChB,YAAY,OAAO;oEAAG,CAAC;oBACrB,MAAM,YAAY,aAAa,MAAM,KAAK;oBAC1C,MAAM,MAA8B;wBAClC,MAAM;wBACN,SAAS,MAAM,OAAO,IAAI,gBAAgB;oBAC5C;oBAEA,SAAS;oBACT,UAAU;oBAEV,IAAI,cAAc,eAAe;wBAC/B,yBAAyB;oBAC3B;oBAEA,UAAU;oBACV,eAAe,OAAO,GAAG;gBAC3B;;YAEA,aAAa;YACb,YAAY,KAAK;oEAAG;oBAClB;oBACA,eAAe,OAAO,GAAG;oBAEzB,IAAI,WAAW,SAAS;wBACtB,UAAU;oBACZ;oBAEA,qBAAqB;oBACrB;gBACF;;YAEA,eAAe;YACf,YAAY,OAAO;oEAAG;oBACpB,eAAe,OAAO,GAAG;oBACzB,UAAU;oBACV;oBACA;gBACF;;YAEA,oBAAoB;YACpB,IAAI;gBACF,YAAY,KAAK;YACnB,EAAE,OAAO,GAAG;gBACV,MAAM,MAA8B;oBAClC,MAAM;oBACN,SAAS,aAAa,QAAQ,EAAE,OAAO,GAAG;gBAC5C;gBACA,SAAS;gBACT,UAAU;gBACV,UAAU;YACZ;QACF;2DAAG;QACD;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;KACD;IAED,mBAAmB;IACnB,MAAM,kBAAkB,IAAA,qXAAW;6DAAC;YAClC,cAAc;YACd,qBAAqB;QACvB;4DAAG,EAAE;IAEL,qBAAqB;IACrB,IAAA,mXAAS;0CAAC;YACR;kDAAO;oBACL;oBACA,IAAI,eAAe,OAAO,EAAE;wBAC1B,IAAI;4BACF,eAAe,OAAO,CAAC,KAAK;wBAC9B,EAAE,OAAM;wBACN,SAAS;wBACX;oBACF;gBACF;;QACF;yCAAG;QAAC;KAAkB;IAEtB,wBAAwB;IACxB,IAAA,mXAAS;0CAAC;YACR,IAAI,CAAC,aAAa;gBAChB,UAAU;YACZ;QACF;yCAAG;QAAC;KAAY;IAEhB,OAAO;QACL;QACA;QACA;QACA;QACA,aAAa,WAAW;QACxB;QACA;QACA;QACA;QACA;IACF;AACF;GAvOgB"}},
    {"offset": {"line": 779, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useTextToSpeech.ts"],"sourcesContent":["'use client';\n\nimport { useState, useCallback, useRef, useEffect } from 'react';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport type TTSStatus = 'idle' | 'loading' | 'speaking' | 'error';\nexport type TTSVoice = 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';\nexport type TTSProvider = 'openai' | 'elevenlabs';\n\nexport interface TTSError {\n  type: 'network' | 'audio' | 'aborted' | 'unknown';\n  message: string;\n}\n\nexport interface UseTextToSpeechReturn {\n  // State\n  status: TTSStatus;\n  error: TTSError | null;\n  isSpeaking: boolean;\n  isLoading: boolean;\n  currentText: string | null;\n  isAudioUnlocked: boolean;\n\n  // Actions\n  speak: (text: string) => Promise<void>;\n  stop: () => void;\n  pause: () => void;\n  resume: () => void;\n  unlockAudio: () => Promise<void>; // Call this on user interaction to enable audio\n}\n\nexport interface UseTextToSpeechOptions {\n  voice?: TTSVoice;\n  speed?: number; // 0.25 to 4.0\n  provider?: TTSProvider; // 'openai' or 'elevenlabs' - defaults to 'openai'\n  onStart?: () => void;\n  onEnd?: () => void;\n  onError?: (error: TTSError) => void;\n  autoPlay?: boolean; // Default true\n}\n\n// ============================================================================\n// Audio unlock state (shared across all hook instances)\n// ============================================================================\n\nlet globalAudioUnlocked = false;\nlet globalAudioContext: AudioContext | null = null;\nlet globalBlessedAudio: HTMLAudioElement | null = null;\nlet globalUnlockListenerAdded = false;\n\n/**\n * Unlock audio playback by playing a silent sound.\n * This must be called from a user interaction (click, tap, etc.)\n */\nasync function unlockAudioPlayback(): Promise<boolean> {\n  if (globalAudioUnlocked) return true;\n\n  try {\n    // Create or resume AudioContext\n    if (!globalAudioContext) {\n      globalAudioContext = new (window.AudioContext ||\n        (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();\n    }\n\n    if (globalAudioContext.state === 'suspended') {\n      await globalAudioContext.resume();\n    }\n\n    // Create a \"blessed\" Audio element that we can reuse\n    // iOS Safari requires the Audio element to be created AND played during user interaction\n    if (!globalBlessedAudio) {\n      globalBlessedAudio = new Audio();\n      globalBlessedAudio.volume = 1;\n    }\n\n    // Play a silent sound to unlock audio on iOS/Safari\n    // Using a very short silent WAV\n    globalBlessedAudio.src = 'data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA';\n\n    const playPromise = globalBlessedAudio.play();\n    if (playPromise !== undefined) {\n      await playPromise;\n    }\n    globalBlessedAudio.pause();\n    globalBlessedAudio.currentTime = 0;\n\n    globalAudioUnlocked = true;\n    console.log('[TTS] Audio playback unlocked');\n    return true;\n  } catch (error) {\n    console.warn('[TTS] Failed to unlock audio:', error);\n    return false;\n  }\n}\n\n/**\n * Add a document-level listener to auto-unlock audio on first user interaction.\n * This ensures audio is unlocked even if the user doesn't explicitly click the voice button.\n */\nfunction setupGlobalUnlockListener() {\n  if (globalUnlockListenerAdded || typeof document === 'undefined') return;\n\n  const unlockHandler = () => {\n    if (!globalAudioUnlocked) {\n      unlockAudioPlayback().catch(console.warn);\n    }\n  };\n\n  // Listen for any user interaction\n  document.addEventListener('click', unlockHandler, { once: false, passive: true });\n  document.addEventListener('touchstart', unlockHandler, { once: false, passive: true });\n  document.addEventListener('keydown', unlockHandler, { once: false, passive: true });\n\n  globalUnlockListenerAdded = true;\n  console.log('[TTS] Global unlock listeners added');\n}\n\n// ============================================================================\n// Hook\n// ============================================================================\n\nexport function useTextToSpeech(\n  options: UseTextToSpeechOptions = {}\n): UseTextToSpeechReturn {\n  const {\n    voice = 'nova',\n    speed = 1.0,\n    provider = 'openai',\n    onStart,\n    onEnd,\n    onError,\n    autoPlay = true,\n  } = options;\n\n  // State\n  const [status, setStatus] = useState<TTSStatus>('idle');\n  const [error, setError] = useState<TTSError | null>(null);\n  const [currentText, setCurrentText] = useState<string | null>(null);\n  const [isAudioUnlocked, setIsAudioUnlocked] = useState(globalAudioUnlocked);\n\n  // Refs\n  const audioRef = useRef<HTMLAudioElement | null>(null);\n  const abortControllerRef = useRef<AbortController | null>(null);\n\n  // Set up global unlock listener on mount\n  useEffect(() => {\n    setupGlobalUnlockListener();\n  }, []);\n\n  // Sync audio unlock state with global state\n  useEffect(() => {\n    const checkUnlockState = () => {\n      if (globalAudioUnlocked && !isAudioUnlocked) {\n        setIsAudioUnlocked(true);\n      }\n    };\n    // Check periodically in case global state was updated\n    const interval = setInterval(checkUnlockState, 500);\n    return () => clearInterval(interval);\n  }, [isAudioUnlocked]);\n\n  // Unlock audio (call this on user interaction like clicking mic button)\n  const unlockAudio = useCallback(async () => {\n    const unlocked = await unlockAudioPlayback();\n    setIsAudioUnlocked(unlocked);\n  }, []);\n\n  // Clean up audio element\n  const cleanupAudio = useCallback(() => {\n    if (audioRef.current) {\n      audioRef.current.pause();\n      audioRef.current.src = '';\n      audioRef.current.load();\n      audioRef.current = null;\n    }\n    if (abortControllerRef.current) {\n      abortControllerRef.current.abort();\n      abortControllerRef.current = null;\n    }\n  }, []);\n\n  // Stop speaking\n  const stop = useCallback(() => {\n    cleanupAudio();\n    setStatus('idle');\n    setCurrentText(null);\n  }, [cleanupAudio]);\n\n  // Pause speaking\n  const pause = useCallback(() => {\n    if (audioRef.current && status === 'speaking') {\n      audioRef.current.pause();\n    }\n  }, [status]);\n\n  // Resume speaking\n  const resume = useCallback(() => {\n    if (audioRef.current && audioRef.current.paused) {\n      audioRef.current.play().catch(console.error);\n    }\n  }, []);\n\n  // Speak text\n  const speak = useCallback(\n    async (text: string) => {\n      if (!text.trim()) return;\n\n      // Stop any current speech\n      cleanupAudio();\n\n      setError(null);\n      setCurrentText(text);\n      setStatus('loading');\n\n      // Ensure AudioContext is resumed (iOS Safari requirement)\n      if (globalAudioContext && globalAudioContext.state === 'suspended') {\n        try {\n          await globalAudioContext.resume();\n          console.log('[TTS] AudioContext resumed');\n        } catch (e) {\n          console.warn('[TTS] Failed to resume AudioContext:', e);\n        }\n      }\n\n      // Create abort controller for this request\n      abortControllerRef.current = new AbortController();\n\n      try {\n        // Use appropriate endpoint based on provider\n        const endpoint = provider === 'elevenlabs' ? '/api/tts/elevenlabs' : '/api/tts';\n        const body = provider === 'elevenlabs'\n          ? { text } // ElevenLabs uses voice ID from env var\n          : { text, voice, speed };\n\n        const response = await fetch(endpoint, {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify(body),\n          signal: abortControllerRef.current.signal,\n        });\n\n        if (!response.ok) {\n          const errorData = await response.json().catch(() => ({}));\n          throw new Error(errorData.error || 'Failed to generate speech');\n        }\n\n        // Get the audio blob\n        const audioBlob = await response.blob();\n        const audioUrl = URL.createObjectURL(audioBlob);\n\n        // Use the blessed audio element if available (for iOS Safari compatibility)\n        // Otherwise create a new one\n        const audio = globalBlessedAudio || new Audio();\n        audioRef.current = audio;\n\n        // Set up event handlers\n        audio.onloadeddata = () => {\n          if (autoPlay) {\n            // Try to play with retry on failure\n            const attemptPlay = async (retries = 2): Promise<void> => {\n              try {\n                await audio.play();\n                setStatus('speaking');\n                setIsAudioUnlocked(true);\n                onStart?.();\n              } catch (playError) {\n                console.warn('[TTS] Play failed:', (playError as Error).message, `(retries left: ${retries})`);\n\n                if (retries > 0) {\n                  // Try to resume AudioContext and retry\n                  if (globalAudioContext?.state === 'suspended') {\n                    await globalAudioContext.resume().catch(() => {});\n                  }\n                  await new Promise(r => setTimeout(r, 100));\n                  return attemptPlay(retries - 1);\n                }\n\n                // All retries failed - show user-friendly message\n                const err: TTSError = {\n                  type: 'audio',\n                  message: 'Tap anywhere to enable voice responses',\n                };\n                setError(err);\n                setStatus('error');\n                onError?.(err);\n              }\n            };\n            attemptPlay();\n          }\n        };\n\n        audio.onended = () => {\n          URL.revokeObjectURL(audioUrl);\n          setStatus('idle');\n          setCurrentText(null);\n          onEnd?.();\n        };\n\n        audio.onerror = () => {\n          URL.revokeObjectURL(audioUrl);\n          const err: TTSError = {\n            type: 'audio',\n            message: 'Failed to load audio',\n          };\n          setError(err);\n          setStatus('error');\n          onError?.(err);\n        };\n\n        // Load the audio\n        audio.src = audioUrl;\n        audio.load();\n      } catch (err) {\n        if (err instanceof Error && err.name === 'AbortError') {\n          // Request was aborted, not an error\n          setStatus('idle');\n          return;\n        }\n\n        const error: TTSError = {\n          type: 'network',\n          message: err instanceof Error ? err.message : 'Unknown error',\n        };\n        setError(error);\n        setStatus('error');\n        onError?.(error);\n      }\n    },\n    [cleanupAudio, provider, voice, speed, autoPlay, onStart, onEnd, onError]\n  );\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      cleanupAudio();\n    };\n  }, [cleanupAudio]);\n\n  // Sync global unlock state\n  useEffect(() => {\n    setIsAudioUnlocked(globalAudioUnlocked);\n  }, []);\n\n  return {\n    status,\n    error,\n    isSpeaking: status === 'speaking',\n    isLoading: status === 'loading',\n    currentText,\n    isAudioUnlocked,\n    speak,\n    stop,\n    pause,\n    resume,\n    unlockAudio,\n  };\n}\n"],"names":[],"mappings":";;;;AAEA;;AAFA;;AA4CA,+EAA+E;AAC/E,wDAAwD;AACxD,+EAA+E;AAE/E,IAAI,sBAAsB;AAC1B,IAAI,qBAA0C;AAC9C,IAAI,qBAA8C;AAClD,IAAI,4BAA4B;AAEhC;;;CAGC,GACD,eAAe;IACb,IAAI,qBAAqB,OAAO;IAEhC,IAAI;QACF,gCAAgC;QAChC,IAAI,CAAC,oBAAoB;YACvB,qBAAqB,IAAI,CAAC,OAAO,YAAY,IAC3C,AAAC,OAAkE,kBAAkB;QACzF;QAEA,IAAI,mBAAmB,KAAK,KAAK,aAAa;YAC5C,MAAM,mBAAmB,MAAM;QACjC;QAEA,qDAAqD;QACrD,yFAAyF;QACzF,IAAI,CAAC,oBAAoB;YACvB,qBAAqB,IAAI;YACzB,mBAAmB,MAAM,GAAG;QAC9B;QAEA,oDAAoD;QACpD,gCAAgC;QAChC,mBAAmB,GAAG,GAAG;QAEzB,MAAM,cAAc,mBAAmB,IAAI;QAC3C,IAAI,gBAAgB,WAAW;YAC7B,MAAM;QACR;QACA,mBAAmB,KAAK;QACxB,mBAAmB,WAAW,GAAG;QAEjC,sBAAsB;QACtB,QAAQ,GAAG,CAAC;QACZ,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,IAAI,CAAC,iCAAiC;QAC9C,OAAO;IACT;AACF;AAEA;;;CAGC,GACD,SAAS;IACP,IAAI,6BAA6B,OAAO,aAAa,aAAa;IAElE,MAAM,gBAAgB;QACpB,IAAI,CAAC,qBAAqB;YACxB,sBAAsB,KAAK,CAAC,QAAQ,IAAI;QAC1C;IACF;IAEA,kCAAkC;IAClC,SAAS,gBAAgB,CAAC,SAAS,eAAe;QAAE,MAAM;QAAO,SAAS;IAAK;IAC/E,SAAS,gBAAgB,CAAC,cAAc,eAAe;QAAE,MAAM;QAAO,SAAS;IAAK;IACpF,SAAS,gBAAgB,CAAC,WAAW,eAAe;QAAE,MAAM;QAAO,SAAS;IAAK;IAEjF,4BAA4B;IAC5B,QAAQ,GAAG,CAAC;AACd;AAMO,SAAS,gBACd,UAAkC,CAAC,CAAC;;IAEpC,MAAM,EACJ,QAAQ,MAAM,EACd,QAAQ,GAAG,EACX,WAAW,QAAQ,EACnB,OAAO,EACP,KAAK,EACL,OAAO,EACP,WAAW,IAAI,EAChB,GAAG;IAEJ,QAAQ;IACR,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,kXAAQ,EAAY;IAChD,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,kXAAQ,EAAkB;IACpD,MAAM,CAAC,aAAa,eAAe,GAAG,IAAA,kXAAQ,EAAgB;IAC9D,MAAM,CAAC,iBAAiB,mBAAmB,GAAG,IAAA,kXAAQ,EAAC;IAEvD,OAAO;IACP,MAAM,WAAW,IAAA,gXAAM,EAA0B;IACjD,MAAM,qBAAqB,IAAA,gXAAM,EAAyB;IAE1D,yCAAyC;IACzC,IAAA,mXAAS;qCAAC;YACR;QACF;oCAAG,EAAE;IAEL,4CAA4C;IAC5C,IAAA,mXAAS;qCAAC;YACR,MAAM;8DAAmB;oBACvB,IAAI,uBAAuB,CAAC,iBAAiB;wBAC3C,mBAAmB;oBACrB;gBACF;;YACA,sDAAsD;YACtD,MAAM,WAAW,YAAY,kBAAkB;YAC/C;6CAAO,IAAM,cAAc;;QAC7B;oCAAG;QAAC;KAAgB;IAEpB,wEAAwE;IACxE,MAAM,cAAc,IAAA,qXAAW;oDAAC;YAC9B,MAAM,WAAW,MAAM;YACvB,mBAAmB;QACrB;mDAAG,EAAE;IAEL,yBAAyB;IACzB,MAAM,eAAe,IAAA,qXAAW;qDAAC;YAC/B,IAAI,SAAS,OAAO,EAAE;gBACpB,SAAS,OAAO,CAAC,KAAK;gBACtB,SAAS,OAAO,CAAC,GAAG,GAAG;gBACvB,SAAS,OAAO,CAAC,IAAI;gBACrB,SAAS,OAAO,GAAG;YACrB;YACA,IAAI,mBAAmB,OAAO,EAAE;gBAC9B,mBAAmB,OAAO,CAAC,KAAK;gBAChC,mBAAmB,OAAO,GAAG;YAC/B;QACF;oDAAG,EAAE;IAEL,gBAAgB;IAChB,MAAM,OAAO,IAAA,qXAAW;6CAAC;YACvB;YACA,UAAU;YACV,eAAe;QACjB;4CAAG;QAAC;KAAa;IAEjB,iBAAiB;IACjB,MAAM,QAAQ,IAAA,qXAAW;8CAAC;YACxB,IAAI,SAAS,OAAO,IAAI,WAAW,YAAY;gBAC7C,SAAS,OAAO,CAAC,KAAK;YACxB;QACF;6CAAG;QAAC;KAAO;IAEX,kBAAkB;IAClB,MAAM,SAAS,IAAA,qXAAW;+CAAC;YACzB,IAAI,SAAS,OAAO,IAAI,SAAS,OAAO,CAAC,MAAM,EAAE;gBAC/C,SAAS,OAAO,CAAC,IAAI,GAAG,KAAK,CAAC,QAAQ,KAAK;YAC7C;QACF;8CAAG,EAAE;IAEL,aAAa;IACb,MAAM,QAAQ,IAAA,qXAAW;8CACvB,OAAO;YACL,IAAI,CAAC,KAAK,IAAI,IAAI;YAElB,0BAA0B;YAC1B;YAEA,SAAS;YACT,eAAe;YACf,UAAU;YAEV,0DAA0D;YAC1D,IAAI,sBAAsB,mBAAmB,KAAK,KAAK,aAAa;gBAClE,IAAI;oBACF,MAAM,mBAAmB,MAAM;oBAC/B,QAAQ,GAAG,CAAC;gBACd,EAAE,OAAO,GAAG;oBACV,QAAQ,IAAI,CAAC,wCAAwC;gBACvD;YACF;YAEA,2CAA2C;YAC3C,mBAAmB,OAAO,GAAG,IAAI;YAEjC,IAAI;gBACF,6CAA6C;gBAC7C,MAAM,WAAW,aAAa,eAAe,wBAAwB;gBACrE,MAAM,OAAO,aAAa,eACtB;oBAAE;gBAAK,EAAE,wCAAwC;mBACjD;oBAAE;oBAAM;oBAAO;gBAAM;gBAEzB,MAAM,WAAW,MAAM,MAAM,UAAU;oBACrC,QAAQ;oBACR,SAAS;wBAAE,gBAAgB;oBAAmB;oBAC9C,MAAM,KAAK,SAAS,CAAC;oBACrB,QAAQ,mBAAmB,OAAO,CAAC,MAAM;gBAC3C;gBAEA,IAAI,CAAC,SAAS,EAAE,EAAE;oBAChB,MAAM,YAAY,MAAM,SAAS,IAAI,GAAG,KAAK;8DAAC,IAAM,CAAC,CAAC,CAAC;;oBACvD,MAAM,IAAI,MAAM,UAAU,KAAK,IAAI;gBACrC;gBAEA,qBAAqB;gBACrB,MAAM,YAAY,MAAM,SAAS,IAAI;gBACrC,MAAM,WAAW,IAAI,eAAe,CAAC;gBAErC,4EAA4E;gBAC5E,6BAA6B;gBAC7B,MAAM,QAAQ,sBAAsB,IAAI;gBACxC,SAAS,OAAO,GAAG;gBAEnB,wBAAwB;gBACxB,MAAM,YAAY;0DAAG;wBACnB,IAAI,UAAU;4BACZ,oCAAoC;4BACpC,MAAM;kFAAc,OAAO,UAAU,CAAC;oCACpC,IAAI;wCACF,MAAM,MAAM,IAAI;wCAChB,UAAU;wCACV,mBAAmB;wCACnB;oCACF,EAAE,OAAO,WAAW;wCAClB,QAAQ,IAAI,CAAC,sBAAsB,AAAC,UAAoB,OAAO,EAAE,CAAC,eAAe,EAAE,QAAQ,CAAC,CAAC;wCAE7F,IAAI,UAAU,GAAG;4CACf,uCAAuC;4CACvC,IAAI,oBAAoB,UAAU,aAAa;gDAC7C,MAAM,mBAAmB,MAAM,GAAG,KAAK;sGAAC,KAAO;;4CACjD;4CACA,MAAM,IAAI;kGAAQ,CAAA,IAAK,WAAW,GAAG;;4CACrC,OAAO,YAAY,UAAU;wCAC/B;wCAEA,kDAAkD;wCAClD,MAAM,MAAgB;4CACpB,MAAM;4CACN,SAAS;wCACX;wCACA,SAAS;wCACT,UAAU;wCACV,UAAU;oCACZ;gCACF;;4BACA;wBACF;oBACF;;gBAEA,MAAM,OAAO;0DAAG;wBACd,IAAI,eAAe,CAAC;wBACpB,UAAU;wBACV,eAAe;wBACf;oBACF;;gBAEA,MAAM,OAAO;0DAAG;wBACd,IAAI,eAAe,CAAC;wBACpB,MAAM,MAAgB;4BACpB,MAAM;4BACN,SAAS;wBACX;wBACA,SAAS;wBACT,UAAU;wBACV,UAAU;oBACZ;;gBAEA,iBAAiB;gBACjB,MAAM,GAAG,GAAG;gBACZ,MAAM,IAAI;YACZ,EAAE,OAAO,KAAK;gBACZ,IAAI,eAAe,SAAS,IAAI,IAAI,KAAK,cAAc;oBACrD,oCAAoC;oBACpC,UAAU;oBACV;gBACF;gBAEA,MAAM,QAAkB;oBACtB,MAAM;oBACN,SAAS,eAAe,QAAQ,IAAI,OAAO,GAAG;gBAChD;gBACA,SAAS;gBACT,UAAU;gBACV,UAAU;YACZ;QACF;6CACA;QAAC;QAAc;QAAU;QAAO;QAAO;QAAU;QAAS;QAAO;KAAQ;IAG3E,qBAAqB;IACrB,IAAA,mXAAS;qCAAC;YACR;6CAAO;oBACL;gBACF;;QACF;oCAAG;QAAC;KAAa;IAEjB,2BAA2B;IAC3B,IAAA,mXAAS;qCAAC;YACR,mBAAmB;QACrB;oCAAG,EAAE;IAEL,OAAO;QACL;QACA;QACA,YAAY,WAAW;QACvB,WAAW,WAAW;QACtB;QACA;QACA;QACA;QACA;QACA;QACA;IACF;AACF;GA3OgB"}},
    {"offset": {"line": 1123, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useVoiceChat.ts"],"sourcesContent":["'use client';\n\nimport { useState, useCallback, useRef, useEffect } from 'react';\nimport {\n  useSpeechRecognition,\n  SpeechRecognitionStatus,\n  SpeechRecognitionError,\n} from './useSpeechRecognition';\nimport {\n  useTextToSpeech,\n  TTSStatus,\n  TTSError,\n  TTSVoice,\n  TTSProvider,\n} from './useTextToSpeech';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport type VoiceChatMode = 'idle' | 'listening' | 'processing' | 'speaking';\n\nexport interface VoiceChatError {\n  type: 'speech' | 'tts' | 'unknown';\n  message: string;\n}\n\nexport interface UseVoiceChatReturn {\n  // State\n  mode: VoiceChatMode;\n  isVoiceEnabled: boolean;\n  transcript: string;\n  interimTranscript: string;\n  error: VoiceChatError | null;\n\n  // Capabilities\n  isSpeechSupported: boolean;\n  isMicrophoneAvailable: boolean;\n\n  // Actions\n  enableVoice: () => void;\n  disableVoice: () => void;\n  toggleVoice: () => void;\n  startListening: () => void;\n  stopListening: () => void;\n  speakResponse: (text: string) => Promise<void>;\n  stopSpeaking: () => void;\n  resetTranscript: () => void;\n}\n\nexport interface UseVoiceChatOptions {\n  voice?: TTSVoice;\n  provider?: TTSProvider; // 'openai' or 'elevenlabs' - defaults to 'openai'\n  language?: string;\n  continuous?: boolean;\n  autoSpeak?: boolean; // Automatically speak AI responses\n  onTranscriptComplete?: (transcript: string) => void;\n  onSpeakingStart?: () => void;\n  onSpeakingEnd?: () => void;\n  onError?: (error: VoiceChatError) => void;\n}\n\n// ============================================================================\n// Hook\n// ============================================================================\n\nexport function useVoiceChat(\n  options: UseVoiceChatOptions = {}\n): UseVoiceChatReturn {\n  const {\n    voice = 'nova',\n    provider = 'elevenlabs', // Default to ElevenLabs for James's cloned voice\n    language = 'en-US',\n    continuous = false,\n    autoSpeak = true,\n    onTranscriptComplete,\n    onSpeakingStart,\n    onSpeakingEnd,\n    onError,\n  } = options;\n\n  // State\n  const [isVoiceEnabled, setIsVoiceEnabled] = useState(false);\n  const [mode, setMode] = useState<VoiceChatMode>('idle');\n  const [error, setError] = useState<VoiceChatError | null>(null);\n\n  // Refs for tracking state across callbacks\n  const pendingTranscriptRef = useRef<string>('');\n  const isProcessingRef = useRef(false);\n\n  // Speech Recognition (input)\n  const speechRecognition = useSpeechRecognition({\n    continuous,\n    language,\n    interimResults: true,\n    autoStop: true,\n    silenceTimeout: 2000,\n    onResult: (transcript, isFinal) => {\n      if (isFinal) {\n        pendingTranscriptRef.current += transcript;\n      }\n    },\n    onEnd: () => {\n      // When speech recognition ends, process the transcript\n      if (pendingTranscriptRef.current.trim() && !isProcessingRef.current) {\n        const finalTranscript = pendingTranscriptRef.current.trim();\n        pendingTranscriptRef.current = '';\n        setMode('processing');\n        isProcessingRef.current = true;\n        onTranscriptComplete?.(finalTranscript);\n        isProcessingRef.current = false;\n      } else if (mode === 'listening') {\n        setMode('idle');\n      }\n    },\n    onError: (err) => {\n      const voiceError: VoiceChatError = {\n        type: 'speech',\n        message: err.message,\n      };\n      setError(voiceError);\n      setMode('idle');\n      onError?.(voiceError);\n    },\n  });\n\n  // Text-to-Speech (output)\n  const tts = useTextToSpeech({\n    voice,\n    provider,\n    speed: 1.0,\n    onStart: () => {\n      setMode('speaking');\n      onSpeakingStart?.();\n    },\n    onEnd: () => {\n      setMode('idle');\n      onSpeakingEnd?.();\n    },\n    onError: (err) => {\n      const voiceError: VoiceChatError = {\n        type: 'tts',\n        message: err.message,\n      };\n      setError(voiceError);\n      setMode('idle');\n      onError?.(voiceError);\n    },\n  });\n\n  // Update mode based on speech recognition status\n  useEffect(() => {\n    if (speechRecognition.isListening && mode !== 'speaking') {\n      setMode('listening');\n    }\n  }, [speechRecognition.isListening, mode]);\n\n  // Enable voice mode\n  const enableVoice = useCallback(() => {\n    setIsVoiceEnabled(true);\n    setError(null);\n    // Unlock audio on user interaction\n    tts.unlockAudio();\n  }, [tts]);\n\n  // Disable voice mode\n  const disableVoice = useCallback(() => {\n    setIsVoiceEnabled(false);\n    speechRecognition.stopListening();\n    tts.stop();\n    setMode('idle');\n    pendingTranscriptRef.current = '';\n  }, [speechRecognition, tts]);\n\n  // Toggle voice mode\n  const toggleVoice = useCallback(() => {\n    if (isVoiceEnabled) {\n      disableVoice();\n    } else {\n      enableVoice();\n    }\n  }, [isVoiceEnabled, enableVoice, disableVoice]);\n\n  // Start listening\n  const startListening = useCallback(() => {\n    if (!isVoiceEnabled) {\n      enableVoice();\n    }\n\n    // Stop any current speech first\n    tts.stop();\n\n    setError(null);\n    pendingTranscriptRef.current = '';\n    speechRecognition.resetTranscript();\n    speechRecognition.startListening();\n  }, [isVoiceEnabled, enableVoice, tts, speechRecognition]);\n\n  // Stop listening\n  const stopListening = useCallback(() => {\n    speechRecognition.stopListening();\n  }, [speechRecognition]);\n\n  // Speak AI response\n  const speakResponse = useCallback(\n    async (text: string) => {\n      if (!isVoiceEnabled || !autoSpeak) return;\n\n      // Clean the text for speech (remove markdown, links, etc.)\n      const cleanText = text\n        .replace(/\\[([^\\]]+)\\]\\([^)]+\\)/g, '$1') // Remove markdown links\n        .replace(/\\*\\*([^*]+)\\*\\*/g, '$1') // Remove bold\n        .replace(/\\*([^*]+)\\*/g, '$1') // Remove italic\n        .replace(/`([^`]+)`/g, '$1') // Remove code\n        .replace(/#{1,6}\\s/g, '') // Remove headers\n        .replace(/\\n+/g, '. ') // Replace newlines with periods\n        .replace(/\\s+/g, ' ') // Normalize whitespace\n        .trim();\n\n      if (cleanText) {\n        await tts.speak(cleanText);\n      }\n    },\n    [isVoiceEnabled, autoSpeak, tts]\n  );\n\n  // Stop speaking\n  const stopSpeaking = useCallback(() => {\n    tts.stop();\n    setMode('idle');\n  }, [tts]);\n\n  // Reset transcript\n  const resetTranscript = useCallback(() => {\n    speechRecognition.resetTranscript();\n    pendingTranscriptRef.current = '';\n  }, [speechRecognition]);\n\n  return {\n    // State\n    mode,\n    isVoiceEnabled,\n    transcript: speechRecognition.transcript,\n    interimTranscript: speechRecognition.interimTranscript,\n    error,\n\n    // Capabilities\n    isSpeechSupported: speechRecognition.isSupported,\n    isMicrophoneAvailable: speechRecognition.isMicrophoneAvailable,\n\n    // Actions\n    enableVoice,\n    disableVoice,\n    toggleVoice,\n    startListening,\n    stopListening,\n    speakResponse,\n    stopSpeaking,\n    resetTranscript,\n  };\n}\n"],"names":[],"mappings":";;;;AAEA;AACA;AAKA;;AARA;;;;AAkEO,SAAS,aACd,UAA+B,CAAC,CAAC;;IAEjC,MAAM,EACJ,QAAQ,MAAM,EACd,WAAW,YAAY,EACvB,WAAW,OAAO,EAClB,aAAa,KAAK,EAClB,YAAY,IAAI,EAChB,oBAAoB,EACpB,eAAe,EACf,aAAa,EACb,OAAO,EACR,GAAG;IAEJ,QAAQ;IACR,MAAM,CAAC,gBAAgB,kBAAkB,GAAG,IAAA,kXAAQ,EAAC;IACrD,MAAM,CAAC,MAAM,QAAQ,GAAG,IAAA,kXAAQ,EAAgB;IAChD,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,kXAAQ,EAAwB;IAE1D,2CAA2C;IAC3C,MAAM,uBAAuB,IAAA,gXAAM,EAAS;IAC5C,MAAM,kBAAkB,IAAA,gXAAM,EAAC;IAE/B,6BAA6B;IAC7B,MAAM,oBAAoB,IAAA,+JAAoB,EAAC;QAC7C;QACA;QACA,gBAAgB;QAChB,UAAU;QACV,gBAAgB;QAChB,QAAQ;oEAAE,CAAC,YAAY;gBACrB,IAAI,SAAS;oBACX,qBAAqB,OAAO,IAAI;gBAClC;YACF;;QACA,KAAK;oEAAE;gBACL,uDAAuD;gBACvD,IAAI,qBAAqB,OAAO,CAAC,IAAI,MAAM,CAAC,gBAAgB,OAAO,EAAE;oBACnE,MAAM,kBAAkB,qBAAqB,OAAO,CAAC,IAAI;oBACzD,qBAAqB,OAAO,GAAG;oBAC/B,QAAQ;oBACR,gBAAgB,OAAO,GAAG;oBAC1B,uBAAuB;oBACvB,gBAAgB,OAAO,GAAG;gBAC5B,OAAO,IAAI,SAAS,aAAa;oBAC/B,QAAQ;gBACV;YACF;;QACA,OAAO;oEAAE,CAAC;gBACR,MAAM,aAA6B;oBACjC,MAAM;oBACN,SAAS,IAAI,OAAO;gBACtB;gBACA,SAAS;gBACT,QAAQ;gBACR,UAAU;YACZ;;IACF;IAEA,0BAA0B;IAC1B,MAAM,MAAM,IAAA,qJAAe,EAAC;QAC1B;QACA;QACA,OAAO;QACP,OAAO;iDAAE;gBACP,QAAQ;gBACR;YACF;;QACA,KAAK;iDAAE;gBACL,QAAQ;gBACR;YACF;;QACA,OAAO;iDAAE,CAAC;gBACR,MAAM,aAA6B;oBACjC,MAAM;oBACN,SAAS,IAAI,OAAO;gBACtB;gBACA,SAAS;gBACT,QAAQ;gBACR,UAAU;YACZ;;IACF;IAEA,iDAAiD;IACjD,IAAA,mXAAS;kCAAC;YACR,IAAI,kBAAkB,WAAW,IAAI,SAAS,YAAY;gBACxD,QAAQ;YACV;QACF;iCAAG;QAAC,kBAAkB,WAAW;QAAE;KAAK;IAExC,oBAAoB;IACpB,MAAM,cAAc,IAAA,qXAAW;iDAAC;YAC9B,kBAAkB;YAClB,SAAS;YACT,mCAAmC;YACnC,IAAI,WAAW;QACjB;gDAAG;QAAC;KAAI;IAER,qBAAqB;IACrB,MAAM,eAAe,IAAA,qXAAW;kDAAC;YAC/B,kBAAkB;YAClB,kBAAkB,aAAa;YAC/B,IAAI,IAAI;YACR,QAAQ;YACR,qBAAqB,OAAO,GAAG;QACjC;iDAAG;QAAC;QAAmB;KAAI;IAE3B,oBAAoB;IACpB,MAAM,cAAc,IAAA,qXAAW;iDAAC;YAC9B,IAAI,gBAAgB;gBAClB;YACF,OAAO;gBACL;YACF;QACF;gDAAG;QAAC;QAAgB;QAAa;KAAa;IAE9C,kBAAkB;IAClB,MAAM,iBAAiB,IAAA,qXAAW;oDAAC;YACjC,IAAI,CAAC,gBAAgB;gBACnB;YACF;YAEA,gCAAgC;YAChC,IAAI,IAAI;YAER,SAAS;YACT,qBAAqB,OAAO,GAAG;YAC/B,kBAAkB,eAAe;YACjC,kBAAkB,cAAc;QAClC;mDAAG;QAAC;QAAgB;QAAa;QAAK;KAAkB;IAExD,iBAAiB;IACjB,MAAM,gBAAgB,IAAA,qXAAW;mDAAC;YAChC,kBAAkB,aAAa;QACjC;kDAAG;QAAC;KAAkB;IAEtB,oBAAoB;IACpB,MAAM,gBAAgB,IAAA,qXAAW;mDAC/B,OAAO;YACL,IAAI,CAAC,kBAAkB,CAAC,WAAW;YAEnC,2DAA2D;YAC3D,MAAM,YAAY,KACf,OAAO,CAAC,0BAA0B,MAAM,wBAAwB;aAChE,OAAO,CAAC,oBAAoB,MAAM,cAAc;aAChD,OAAO,CAAC,gBAAgB,MAAM,gBAAgB;aAC9C,OAAO,CAAC,cAAc,MAAM,cAAc;aAC1C,OAAO,CAAC,aAAa,IAAI,iBAAiB;aAC1C,OAAO,CAAC,QAAQ,MAAM,gCAAgC;aACtD,OAAO,CAAC,QAAQ,KAAK,uBAAuB;aAC5C,IAAI;YAEP,IAAI,WAAW;gBACb,MAAM,IAAI,KAAK,CAAC;YAClB;QACF;kDACA;QAAC;QAAgB;QAAW;KAAI;IAGlC,gBAAgB;IAChB,MAAM,eAAe,IAAA,qXAAW;kDAAC;YAC/B,IAAI,IAAI;YACR,QAAQ;QACV;iDAAG;QAAC;KAAI;IAER,mBAAmB;IACnB,MAAM,kBAAkB,IAAA,qXAAW;qDAAC;YAClC,kBAAkB,eAAe;YACjC,qBAAqB,OAAO,GAAG;QACjC;oDAAG;QAAC;KAAkB;IAEtB,OAAO;QACL,QAAQ;QACR;QACA;QACA,YAAY,kBAAkB,UAAU;QACxC,mBAAmB,kBAAkB,iBAAiB;QACtD;QAEA,eAAe;QACf,mBAAmB,kBAAkB,WAAW;QAChD,uBAAuB,kBAAkB,qBAAqB;QAE9D,UAAU;QACV;QACA;QACA;QACA;QACA;QACA;QACA;QACA;IACF;AACF;GAlMgB;;QAyBY,+JAAoB;QAoClC,qJAAe"}},
    {"offset": {"line": 1365, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/usePauseMusicForVoice.ts"],"sourcesContent":["'use client';\n\nimport { useEffect, useRef, useContext } from 'react';\nimport { MusicContext } from '@/context/MusicContext';\n\ninterface UsePauseMusicForVoiceOptions {\n  /** Whether voice recording is active */\n  isRecording?: boolean;\n  /** Whether TTS is speaking (voiceChat.mode === 'speaking') */\n  isSpeaking?: boolean;\n  /** Whether voice transcription is processing */\n  isTranscribing?: boolean;\n}\n\n/**\n * Pauses music when voice recording or TTS speaking is active.\n * Music stays paused after voice interaction ends (no auto-resume).\n *\n * Safe to use even if MusicProvider is not available (will no-op).\n *\n * Usage:\n * ```tsx\n * usePauseMusicForVoice({\n *   isRecording: voiceRecorder.isRecording,\n *   isSpeaking: voiceChat.mode === 'speaking',\n *   isTranscribing: isTranscribing,\n * });\n * ```\n */\nexport function usePauseMusicForVoice({\n  isRecording = false,\n  isSpeaking = false,\n  isTranscribing = false,\n}: UsePauseMusicForVoiceOptions) {\n  // Use context directly to avoid throwing if not in provider\n  const musicContext = useContext(MusicContext);\n\n  // Track if we paused the music (to avoid redundant pause calls)\n  const didPauseRef = useRef(false);\n\n  // Pause music when recording starts\n  useEffect(() => {\n    if (!musicContext) return;\n    if (isRecording && musicContext.isPlaying) {\n      musicContext.pause();\n      didPauseRef.current = true;\n    }\n  }, [isRecording, musicContext]);\n\n  // Pause music when TTS speaking starts\n  useEffect(() => {\n    if (!musicContext) return;\n    if (isSpeaking && musicContext.isPlaying) {\n      musicContext.pause();\n      didPauseRef.current = true;\n    }\n  }, [isSpeaking, musicContext]);\n\n  // Pause music when transcribing starts (covers the processing phase)\n  useEffect(() => {\n    if (!musicContext) return;\n    if (isTranscribing && musicContext.isPlaying) {\n      musicContext.pause();\n      didPauseRef.current = true;\n    }\n  }, [isTranscribing, musicContext]);\n\n  // Reset the ref when voice interaction ends (but don't auto-resume)\n  useEffect(() => {\n    if (!isRecording && !isSpeaking && !isTranscribing) {\n      didPauseRef.current = false;\n    }\n  }, [isRecording, isSpeaking, isTranscribing]);\n}\n\nexport default usePauseMusicForVoice;\n"],"names":[],"mappings":";;;;;;AAEA;AACA;;AAHA;;;AA6BO,SAAS,sBAAsB,EACpC,cAAc,KAAK,EACnB,aAAa,KAAK,EAClB,iBAAiB,KAAK,EACO;;IAC7B,4DAA4D;IAC5D,MAAM,eAAe,IAAA,oXAAU,EAAC,kJAAY;IAE5C,gEAAgE;IAChE,MAAM,cAAc,IAAA,gXAAM,EAAC;IAE3B,oCAAoC;IACpC,IAAA,mXAAS;2CAAC;YACR,IAAI,CAAC,cAAc;YACnB,IAAI,eAAe,aAAa,SAAS,EAAE;gBACzC,aAAa,KAAK;gBAClB,YAAY,OAAO,GAAG;YACxB;QACF;0CAAG;QAAC;QAAa;KAAa;IAE9B,uCAAuC;IACvC,IAAA,mXAAS;2CAAC;YACR,IAAI,CAAC,cAAc;YACnB,IAAI,cAAc,aAAa,SAAS,EAAE;gBACxC,aAAa,KAAK;gBAClB,YAAY,OAAO,GAAG;YACxB;QACF;0CAAG;QAAC;QAAY;KAAa;IAE7B,qEAAqE;IACrE,IAAA,mXAAS;2CAAC;YACR,IAAI,CAAC,cAAc;YACnB,IAAI,kBAAkB,aAAa,SAAS,EAAE;gBAC5C,aAAa,KAAK;gBAClB,YAAY,OAAO,GAAG;YACxB;QACF;0CAAG;QAAC;QAAgB;KAAa;IAEjC,oEAAoE;IACpE,IAAA,mXAAS;2CAAC;YACR,IAAI,CAAC,eAAe,CAAC,cAAc,CAAC,gBAAgB;gBAClD,YAAY,OAAO,GAAG;YACxB;QACF;0CAAG;QAAC;QAAa;QAAY;KAAe;AAC9C;GA5CgB;uCA8CD"}},
    {"offset": {"line": 1444, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useVoiceMode.ts"],"sourcesContent":["'use client';\n\nimport { useState, useCallback, useRef, useEffect } from 'react';\n\n// ============================================================================\n// Types\n// ============================================================================\n\nexport type VoiceModeState = 'idle' | 'listening' | 'processing' | 'speaking';\n\nexport interface VoiceModeConfig {\n  // Chunking config\n  chunkDurationMs?: number; // Duration of each audio chunk (default: 2000ms)\n  silenceThreshold?: number; // Audio level below which is considered silence (0-1, default: 0.02)\n  silenceDurationMs?: number; // Duration of silence before auto-send (default: 1500ms)\n\n  // API endpoints\n  whisperEndpoint?: string;\n  chatEndpoint?: string;\n  ttsEndpoint?: string;\n\n  // Callbacks\n  onTranscriptUpdate?: (transcript: string, isFinal: boolean) => void;\n  onResponseStart?: () => void;\n  onResponseEnd?: (response: string) => void;\n  onError?: (error: string) => void;\n  onStateChange?: (state: VoiceModeState) => void;\n}\n\nexport interface UseVoiceModeReturn {\n  // State\n  state: VoiceModeState;\n  isActive: boolean;\n  transcript: string;\n  response: string;\n  audioIntensity: number; // 0-1 for UI feedback\n  error: string | null;\n\n  // Actions\n  start: () => Promise<void>;\n  stop: () => void;\n  send: () => Promise<void>; // Manual send (tap to send)\n  interrupt: () => void; // Stop speaking, switch to listening\n}\n\n// ============================================================================\n// Constants\n// ============================================================================\n\nconst DEFAULT_CHUNK_DURATION = 2000; // 2 seconds\nconst DEFAULT_SILENCE_THRESHOLD = 0.02;\nconst DEFAULT_SILENCE_DURATION = 1500; // 1.5 seconds\nconst AUDIO_LEVEL_UPDATE_INTERVAL = 50; // 50ms\n\n// Debug logging\nconst LOG_PREFIX = '[VoiceMode]';\nconst log = {\n  info: (msg: string, data?: unknown) => console.log(`${LOG_PREFIX} ${msg}`, data ?? ''),\n  warn: (msg: string, data?: unknown) => console.warn(`${LOG_PREFIX} ${msg}`, data ?? ''),\n  error: (msg: string, data?: unknown) => console.error(`${LOG_PREFIX} ${msg}`, data ?? ''),\n  state: (from: VoiceModeState, to: VoiceModeState) =>\n    console.log(`${LOG_PREFIX} [STATE] ${from}  ${to}`),\n  timing: (label: string, ms: number) =>\n    console.log(`${LOG_PREFIX} [TIMING] ${label}: ${ms}ms`),\n};\n\n// ============================================================================\n// Hook\n// ============================================================================\n\nexport function useVoiceMode(config: VoiceModeConfig = {}): UseVoiceModeReturn {\n  const {\n    chunkDurationMs = DEFAULT_CHUNK_DURATION,\n    silenceThreshold = DEFAULT_SILENCE_THRESHOLD,\n    silenceDurationMs = DEFAULT_SILENCE_DURATION,\n    whisperEndpoint = '/api/whisper',\n    chatEndpoint = '/api/chat/stream',\n    ttsEndpoint = '/api/tts',\n    onTranscriptUpdate,\n    onResponseStart,\n    onResponseEnd,\n    onError,\n    onStateChange,\n  } = config;\n\n  // State\n  const [state, setState] = useState<VoiceModeState>('idle');\n  const [transcript, setTranscript] = useState('');\n  const [response, setResponse] = useState('');\n  const [audioIntensity, setAudioIntensity] = useState(0);\n  const [error, setError] = useState<string | null>(null);\n\n  // Refs for cleanup and management\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const streamRef = useRef<MediaStream | null>(null);\n  const audioChunksRef = useRef<Blob[]>([]);\n  const audioLevelIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);\n  const chunkIntervalRef = useRef<NodeJS.Timeout | null>(null);\n  const lastAudioLevelRef = useRef(0);\n  const silenceStartRef = useRef<number | null>(null);\n  const currentAudioRef = useRef<HTMLAudioElement | null>(null);\n  const abortControllerRef = useRef<AbortController | null>(null);\n  const startTimeRef = useRef<number>(0);\n\n  // State change with logging and callback\n  const transitionState = useCallback((newState: VoiceModeState) => {\n    setState(prev => {\n      if (prev !== newState) {\n        log.state(prev, newState);\n        onStateChange?.(newState);\n      }\n      return newState;\n    });\n  }, [onStateChange]);\n\n  // Cleanup all resources\n  const cleanup = useCallback(() => {\n    log.info('cleanup() - releasing all resources');\n\n    // Stop intervals\n    if (audioLevelIntervalRef.current) {\n      clearInterval(audioLevelIntervalRef.current);\n      audioLevelIntervalRef.current = null;\n    }\n    if (silenceTimeoutRef.current) {\n      clearTimeout(silenceTimeoutRef.current);\n      silenceTimeoutRef.current = null;\n    }\n    if (chunkIntervalRef.current) {\n      clearInterval(chunkIntervalRef.current);\n      chunkIntervalRef.current = null;\n    }\n\n    // Stop media recorder\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\n      try {\n        mediaRecorderRef.current.stop();\n      } catch {\n        // Ignore\n      }\n    }\n    mediaRecorderRef.current = null;\n\n    // Stop stream tracks\n    if (streamRef.current) {\n      streamRef.current.getTracks().forEach(track => track.stop());\n      streamRef.current = null;\n    }\n\n    // Close audio context\n    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\n      audioContextRef.current.close();\n      audioContextRef.current = null;\n    }\n    analyserRef.current = null;\n\n    // Stop any playing audio\n    if (currentAudioRef.current) {\n      currentAudioRef.current.pause();\n      currentAudioRef.current = null;\n    }\n\n    // Abort any pending requests\n    if (abortControllerRef.current) {\n      abortControllerRef.current.abort();\n      abortControllerRef.current = null;\n    }\n\n    // Reset refs\n    audioChunksRef.current = [];\n    silenceStartRef.current = null;\n  }, []);\n\n  // Update audio intensity for UI feedback\n  const updateAudioLevel = useCallback(() => {\n    if (!analyserRef.current) return;\n\n    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);\n    analyserRef.current.getByteFrequencyData(dataArray);\n\n    // Calculate average level\n    let sum = 0;\n    for (let i = 0; i < dataArray.length; i++) {\n      sum += dataArray[i];\n    }\n    const level = sum / dataArray.length / 255;\n    setAudioIntensity(level);\n    lastAudioLevelRef.current = level;\n\n    // Detect silence for auto-send\n    if (level < silenceThreshold) {\n      if (!silenceStartRef.current) {\n        silenceStartRef.current = Date.now();\n      } else if (Date.now() - silenceStartRef.current > silenceDurationMs) {\n        // Silence detected long enough - could trigger auto-send here\n        // For now, we rely on manual tap-to-send per the UX\n      }\n    } else {\n      silenceStartRef.current = null;\n    }\n  }, [silenceThreshold, silenceDurationMs]);\n\n  // Transcribe audio chunk via Whisper\n  const transcribeChunk = useCallback(async (audioBlob: Blob): Promise<string> => {\n    const formData = new FormData();\n    formData.append('audio', audioBlob, 'chunk.webm');\n    formData.append('language', 'en');\n\n    const startTime = Date.now();\n    log.info('transcribeChunk() - sending to Whisper', { size: audioBlob.size });\n\n    try {\n      const response = await fetch(whisperEndpoint, {\n        method: 'POST',\n        body: formData,\n        signal: abortControllerRef.current?.signal,\n      });\n\n      if (!response.ok) {\n        throw new Error(`Whisper error: ${response.status}`);\n      }\n\n      const result = await response.json();\n      log.timing('STT', Date.now() - startTime);\n      return result.text || '';\n    } catch (err) {\n      if (err instanceof Error && err.name === 'AbortError') {\n        log.info('Transcription aborted');\n        return '';\n      }\n      throw err;\n    }\n  }, [whisperEndpoint]);\n\n  // Get LLM response via streaming chat\n  const getAIResponse = useCallback(async (userMessage: string): Promise<string> => {\n    const startTime = Date.now();\n    log.info('getAIResponse() - sending to LLM', { length: userMessage.length });\n    onResponseStart?.();\n\n    try {\n      const response = await fetch(chatEndpoint, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          messages: [{ role: 'user', content: userMessage }],\n          model: 'claude',\n          stream: true,\n        }),\n        signal: abortControllerRef.current?.signal,\n      });\n\n      if (!response.ok) {\n        throw new Error(`Chat error: ${response.status}`);\n      }\n\n      // Read streaming response\n      const reader = response.body?.getReader();\n      if (!reader) throw new Error('No response body');\n\n      const decoder = new TextDecoder();\n      let fullResponse = '';\n      let firstTokenTime: number | null = null;\n\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        const chunk = decoder.decode(value);\n        const lines = chunk.split('\\n');\n\n        for (const line of lines) {\n          if (line.startsWith('data: ')) {\n            try {\n              const data = JSON.parse(line.slice(6));\n              if (data.content) {\n                if (!firstTokenTime) {\n                  firstTokenTime = Date.now();\n                  log.timing('LLM first token', firstTokenTime - startTime);\n                }\n                fullResponse += data.content;\n                setResponse(fullResponse);\n              }\n            } catch {\n              // Ignore parse errors for non-JSON lines\n            }\n          }\n        }\n      }\n\n      log.timing('LLM total', Date.now() - startTime);\n      return fullResponse;\n    } catch (err) {\n      if (err instanceof Error && err.name === 'AbortError') {\n        log.info('LLM request aborted');\n        return '';\n      }\n      throw err;\n    }\n  }, [chatEndpoint, onResponseStart]);\n\n  // Speak response via TTS\n  const speakResponse = useCallback(async (text: string): Promise<void> => {\n    const startTime = Date.now();\n    log.info('speakResponse() - sending to TTS', { length: text.length });\n\n    try {\n      const response = await fetch(ttsEndpoint, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ text, voice: 'nova' }),\n        signal: abortControllerRef.current?.signal,\n      });\n\n      if (!response.ok) {\n        throw new Error(`TTS error: ${response.status}`);\n      }\n\n      const audioBlob = await response.blob();\n      log.timing('TTS', Date.now() - startTime);\n\n      // Play audio\n      const audioUrl = URL.createObjectURL(audioBlob);\n      const audio = new Audio(audioUrl);\n      currentAudioRef.current = audio;\n\n      return new Promise((resolve, reject) => {\n        audio.onended = () => {\n          URL.revokeObjectURL(audioUrl);\n          currentAudioRef.current = null;\n          resolve();\n        };\n        audio.onerror = () => {\n          URL.revokeObjectURL(audioUrl);\n          currentAudioRef.current = null;\n          reject(new Error('Audio playback failed'));\n        };\n        audio.play().catch(reject);\n      });\n    } catch (err) {\n      if (err instanceof Error && err.name === 'AbortError') {\n        log.info('TTS aborted');\n        return;\n      }\n      throw err;\n    }\n  }, [ttsEndpoint]);\n\n  // Start voice mode (begin listening)\n  const start = useCallback(async () => {\n    log.info('start() - initializing voice mode');\n    startTimeRef.current = Date.now();\n\n    cleanup();\n    setError(null);\n    setTranscript('');\n    setResponse('');\n    audioChunksRef.current = [];\n\n    try {\n      // Request microphone\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          echoCancellation: true,\n          noiseSuppression: true,\n          autoGainControl: true,\n        },\n      });\n      streamRef.current = stream;\n\n      // Set up audio analysis\n      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;\n      const audioContext = new AudioContextClass();\n      audioContextRef.current = audioContext;\n\n      const analyser = audioContext.createAnalyser();\n      analyser.fftSize = 256;\n      analyser.smoothingTimeConstant = 0.5;\n      analyserRef.current = analyser;\n\n      const source = audioContext.createMediaStreamSource(stream);\n      source.connect(analyser);\n\n      // Create media recorder\n      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')\n        ? 'audio/webm;codecs=opus'\n        : 'audio/webm';\n\n      const mediaRecorder = new MediaRecorder(stream, { mimeType });\n      mediaRecorderRef.current = mediaRecorder;\n\n      mediaRecorder.ondataavailable = (event) => {\n        if (event.data.size > 0) {\n          audioChunksRef.current.push(event.data);\n        }\n      };\n\n      // Start recording\n      mediaRecorder.start(100); // Collect data every 100ms\n      abortControllerRef.current = new AbortController();\n\n      // Start audio level monitoring\n      audioLevelIntervalRef.current = setInterval(updateAudioLevel, AUDIO_LEVEL_UPDATE_INTERVAL);\n\n      transitionState('listening');\n      log.timing('Mic ready', Date.now() - startTimeRef.current);\n    } catch (err) {\n      const errorMsg = err instanceof Error ? err.message : 'Failed to start voice mode';\n      log.error('start() failed', err);\n      setError(errorMsg);\n      onError?.(errorMsg);\n      cleanup();\n    }\n  }, [cleanup, updateAudioLevel, transitionState, onError]);\n\n  // Stop voice mode completely\n  const stop = useCallback(() => {\n    log.info('stop() - ending voice mode');\n    cleanup();\n    transitionState('idle');\n    setAudioIntensity(0);\n  }, [cleanup, transitionState]);\n\n  // Send current audio for processing (manual trigger)\n  const send = useCallback(async () => {\n    if (state !== 'listening' || audioChunksRef.current.length === 0) {\n      log.warn('send() - nothing to send', { state, chunks: audioChunksRef.current.length });\n      return;\n    }\n\n    log.info('send() - processing audio');\n    const totalStartTime = Date.now();\n\n    // Stop recording but keep resources\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {\n      mediaRecorderRef.current.stop();\n    }\n\n    transitionState('processing');\n\n    try {\n      // Combine audio chunks\n      const audioBlob = new Blob(audioChunksRef.current, {\n        type: mediaRecorderRef.current?.mimeType || 'audio/webm',\n      });\n      audioChunksRef.current = [];\n\n      // Transcribe\n      const text = await transcribeChunk(audioBlob);\n      if (!text.trim()) {\n        log.warn('Empty transcript, returning to listening');\n        await start(); // Restart listening\n        return;\n      }\n\n      setTranscript(text);\n      onTranscriptUpdate?.(text, true);\n      log.info('Transcript ready', { text: text.substring(0, 50) + '...' });\n\n      // Get AI response\n      const aiResponse = await getAIResponse(text);\n      if (!aiResponse.trim()) {\n        log.warn('Empty AI response');\n        onResponseEnd?.('');\n        await start();\n        return;\n      }\n\n      onResponseEnd?.(aiResponse);\n\n      // Speak response\n      transitionState('speaking');\n      await speakResponse(aiResponse);\n\n      // Return to listening after speaking\n      log.timing('Total round-trip', Date.now() - totalStartTime);\n      await start();\n    } catch (err) {\n      const errorMsg = err instanceof Error ? err.message : 'Processing failed';\n      log.error('send() failed', err);\n      setError(errorMsg);\n      onError?.(errorMsg);\n      stop();\n    }\n  }, [state, start, stop, transcribeChunk, getAIResponse, speakResponse, transitionState, onTranscriptUpdate, onResponseEnd, onError]);\n\n  // Interrupt speaking and switch back to listening\n  const interrupt = useCallback(() => {\n    log.info('interrupt() - stopping speech, returning to listening');\n\n    // Stop current audio playback\n    if (currentAudioRef.current) {\n      currentAudioRef.current.pause();\n      currentAudioRef.current = null;\n    }\n\n    // Abort any pending requests\n    if (abortControllerRef.current) {\n      abortControllerRef.current.abort();\n    }\n\n    // Restart listening\n    start();\n  }, [start]);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      cleanup();\n    };\n  }, [cleanup]);\n\n  return {\n    state,\n    isActive: state !== 'idle',\n    transcript,\n    response,\n    audioIntensity,\n    error,\n    start,\n    stop,\n    send,\n    interrupt,\n  };\n}\n\nexport default useVoiceMode;\n"],"names":[],"mappings":";;;;;;AAEA;;AAFA;;AA6CA,+EAA+E;AAC/E,YAAY;AACZ,+EAA+E;AAE/E,MAAM,yBAAyB,MAAM,YAAY;AACjD,MAAM,4BAA4B;AAClC,MAAM,2BAA2B,MAAM,cAAc;AACrD,MAAM,8BAA8B,IAAI,OAAO;AAE/C,gBAAgB;AAChB,MAAM,aAAa;AACnB,MAAM,MAAM;IACV,MAAM,CAAC,KAAa,OAAmB,QAAQ,GAAG,CAAC,GAAG,WAAW,CAAC,EAAE,KAAK,EAAE,QAAQ;IACnF,MAAM,CAAC,KAAa,OAAmB,QAAQ,IAAI,CAAC,GAAG,WAAW,CAAC,EAAE,KAAK,EAAE,QAAQ;IACpF,OAAO,CAAC,KAAa,OAAmB,QAAQ,KAAK,CAAC,GAAG,WAAW,CAAC,EAAE,KAAK,EAAE,QAAQ;IACtF,OAAO,CAAC,MAAsB,KAC5B,QAAQ,GAAG,CAAC,GAAG,WAAW,SAAS,EAAE,KAAK,GAAG,EAAE,IAAI;IACrD,QAAQ,CAAC,OAAe,KACtB,QAAQ,GAAG,CAAC,GAAG,WAAW,UAAU,EAAE,MAAM,EAAE,EAAE,GAAG,EAAE,CAAC;AAC1D;AAMO,SAAS,aAAa,SAA0B,CAAC,CAAC;;IACvD,MAAM,EACJ,kBAAkB,sBAAsB,EACxC,mBAAmB,yBAAyB,EAC5C,oBAAoB,wBAAwB,EAC5C,kBAAkB,cAAc,EAChC,eAAe,kBAAkB,EACjC,cAAc,UAAU,EACxB,kBAAkB,EAClB,eAAe,EACf,aAAa,EACb,OAAO,EACP,aAAa,EACd,GAAG;IAEJ,QAAQ;IACR,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,kXAAQ,EAAiB;IACnD,MAAM,CAAC,YAAY,cAAc,GAAG,IAAA,kXAAQ,EAAC;IAC7C,MAAM,CAAC,UAAU,YAAY,GAAG,IAAA,kXAAQ,EAAC;IACzC,MAAM,CAAC,gBAAgB,kBAAkB,GAAG,IAAA,kXAAQ,EAAC;IACrD,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,kXAAQ,EAAgB;IAElD,kCAAkC;IAClC,MAAM,mBAAmB,IAAA,gXAAM,EAAuB;IACtD,MAAM,kBAAkB,IAAA,gXAAM,EAAsB;IACpD,MAAM,cAAc,IAAA,gXAAM,EAAsB;IAChD,MAAM,YAAY,IAAA,gXAAM,EAAqB;IAC7C,MAAM,iBAAiB,IAAA,gXAAM,EAAS,EAAE;IACxC,MAAM,wBAAwB,IAAA,gXAAM,EAAwB;IAC5D,MAAM,oBAAoB,IAAA,gXAAM,EAAwB;IACxD,MAAM,mBAAmB,IAAA,gXAAM,EAAwB;IACvD,MAAM,oBAAoB,IAAA,gXAAM,EAAC;IACjC,MAAM,kBAAkB,IAAA,gXAAM,EAAgB;IAC9C,MAAM,kBAAkB,IAAA,gXAAM,EAA0B;IACxD,MAAM,qBAAqB,IAAA,gXAAM,EAAyB;IAC1D,MAAM,eAAe,IAAA,gXAAM,EAAS;IAEpC,yCAAyC;IACzC,MAAM,kBAAkB,IAAA,qXAAW;qDAAC,CAAC;YACnC;6DAAS,CAAA;oBACP,IAAI,SAAS,UAAU;wBACrB,IAAI,KAAK,CAAC,MAAM;wBAChB,gBAAgB;oBAClB;oBACA,OAAO;gBACT;;QACF;oDAAG;QAAC;KAAc;IAElB,wBAAwB;IACxB,MAAM,UAAU,IAAA,qXAAW;6CAAC;YAC1B,IAAI,IAAI,CAAC;YAET,iBAAiB;YACjB,IAAI,sBAAsB,OAAO,EAAE;gBACjC,cAAc,sBAAsB,OAAO;gBAC3C,sBAAsB,OAAO,GAAG;YAClC;YACA,IAAI,kBAAkB,OAAO,EAAE;gBAC7B,aAAa,kBAAkB,OAAO;gBACtC,kBAAkB,OAAO,GAAG;YAC9B;YACA,IAAI,iBAAiB,OAAO,EAAE;gBAC5B,cAAc,iBAAiB,OAAO;gBACtC,iBAAiB,OAAO,GAAG;YAC7B;YAEA,sBAAsB;YACtB,IAAI,iBAAiB,OAAO,IAAI,iBAAiB,OAAO,CAAC,KAAK,KAAK,YAAY;gBAC7E,IAAI;oBACF,iBAAiB,OAAO,CAAC,IAAI;gBAC/B,EAAE,OAAM;gBACN,SAAS;gBACX;YACF;YACA,iBAAiB,OAAO,GAAG;YAE3B,qBAAqB;YACrB,IAAI,UAAU,OAAO,EAAE;gBACrB,UAAU,OAAO,CAAC,SAAS,GAAG,OAAO;yDAAC,CAAA,QAAS,MAAM,IAAI;;gBACzD,UAAU,OAAO,GAAG;YACtB;YAEA,sBAAsB;YACtB,IAAI,gBAAgB,OAAO,IAAI,gBAAgB,OAAO,CAAC,KAAK,KAAK,UAAU;gBACzE,gBAAgB,OAAO,CAAC,KAAK;gBAC7B,gBAAgB,OAAO,GAAG;YAC5B;YACA,YAAY,OAAO,GAAG;YAEtB,yBAAyB;YACzB,IAAI,gBAAgB,OAAO,EAAE;gBAC3B,gBAAgB,OAAO,CAAC,KAAK;gBAC7B,gBAAgB,OAAO,GAAG;YAC5B;YAEA,6BAA6B;YAC7B,IAAI,mBAAmB,OAAO,EAAE;gBAC9B,mBAAmB,OAAO,CAAC,KAAK;gBAChC,mBAAmB,OAAO,GAAG;YAC/B;YAEA,aAAa;YACb,eAAe,OAAO,GAAG,EAAE;YAC3B,gBAAgB,OAAO,GAAG;QAC5B;4CAAG,EAAE;IAEL,yCAAyC;IACzC,MAAM,mBAAmB,IAAA,qXAAW;sDAAC;YACnC,IAAI,CAAC,YAAY,OAAO,EAAE;YAE1B,MAAM,YAAY,IAAI,WAAW,YAAY,OAAO,CAAC,iBAAiB;YACtE,YAAY,OAAO,CAAC,oBAAoB,CAAC;YAEzC,0BAA0B;YAC1B,IAAI,MAAM;YACV,IAAK,IAAI,IAAI,GAAG,IAAI,UAAU,MAAM,EAAE,IAAK;gBACzC,OAAO,SAAS,CAAC,EAAE;YACrB;YACA,MAAM,QAAQ,MAAM,UAAU,MAAM,GAAG;YACvC,kBAAkB;YAClB,kBAAkB,OAAO,GAAG;YAE5B,+BAA+B;YAC/B,IAAI,QAAQ,kBAAkB;gBAC5B,IAAI,CAAC,gBAAgB,OAAO,EAAE;oBAC5B,gBAAgB,OAAO,GAAG,KAAK,GAAG;gBACpC,OAAO,IAAI,KAAK,GAAG,KAAK,gBAAgB,OAAO,GAAG,mBAAmB;gBACnE,8DAA8D;gBAC9D,oDAAoD;gBACtD;YACF,OAAO;gBACL,gBAAgB,OAAO,GAAG;YAC5B;QACF;qDAAG;QAAC;QAAkB;KAAkB;IAExC,qCAAqC;IACrC,MAAM,kBAAkB,IAAA,qXAAW;qDAAC,OAAO;YACzC,MAAM,WAAW,IAAI;YACrB,SAAS,MAAM,CAAC,SAAS,WAAW;YACpC,SAAS,MAAM,CAAC,YAAY;YAE5B,MAAM,YAAY,KAAK,GAAG;YAC1B,IAAI,IAAI,CAAC,0CAA0C;gBAAE,MAAM,UAAU,IAAI;YAAC;YAE1E,IAAI;gBACF,MAAM,WAAW,MAAM,MAAM,iBAAiB;oBAC5C,QAAQ;oBACR,MAAM;oBACN,QAAQ,mBAAmB,OAAO,EAAE;gBACtC;gBAEA,IAAI,CAAC,SAAS,EAAE,EAAE;oBAChB,MAAM,IAAI,MAAM,CAAC,eAAe,EAAE,SAAS,MAAM,EAAE;gBACrD;gBAEA,MAAM,SAAS,MAAM,SAAS,IAAI;gBAClC,IAAI,MAAM,CAAC,OAAO,KAAK,GAAG,KAAK;gBAC/B,OAAO,OAAO,IAAI,IAAI;YACxB,EAAE,OAAO,KAAK;gBACZ,IAAI,eAAe,SAAS,IAAI,IAAI,KAAK,cAAc;oBACrD,IAAI,IAAI,CAAC;oBACT,OAAO;gBACT;gBACA,MAAM;YACR;QACF;oDAAG;QAAC;KAAgB;IAEpB,sCAAsC;IACtC,MAAM,gBAAgB,IAAA,qXAAW;mDAAC,OAAO;YACvC,MAAM,YAAY,KAAK,GAAG;YAC1B,IAAI,IAAI,CAAC,oCAAoC;gBAAE,QAAQ,YAAY,MAAM;YAAC;YAC1E;YAEA,IAAI;gBACF,MAAM,WAAW,MAAM,MAAM,cAAc;oBACzC,QAAQ;oBACR,SAAS;wBAAE,gBAAgB;oBAAmB;oBAC9C,MAAM,KAAK,SAAS,CAAC;wBACnB,UAAU;4BAAC;gCAAE,MAAM;gCAAQ,SAAS;4BAAY;yBAAE;wBAClD,OAAO;wBACP,QAAQ;oBACV;oBACA,QAAQ,mBAAmB,OAAO,EAAE;gBACtC;gBAEA,IAAI,CAAC,SAAS,EAAE,EAAE;oBAChB,MAAM,IAAI,MAAM,CAAC,YAAY,EAAE,SAAS,MAAM,EAAE;gBAClD;gBAEA,0BAA0B;gBAC1B,MAAM,SAAS,SAAS,IAAI,EAAE;gBAC9B,IAAI,CAAC,QAAQ,MAAM,IAAI,MAAM;gBAE7B,MAAM,UAAU,IAAI;gBACpB,IAAI,eAAe;gBACnB,IAAI,iBAAgC;gBAEpC,MAAO,KAAM;oBACX,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,OAAO,IAAI;oBACzC,IAAI,MAAM;oBAEV,MAAM,QAAQ,QAAQ,MAAM,CAAC;oBAC7B,MAAM,QAAQ,MAAM,KAAK,CAAC;oBAE1B,KAAK,MAAM,QAAQ,MAAO;wBACxB,IAAI,KAAK,UAAU,CAAC,WAAW;4BAC7B,IAAI;gCACF,MAAM,OAAO,KAAK,KAAK,CAAC,KAAK,KAAK,CAAC;gCACnC,IAAI,KAAK,OAAO,EAAE;oCAChB,IAAI,CAAC,gBAAgB;wCACnB,iBAAiB,KAAK,GAAG;wCACzB,IAAI,MAAM,CAAC,mBAAmB,iBAAiB;oCACjD;oCACA,gBAAgB,KAAK,OAAO;oCAC5B,YAAY;gCACd;4BACF,EAAE,OAAM;4BACN,yCAAyC;4BAC3C;wBACF;oBACF;gBACF;gBAEA,IAAI,MAAM,CAAC,aAAa,KAAK,GAAG,KAAK;gBACrC,OAAO;YACT,EAAE,OAAO,KAAK;gBACZ,IAAI,eAAe,SAAS,IAAI,IAAI,KAAK,cAAc;oBACrD,IAAI,IAAI,CAAC;oBACT,OAAO;gBACT;gBACA,MAAM;YACR;QACF;kDAAG;QAAC;QAAc;KAAgB;IAElC,yBAAyB;IACzB,MAAM,gBAAgB,IAAA,qXAAW;mDAAC,OAAO;YACvC,MAAM,YAAY,KAAK,GAAG;YAC1B,IAAI,IAAI,CAAC,oCAAoC;gBAAE,QAAQ,KAAK,MAAM;YAAC;YAEnE,IAAI;gBACF,MAAM,WAAW,MAAM,MAAM,aAAa;oBACxC,QAAQ;oBACR,SAAS;wBAAE,gBAAgB;oBAAmB;oBAC9C,MAAM,KAAK,SAAS,CAAC;wBAAE;wBAAM,OAAO;oBAAO;oBAC3C,QAAQ,mBAAmB,OAAO,EAAE;gBACtC;gBAEA,IAAI,CAAC,SAAS,EAAE,EAAE;oBAChB,MAAM,IAAI,MAAM,CAAC,WAAW,EAAE,SAAS,MAAM,EAAE;gBACjD;gBAEA,MAAM,YAAY,MAAM,SAAS,IAAI;gBACrC,IAAI,MAAM,CAAC,OAAO,KAAK,GAAG,KAAK;gBAE/B,aAAa;gBACb,MAAM,WAAW,IAAI,eAAe,CAAC;gBACrC,MAAM,QAAQ,IAAI,MAAM;gBACxB,gBAAgB,OAAO,GAAG;gBAE1B,OAAO,IAAI;+DAAQ,CAAC,SAAS;wBAC3B,MAAM,OAAO;uEAAG;gCACd,IAAI,eAAe,CAAC;gCACpB,gBAAgB,OAAO,GAAG;gCAC1B;4BACF;;wBACA,MAAM,OAAO;uEAAG;gCACd,IAAI,eAAe,CAAC;gCACpB,gBAAgB,OAAO,GAAG;gCAC1B,OAAO,IAAI,MAAM;4BACnB;;wBACA,MAAM,IAAI,GAAG,KAAK,CAAC;oBACrB;;YACF,EAAE,OAAO,KAAK;gBACZ,IAAI,eAAe,SAAS,IAAI,IAAI,KAAK,cAAc;oBACrD,IAAI,IAAI,CAAC;oBACT;gBACF;gBACA,MAAM;YACR;QACF;kDAAG;QAAC;KAAY;IAEhB,qCAAqC;IACrC,MAAM,QAAQ,IAAA,qXAAW;2CAAC;YACxB,IAAI,IAAI,CAAC;YACT,aAAa,OAAO,GAAG,KAAK,GAAG;YAE/B;YACA,SAAS;YACT,cAAc;YACd,YAAY;YACZ,eAAe,OAAO,GAAG,EAAE;YAE3B,IAAI;gBACF,qBAAqB;gBACrB,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;oBACvD,OAAO;wBACL,kBAAkB;wBAClB,kBAAkB;wBAClB,iBAAiB;oBACnB;gBACF;gBACA,UAAU,OAAO,GAAG;gBAEpB,wBAAwB;gBACxB,MAAM,oBAAoB,OAAO,YAAY,IAAI,AAAC,OAAkE,kBAAkB;gBACtI,MAAM,eAAe,IAAI;gBACzB,gBAAgB,OAAO,GAAG;gBAE1B,MAAM,WAAW,aAAa,cAAc;gBAC5C,SAAS,OAAO,GAAG;gBACnB,SAAS,qBAAqB,GAAG;gBACjC,YAAY,OAAO,GAAG;gBAEtB,MAAM,SAAS,aAAa,uBAAuB,CAAC;gBACpD,OAAO,OAAO,CAAC;gBAEf,wBAAwB;gBACxB,MAAM,WAAW,cAAc,eAAe,CAAC,4BAC3C,2BACA;gBAEJ,MAAM,gBAAgB,IAAI,cAAc,QAAQ;oBAAE;gBAAS;gBAC3D,iBAAiB,OAAO,GAAG;gBAE3B,cAAc,eAAe;uDAAG,CAAC;wBAC/B,IAAI,MAAM,IAAI,CAAC,IAAI,GAAG,GAAG;4BACvB,eAAe,OAAO,CAAC,IAAI,CAAC,MAAM,IAAI;wBACxC;oBACF;;gBAEA,kBAAkB;gBAClB,cAAc,KAAK,CAAC,MAAM,2BAA2B;gBACrD,mBAAmB,OAAO,GAAG,IAAI;gBAEjC,+BAA+B;gBAC/B,sBAAsB,OAAO,GAAG,YAAY,kBAAkB;gBAE9D,gBAAgB;gBAChB,IAAI,MAAM,CAAC,aAAa,KAAK,GAAG,KAAK,aAAa,OAAO;YAC3D,EAAE,OAAO,KAAK;gBACZ,MAAM,WAAW,eAAe,QAAQ,IAAI,OAAO,GAAG;gBACtD,IAAI,KAAK,CAAC,kBAAkB;gBAC5B,SAAS;gBACT,UAAU;gBACV;YACF;QACF;0CAAG;QAAC;QAAS;QAAkB;QAAiB;KAAQ;IAExD,6BAA6B;IAC7B,MAAM,OAAO,IAAA,qXAAW;0CAAC;YACvB,IAAI,IAAI,CAAC;YACT;YACA,gBAAgB;YAChB,kBAAkB;QACpB;yCAAG;QAAC;QAAS;KAAgB;IAE7B,qDAAqD;IACrD,MAAM,OAAO,IAAA,qXAAW;0CAAC;YACvB,IAAI,UAAU,eAAe,eAAe,OAAO,CAAC,MAAM,KAAK,GAAG;gBAChE,IAAI,IAAI,CAAC,4BAA4B;oBAAE;oBAAO,QAAQ,eAAe,OAAO,CAAC,MAAM;gBAAC;gBACpF;YACF;YAEA,IAAI,IAAI,CAAC;YACT,MAAM,iBAAiB,KAAK,GAAG;YAE/B,oCAAoC;YACpC,IAAI,iBAAiB,OAAO,IAAI,iBAAiB,OAAO,CAAC,KAAK,KAAK,aAAa;gBAC9E,iBAAiB,OAAO,CAAC,IAAI;YAC/B;YAEA,gBAAgB;YAEhB,IAAI;gBACF,uBAAuB;gBACvB,MAAM,YAAY,IAAI,KAAK,eAAe,OAAO,EAAE;oBACjD,MAAM,iBAAiB,OAAO,EAAE,YAAY;gBAC9C;gBACA,eAAe,OAAO,GAAG,EAAE;gBAE3B,aAAa;gBACb,MAAM,OAAO,MAAM,gBAAgB;gBACnC,IAAI,CAAC,KAAK,IAAI,IAAI;oBAChB,IAAI,IAAI,CAAC;oBACT,MAAM,SAAS,oBAAoB;oBACnC;gBACF;gBAEA,cAAc;gBACd,qBAAqB,MAAM;gBAC3B,IAAI,IAAI,CAAC,oBAAoB;oBAAE,MAAM,KAAK,SAAS,CAAC,GAAG,MAAM;gBAAM;gBAEnE,kBAAkB;gBAClB,MAAM,aAAa,MAAM,cAAc;gBACvC,IAAI,CAAC,WAAW,IAAI,IAAI;oBACtB,IAAI,IAAI,CAAC;oBACT,gBAAgB;oBAChB,MAAM;oBACN;gBACF;gBAEA,gBAAgB;gBAEhB,iBAAiB;gBACjB,gBAAgB;gBAChB,MAAM,cAAc;gBAEpB,qCAAqC;gBACrC,IAAI,MAAM,CAAC,oBAAoB,KAAK,GAAG,KAAK;gBAC5C,MAAM;YACR,EAAE,OAAO,KAAK;gBACZ,MAAM,WAAW,eAAe,QAAQ,IAAI,OAAO,GAAG;gBACtD,IAAI,KAAK,CAAC,iBAAiB;gBAC3B,SAAS;gBACT,UAAU;gBACV;YACF;QACF;yCAAG;QAAC;QAAO;QAAO;QAAM;QAAiB;QAAe;QAAe;QAAiB;QAAoB;QAAe;KAAQ;IAEnI,kDAAkD;IAClD,MAAM,YAAY,IAAA,qXAAW;+CAAC;YAC5B,IAAI,IAAI,CAAC;YAET,8BAA8B;YAC9B,IAAI,gBAAgB,OAAO,EAAE;gBAC3B,gBAAgB,OAAO,CAAC,KAAK;gBAC7B,gBAAgB,OAAO,GAAG;YAC5B;YAEA,6BAA6B;YAC7B,IAAI,mBAAmB,OAAO,EAAE;gBAC9B,mBAAmB,OAAO,CAAC,KAAK;YAClC;YAEA,oBAAoB;YACpB;QACF;8CAAG;QAAC;KAAM;IAEV,qBAAqB;IACrB,IAAA,mXAAS;kCAAC;YACR;0CAAO;oBACL;gBACF;;QACF;iCAAG;QAAC;KAAQ;IAEZ,OAAO;QACL;QACA,UAAU,UAAU;QACpB;QACA;QACA;QACA;QACA;QACA;QACA;QACA;IACF;AACF;GAzcgB;uCA2cD"}},
    {"offset": {"line": 1955, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/usePerformanceMetrics.ts"],"sourcesContent":["\"use client\";\n\nimport { useState, useEffect, useCallback } from \"react\";\n\nexport interface PerformanceMetrics {\n  // Core Web Vitals\n  fcp: number | null; // First Contentful Paint\n  lcp: number | null; // Largest Contentful Paint\n  cls: number | null; // Cumulative Layout Shift\n  fid: number | null; // First Input Delay\n  inp: number | null; // Interaction to Next Paint\n  ttfb: number | null; // Time to First Byte\n\n  // Custom metrics\n  pageLoadTime: number | null;\n  domInteractive: number | null;\n  resourceCount: number;\n  transferSize: number; // KB\n\n  // Computed status\n  overallScore: \"fast\" | \"moderate\" | \"slow\";\n  primaryMetric: number | null; // The main ms value to display\n}\n\nconst initialMetrics: PerformanceMetrics = {\n  fcp: null,\n  lcp: null,\n  cls: null,\n  fid: null,\n  inp: null,\n  ttfb: null,\n  pageLoadTime: null,\n  domInteractive: null,\n  resourceCount: 0,\n  transferSize: 0,\n  overallScore: \"fast\",\n  primaryMetric: null,\n};\n\nfunction getOverallScore(metrics: Partial<PerformanceMetrics>): \"fast\" | \"moderate\" | \"slow\" {\n  const { lcp, fcp, cls, ttfb, pageLoadTime } = metrics;\n\n  // Primary metric for scoring (prefer LCP, fallback to FCP, then pageLoadTime)\n  const primaryTime = lcp ?? fcp ?? pageLoadTime ?? 0;\n\n  // Google's Core Web Vitals thresholds\n  // LCP: Good < 2500ms, Needs Improvement < 4000ms, Poor >= 4000ms\n  // FCP: Good < 1800ms, Needs Improvement < 3000ms, Poor >= 3000ms\n  // CLS: Good < 0.1, Needs Improvement < 0.25, Poor >= 0.25\n  // TTFB: Good < 800ms, Needs Improvement < 1800ms, Poor >= 1800ms\n\n  let score = 0;\n  let count = 0;\n\n  if (primaryTime > 0) {\n    if (primaryTime < 1500) score += 3;\n    else if (primaryTime < 2500) score += 2;\n    else if (primaryTime < 4000) score += 1;\n    count++;\n  }\n\n  if (ttfb && ttfb > 0) {\n    if (ttfb < 400) score += 3;\n    else if (ttfb < 800) score += 2;\n    else if (ttfb < 1800) score += 1;\n    count++;\n  }\n\n  if (cls !== null && cls !== undefined) {\n    if (cls < 0.1) score += 3;\n    else if (cls < 0.25) score += 2;\n    else score += 1;\n    count++;\n  }\n\n  if (count === 0) return \"fast\";\n\n  const avg = score / count;\n  if (avg >= 2.5) return \"fast\";\n  if (avg >= 1.5) return \"moderate\";\n  return \"slow\";\n}\n\nexport function usePerformanceMetrics() {\n  const [metrics, setMetrics] = useState<PerformanceMetrics>(initialMetrics);\n  const [isSupported, setIsSupported] = useState(true);\n\n  const updateMetrics = useCallback((updates: Partial<PerformanceMetrics>) => {\n    setMetrics((prev) => {\n      const newMetrics = { ...prev, ...updates };\n      // Recalculate primary metric and score\n      newMetrics.primaryMetric = newMetrics.lcp ?? newMetrics.fcp ?? newMetrics.pageLoadTime;\n      newMetrics.overallScore = getOverallScore(newMetrics);\n      return newMetrics;\n    });\n  }, []);\n\n  useEffect(() => {\n    if (typeof window === \"undefined\" || !window.performance) {\n      setIsSupported(false);\n      return;\n    }\n\n    // Get navigation timing data\n    const getNavigationTiming = () => {\n      const navigation = performance.getEntriesByType(\"navigation\")[0] as PerformanceNavigationTiming | undefined;\n\n      if (navigation) {\n        const pageLoadTime = navigation.loadEventEnd - navigation.startTime;\n        const domInteractive = navigation.domInteractive - navigation.startTime;\n        const ttfb = navigation.responseStart - navigation.requestStart;\n\n        updateMetrics({\n          pageLoadTime: pageLoadTime > 0 ? Math.round(pageLoadTime) : null,\n          domInteractive: domInteractive > 0 ? Math.round(domInteractive) : null,\n          ttfb: ttfb > 0 ? Math.round(ttfb) : null,\n        });\n      }\n    };\n\n    // Get resource timing data\n    const getResourceTiming = () => {\n      const resources = performance.getEntriesByType(\"resource\") as PerformanceResourceTiming[];\n      const totalSize = resources.reduce((acc, r) => acc + (r.transferSize || 0), 0);\n\n      updateMetrics({\n        resourceCount: resources.length,\n        transferSize: Math.round(totalSize / 1024), // Convert to KB\n      });\n    };\n\n    // Initial timing collection after page load\n    if (document.readyState === \"complete\") {\n      getNavigationTiming();\n      getResourceTiming();\n    } else {\n      window.addEventListener(\"load\", () => {\n        // Wait a bit for metrics to stabilize\n        setTimeout(() => {\n          getNavigationTiming();\n          getResourceTiming();\n        }, 100);\n      });\n    }\n\n    // Observe paint timing (FCP)\n    const paintObserver = new PerformanceObserver((entryList) => {\n      for (const entry of entryList.getEntries()) {\n        if (entry.name === \"first-contentful-paint\") {\n          updateMetrics({ fcp: Math.round(entry.startTime) });\n        }\n      }\n    });\n\n    try {\n      paintObserver.observe({ type: \"paint\", buffered: true });\n    } catch {\n      // Paint observer not supported\n    }\n\n    // Observe LCP\n    const lcpObserver = new PerformanceObserver((entryList) => {\n      const entries = entryList.getEntries();\n      const lastEntry = entries[entries.length - 1];\n      if (lastEntry) {\n        updateMetrics({ lcp: Math.round(lastEntry.startTime) });\n      }\n    });\n\n    try {\n      lcpObserver.observe({ type: \"largest-contentful-paint\", buffered: true });\n    } catch {\n      // LCP observer not supported\n    }\n\n    // Observe CLS\n    let clsValue = 0;\n    const clsObserver = new PerformanceObserver((entryList) => {\n      for (const entry of entryList.getEntries()) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        if (!(entry as any).hadRecentInput) {\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\n          clsValue += (entry as any).value;\n          updateMetrics({ cls: Math.round(clsValue * 1000) / 1000 });\n        }\n      }\n    });\n\n    try {\n      clsObserver.observe({ type: \"layout-shift\", buffered: true });\n    } catch {\n      // CLS observer not supported\n    }\n\n    // Observe FID\n    const fidObserver = new PerformanceObserver((entryList) => {\n      for (const entry of entryList.getEntries()) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const fidEntry = entry as any;\n        updateMetrics({ fid: Math.round(fidEntry.processingStart - fidEntry.startTime) });\n      }\n    });\n\n    try {\n      fidObserver.observe({ type: \"first-input\", buffered: true });\n    } catch {\n      // FID observer not supported\n    }\n\n    // Observe INP (Interaction to Next Paint)\n    const inpObserver = new PerformanceObserver((entryList) => {\n      for (const entry of entryList.getEntries()) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const duration = (entry as any).duration;\n        if (duration) {\n          updateMetrics({ inp: Math.round(duration) });\n        }\n      }\n    });\n\n    try {\n      inpObserver.observe({ type: \"event\", buffered: true });\n    } catch {\n      // INP observer not supported\n    }\n\n    return () => {\n      paintObserver.disconnect();\n      lcpObserver.disconnect();\n      clsObserver.disconnect();\n      fidObserver.disconnect();\n      inpObserver.disconnect();\n    };\n  }, [updateMetrics]);\n\n  // Force refresh metrics\n  const refreshMetrics = useCallback(() => {\n    if (typeof window === \"undefined\" || !window.performance) return;\n\n    const navigation = performance.getEntriesByType(\"navigation\")[0] as PerformanceNavigationTiming | undefined;\n    const resources = performance.getEntriesByType(\"resource\") as PerformanceResourceTiming[];\n\n    if (navigation) {\n      const pageLoadTime = navigation.loadEventEnd - navigation.startTime;\n      const ttfb = navigation.responseStart - navigation.requestStart;\n      const totalSize = resources.reduce((acc, r) => acc + (r.transferSize || 0), 0);\n\n      updateMetrics({\n        pageLoadTime: pageLoadTime > 0 ? Math.round(pageLoadTime) : null,\n        ttfb: ttfb > 0 ? Math.round(ttfb) : null,\n        resourceCount: resources.length,\n        transferSize: Math.round(totalSize / 1024),\n      });\n    }\n  }, [updateMetrics]);\n\n  return { metrics, isSupported, refreshMetrics };\n}\n"],"names":[],"mappings":";;;;AAEA;;AAFA;;AAwBA,MAAM,iBAAqC;IACzC,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,MAAM;IACN,cAAc;IACd,gBAAgB;IAChB,eAAe;IACf,cAAc;IACd,cAAc;IACd,eAAe;AACjB;AAEA,SAAS,gBAAgB,OAAoC;IAC3D,MAAM,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,YAAY,EAAE,GAAG;IAE9C,8EAA8E;IAC9E,MAAM,cAAc,OAAO,OAAO,gBAAgB;IAElD,sCAAsC;IACtC,iEAAiE;IACjE,iEAAiE;IACjE,0DAA0D;IAC1D,iEAAiE;IAEjE,IAAI,QAAQ;IACZ,IAAI,QAAQ;IAEZ,IAAI,cAAc,GAAG;QACnB,IAAI,cAAc,MAAM,SAAS;aAC5B,IAAI,cAAc,MAAM,SAAS;aACjC,IAAI,cAAc,MAAM,SAAS;QACtC;IACF;IAEA,IAAI,QAAQ,OAAO,GAAG;QACpB,IAAI,OAAO,KAAK,SAAS;aACpB,IAAI,OAAO,KAAK,SAAS;aACzB,IAAI,OAAO,MAAM,SAAS;QAC/B;IACF;IAEA,IAAI,QAAQ,QAAQ,QAAQ,WAAW;QACrC,IAAI,MAAM,KAAK,SAAS;aACnB,IAAI,MAAM,MAAM,SAAS;aACzB,SAAS;QACd;IACF;IAEA,IAAI,UAAU,GAAG,OAAO;IAExB,MAAM,MAAM,QAAQ;IACpB,IAAI,OAAO,KAAK,OAAO;IACvB,IAAI,OAAO,KAAK,OAAO;IACvB,OAAO;AACT;AAEO,SAAS;;IACd,MAAM,CAAC,SAAS,WAAW,GAAG,IAAA,kXAAQ,EAAqB;IAC3D,MAAM,CAAC,aAAa,eAAe,GAAG,IAAA,kXAAQ,EAAC;IAE/C,MAAM,gBAAgB,IAAA,qXAAW;4DAAC,CAAC;YACjC;oEAAW,CAAC;oBACV,MAAM,aAAa;wBAAE,GAAG,IAAI;wBAAE,GAAG,OAAO;oBAAC;oBACzC,uCAAuC;oBACvC,WAAW,aAAa,GAAG,WAAW,GAAG,IAAI,WAAW,GAAG,IAAI,WAAW,YAAY;oBACtF,WAAW,YAAY,GAAG,gBAAgB;oBAC1C,OAAO;gBACT;;QACF;2DAAG,EAAE;IAEL,IAAA,mXAAS;2CAAC;YACR,IAAI,+CAAkB,eAAe,CAAC,OAAO,WAAW,EAAE;gBACxD,eAAe;gBACf;YACF;YAEA,6BAA6B;YAC7B,MAAM;uEAAsB;oBAC1B,MAAM,aAAa,YAAY,gBAAgB,CAAC,aAAa,CAAC,EAAE;oBAEhE,IAAI,YAAY;wBACd,MAAM,eAAe,WAAW,YAAY,GAAG,WAAW,SAAS;wBACnE,MAAM,iBAAiB,WAAW,cAAc,GAAG,WAAW,SAAS;wBACvE,MAAM,OAAO,WAAW,aAAa,GAAG,WAAW,YAAY;wBAE/D,cAAc;4BACZ,cAAc,eAAe,IAAI,KAAK,KAAK,CAAC,gBAAgB;4BAC5D,gBAAgB,iBAAiB,IAAI,KAAK,KAAK,CAAC,kBAAkB;4BAClE,MAAM,OAAO,IAAI,KAAK,KAAK,CAAC,QAAQ;wBACtC;oBACF;gBACF;;YAEA,2BAA2B;YAC3B,MAAM;qEAAoB;oBACxB,MAAM,YAAY,YAAY,gBAAgB,CAAC;oBAC/C,MAAM,YAAY,UAAU,MAAM;uFAAC,CAAC,KAAK,IAAM,MAAM,CAAC,EAAE,YAAY,IAAI,CAAC;sFAAG;oBAE5E,cAAc;wBACZ,eAAe,UAAU,MAAM;wBAC/B,cAAc,KAAK,KAAK,CAAC,YAAY;oBACvC;gBACF;;YAEA,4CAA4C;YAC5C,IAAI,SAAS,UAAU,KAAK,YAAY;gBACtC;gBACA;YACF,OAAO;gBACL,OAAO,gBAAgB,CAAC;uDAAQ;wBAC9B,sCAAsC;wBACtC;+DAAW;gCACT;gCACA;4BACF;8DAAG;oBACL;;YACF;YAEA,6BAA6B;YAC7B,MAAM,gBAAgB,IAAI;mDAAoB,CAAC;oBAC7C,KAAK,MAAM,SAAS,UAAU,UAAU,GAAI;wBAC1C,IAAI,MAAM,IAAI,KAAK,0BAA0B;4BAC3C,cAAc;gCAAE,KAAK,KAAK,KAAK,CAAC,MAAM,SAAS;4BAAE;wBACnD;oBACF;gBACF;;YAEA,IAAI;gBACF,cAAc,OAAO,CAAC;oBAAE,MAAM;oBAAS,UAAU;gBAAK;YACxD,EAAE,OAAM;YACN,+BAA+B;YACjC;YAEA,cAAc;YACd,MAAM,cAAc,IAAI;mDAAoB,CAAC;oBAC3C,MAAM,UAAU,UAAU,UAAU;oBACpC,MAAM,YAAY,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE;oBAC7C,IAAI,WAAW;wBACb,cAAc;4BAAE,KAAK,KAAK,KAAK,CAAC,UAAU,SAAS;wBAAE;oBACvD;gBACF;;YAEA,IAAI;gBACF,YAAY,OAAO,CAAC;oBAAE,MAAM;oBAA4B,UAAU;gBAAK;YACzE,EAAE,OAAM;YACN,6BAA6B;YAC/B;YAEA,cAAc;YACd,IAAI,WAAW;YACf,MAAM,cAAc,IAAI;mDAAoB,CAAC;oBAC3C,KAAK,MAAM,SAAS,UAAU,UAAU,GAAI;wBAC1C,8DAA8D;wBAC9D,IAAI,CAAC,AAAC,MAAc,cAAc,EAAE;4BAClC,8DAA8D;4BAC9D,YAAY,AAAC,MAAc,KAAK;4BAChC,cAAc;gCAAE,KAAK,KAAK,KAAK,CAAC,WAAW,QAAQ;4BAAK;wBAC1D;oBACF;gBACF;;YAEA,IAAI;gBACF,YAAY,OAAO,CAAC;oBAAE,MAAM;oBAAgB,UAAU;gBAAK;YAC7D,EAAE,OAAM;YACN,6BAA6B;YAC/B;YAEA,cAAc;YACd,MAAM,cAAc,IAAI;mDAAoB,CAAC;oBAC3C,KAAK,MAAM,SAAS,UAAU,UAAU,GAAI;wBAC1C,8DAA8D;wBAC9D,MAAM,WAAW;wBACjB,cAAc;4BAAE,KAAK,KAAK,KAAK,CAAC,SAAS,eAAe,GAAG,SAAS,SAAS;wBAAE;oBACjF;gBACF;;YAEA,IAAI;gBACF,YAAY,OAAO,CAAC;oBAAE,MAAM;oBAAe,UAAU;gBAAK;YAC5D,EAAE,OAAM;YACN,6BAA6B;YAC/B;YAEA,0CAA0C;YAC1C,MAAM,cAAc,IAAI;mDAAoB,CAAC;oBAC3C,KAAK,MAAM,SAAS,UAAU,UAAU,GAAI;wBAC1C,8DAA8D;wBAC9D,MAAM,WAAW,AAAC,MAAc,QAAQ;wBACxC,IAAI,UAAU;4BACZ,cAAc;gCAAE,KAAK,KAAK,KAAK,CAAC;4BAAU;wBAC5C;oBACF;gBACF;;YAEA,IAAI;gBACF,YAAY,OAAO,CAAC;oBAAE,MAAM;oBAAS,UAAU;gBAAK;YACtD,EAAE,OAAM;YACN,6BAA6B;YAC/B;YAEA;mDAAO;oBACL,cAAc,UAAU;oBACxB,YAAY,UAAU;oBACtB,YAAY,UAAU;oBACtB,YAAY,UAAU;oBACtB,YAAY,UAAU;gBACxB;;QACF;0CAAG;QAAC;KAAc;IAElB,wBAAwB;IACxB,MAAM,iBAAiB,IAAA,qXAAW;6DAAC;YACjC,IAAI,+CAAkB,eAAe,CAAC,OAAO,WAAW,EAAE;YAE1D,MAAM,aAAa,YAAY,gBAAgB,CAAC,aAAa,CAAC,EAAE;YAChE,MAAM,YAAY,YAAY,gBAAgB,CAAC;YAE/C,IAAI,YAAY;gBACd,MAAM,eAAe,WAAW,YAAY,GAAG,WAAW,SAAS;gBACnE,MAAM,OAAO,WAAW,aAAa,GAAG,WAAW,YAAY;gBAC/D,MAAM,YAAY,UAAU,MAAM;mFAAC,CAAC,KAAK,IAAM,MAAM,CAAC,EAAE,YAAY,IAAI,CAAC;kFAAG;gBAE5E,cAAc;oBACZ,cAAc,eAAe,IAAI,KAAK,KAAK,CAAC,gBAAgB;oBAC5D,MAAM,OAAO,IAAI,KAAK,KAAK,CAAC,QAAQ;oBACpC,eAAe,UAAU,MAAM;oBAC/B,cAAc,KAAK,KAAK,CAAC,YAAY;gBACvC;YACF;QACF;4DAAG;QAAC;KAAc;IAElB,OAAO;QAAE;QAAS;QAAa;IAAe;AAChD;GA9KgB"}},
    {"offset": {"line": 2240, "column": 0}, "map": {"version":3,"sources":["file:///Users/jamesspalding/OpenClaw-OS/src/hooks/useProviderStatus.ts"],"sourcesContent":["'use client';\n\nimport { useState, useEffect, useCallback, useRef } from 'react';\n\nexport type ProviderType = 'cloud' | 'local' | 'lynkr';\nexport type ConnectionStatus = 'connected' | 'connecting' | 'disconnected';\n\nexport interface ProviderStatusData {\n  providerType: ProviderType;\n  status: ConnectionStatus;\n  latencyMs?: number;\n  error?: string;\n  lastChecked: number;\n}\n\ninterface HealthResponse {\n  timestamp: number;\n  providers: {\n    ollama: { connected: boolean; latencyMs?: number; error?: string };\n    lynkr: { connected: boolean; latencyMs?: number; error?: string };\n    openai: { connected: boolean; latencyMs?: number; error?: string };\n    anthropic: { connected: boolean; latencyMs?: number; error?: string };\n  };\n  summary: {\n    localAvailable: boolean;\n    lynkrAvailable: boolean;\n    cloudAvailable: boolean;\n    recommendedProvider: 'local' | 'lynkr' | 'cloud';\n  };\n}\n\nconst POLL_INTERVAL = 30000; // 30 seconds\nconst INITIAL_TIMEOUT = 8000; // 8 seconds for health check\n\n/**\n * Hook to track AI provider connection status\n * Returns the current active provider and its connection status\n */\nexport function useProviderStatus() {\n  const [status, setStatus] = useState<ProviderStatusData>({\n    providerType: 'cloud',\n    status: 'connecting',\n    lastChecked: 0,\n  });\n  const isCheckingRef = useRef(false);\n\n  const checkHealth = useCallback(async () => {\n    if (isCheckingRef.current) return;\n    isCheckingRef.current = true;\n\n    try {\n      // Check health with timeout for better UX\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), INITIAL_TIMEOUT);\n\n      const healthRes = await fetch('/api/health/providers?checkCloud=false', {\n        signal: controller.signal,\n      });\n      clearTimeout(timeoutId);\n\n      if (!healthRes.ok) {\n        setStatus((prev) => ({\n          ...prev,\n          status: 'disconnected',\n          error: 'Health check failed',\n          lastChecked: Date.now(),\n        }));\n        return;\n      }\n\n      const health: HealthResponse = await healthRes.json();\n\n      // Determine provider based on what's available\n      // Priority: Lynkr > Local > Cloud\n      let actualProvider: ProviderType = 'cloud';\n      let connectionStatus: ConnectionStatus = 'connected';\n      let latency: number | undefined;\n\n      if (health.summary.lynkrAvailable) {\n        actualProvider = 'lynkr';\n        connectionStatus = 'connected';\n        latency = health.providers.lynkr.latencyMs;\n      } else if (health.summary.localAvailable) {\n        actualProvider = 'local';\n        connectionStatus = 'connected';\n        latency = health.providers.ollama.latencyMs;\n      } else {\n        // Default to cloud - assume cloud is always available\n        actualProvider = 'cloud';\n        connectionStatus = 'connected';\n      }\n\n      setStatus({\n        providerType: actualProvider,\n        status: connectionStatus,\n        latencyMs: latency,\n        lastChecked: Date.now(),\n      });\n    } catch (err) {\n      // On error, assume cloud fallback is working\n      setStatus({\n        providerType: 'cloud',\n        status: 'connected',\n        lastChecked: Date.now(),\n      });\n    } finally {\n      isCheckingRef.current = false;\n    }\n  }, []);\n\n  // Initial check with a small delay to not block render\n  useEffect(() => {\n    const timer = setTimeout(checkHealth, 1000);\n    return () => clearTimeout(timer);\n  }, [checkHealth]);\n\n  // Periodic polling\n  useEffect(() => {\n    const interval = setInterval(checkHealth, POLL_INTERVAL);\n    return () => clearInterval(interval);\n  }, [checkHealth]);\n\n  // Helper function to get display color\n  const getStatusColor = useCallback(() => {\n    switch (status.status) {\n      case 'connected':\n        return '#22c55e'; // green-500\n      case 'connecting':\n        return '#f97316'; // orange-500\n      case 'disconnected':\n        return '#ef4444'; // red-500\n      default:\n        return '#6b7280'; // gray-500\n    }\n  }, [status.status]);\n\n  // Helper function to get provider display name\n  const getProviderDisplayName = useCallback(() => {\n    switch (status.providerType) {\n      case 'lynkr':\n        return 'Lynkr';\n      case 'local':\n        return 'Local';\n      case 'cloud':\n        return 'Cloud';\n      default:\n        return 'Unknown';\n    }\n  }, [status.providerType]);\n\n  return {\n    ...status,\n    isChecking: isCheckingRef.current,\n    refresh: checkHealth,\n    getStatusColor,\n    getProviderDisplayName,\n  };\n}\n\nexport default useProviderStatus;\n"],"names":[],"mappings":";;;;;;AAEA;;AAFA;;AA+BA,MAAM,gBAAgB,OAAO,aAAa;AAC1C,MAAM,kBAAkB,MAAM,6BAA6B;AAMpD,SAAS;;IACd,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,kXAAQ,EAAqB;QACvD,cAAc;QACd,QAAQ;QACR,aAAa;IACf;IACA,MAAM,gBAAgB,IAAA,gXAAM,EAAC;IAE7B,MAAM,cAAc,IAAA,qXAAW;sDAAC;YAC9B,IAAI,cAAc,OAAO,EAAE;YAC3B,cAAc,OAAO,GAAG;YAExB,IAAI;gBACF,0CAA0C;gBAC1C,MAAM,aAAa,IAAI;gBACvB,MAAM,YAAY;4EAAW,IAAM,WAAW,KAAK;2EAAI;gBAEvD,MAAM,YAAY,MAAM,MAAM,0CAA0C;oBACtE,QAAQ,WAAW,MAAM;gBAC3B;gBACA,aAAa;gBAEb,IAAI,CAAC,UAAU,EAAE,EAAE;oBACjB;sEAAU,CAAC,OAAS,CAAC;gCACnB,GAAG,IAAI;gCACP,QAAQ;gCACR,OAAO;gCACP,aAAa,KAAK,GAAG;4BACvB,CAAC;;oBACD;gBACF;gBAEA,MAAM,SAAyB,MAAM,UAAU,IAAI;gBAEnD,+CAA+C;gBAC/C,kCAAkC;gBAClC,IAAI,iBAA+B;gBACnC,IAAI,mBAAqC;gBACzC,IAAI;gBAEJ,IAAI,OAAO,OAAO,CAAC,cAAc,EAAE;oBACjC,iBAAiB;oBACjB,mBAAmB;oBACnB,UAAU,OAAO,SAAS,CAAC,KAAK,CAAC,SAAS;gBAC5C,OAAO,IAAI,OAAO,OAAO,CAAC,cAAc,EAAE;oBACxC,iBAAiB;oBACjB,mBAAmB;oBACnB,UAAU,OAAO,SAAS,CAAC,MAAM,CAAC,SAAS;gBAC7C,OAAO;oBACL,sDAAsD;oBACtD,iBAAiB;oBACjB,mBAAmB;gBACrB;gBAEA,UAAU;oBACR,cAAc;oBACd,QAAQ;oBACR,WAAW;oBACX,aAAa,KAAK,GAAG;gBACvB;YACF,EAAE,OAAO,KAAK;gBACZ,6CAA6C;gBAC7C,UAAU;oBACR,cAAc;oBACd,QAAQ;oBACR,aAAa,KAAK,GAAG;gBACvB;YACF,SAAU;gBACR,cAAc,OAAO,GAAG;YAC1B;QACF;qDAAG,EAAE;IAEL,uDAAuD;IACvD,IAAA,mXAAS;uCAAC;YACR,MAAM,QAAQ,WAAW,aAAa;YACtC;+CAAO,IAAM,aAAa;;QAC5B;sCAAG;QAAC;KAAY;IAEhB,mBAAmB;IACnB,IAAA,mXAAS;uCAAC;YACR,MAAM,WAAW,YAAY,aAAa;YAC1C;+CAAO,IAAM,cAAc;;QAC7B;sCAAG;QAAC;KAAY;IAEhB,uCAAuC;IACvC,MAAM,iBAAiB,IAAA,qXAAW;yDAAC;YACjC,OAAQ,OAAO,MAAM;gBACnB,KAAK;oBACH,OAAO,WAAW,YAAY;gBAChC,KAAK;oBACH,OAAO,WAAW,aAAa;gBACjC,KAAK;oBACH,OAAO,WAAW,UAAU;gBAC9B;oBACE,OAAO,WAAW,WAAW;YACjC;QACF;wDAAG;QAAC,OAAO,MAAM;KAAC;IAElB,+CAA+C;IAC/C,MAAM,yBAAyB,IAAA,qXAAW;iEAAC;YACzC,OAAQ,OAAO,YAAY;gBACzB,KAAK;oBACH,OAAO;gBACT,KAAK;oBACH,OAAO;gBACT,KAAK;oBACH,OAAO;gBACT;oBACE,OAAO;YACX;QACF;gEAAG;QAAC,OAAO,YAAY;KAAC;IAExB,OAAO;QACL,GAAG,MAAM;QACT,YAAY,cAAc,OAAO;QACjC,SAAS;QACT;QACA;IACF;AACF;GAvHgB;uCAyHD"}}]
}